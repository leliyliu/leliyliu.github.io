<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>坠落</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="record">
<meta property="og:type" content="website">
<meta property="og:title" content="坠落">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="坠落">
<meta property="og:description" content="record">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="坠落">
<meta name="twitter:description" content="record">
  
    <link rel="alternate" href="/atom.xml" title="坠落" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">坠落</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">do what you want to do</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-github-use-1" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/09/25/github-use-1/" class="article-date">
  <time datetime="2019-09-25T11:15:03.000Z" itemprop="datePublished">2019-09-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/25/github-use-1/">github&amp;git</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/09/25/github-use-1/" data-id="ck0z6d1om000gp8tqsc30ly5n" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/github-git/">github/git</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-github&amp;git" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/09/25/github&git/" class="article-date">
  <time datetime="2019-09-25T11:15:03.000Z" itemprop="datePublished">2019-09-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/09/25/github&git/">github&amp;git</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Git-amp-github"><a href="#Git-amp-github" class="headerlink" title="Git &amp; github"></a>Git &amp; github</h1><hr>
<h2 id="github-账号申请"><a href="#github-账号申请" class="headerlink" title="github 账号申请"></a>github 账号申请</h2><h3 id="personal-or-workgroup"><a href="#personal-or-workgroup" class="headerlink" title="personal or workgroup"></a>personal or workgroup</h3><ul>
<li>个人账号注册-&gt; 登录<a href="https://github.com/" target="_blank" rel="noopener">github</a> 根据相关信息注册账号(sign up 表示注册，sign in 表示登录)</li>
</ul>
<p>当需要注册organization的时候，则可以如图，选择new organization 来创建一个workgroup。<br><img src="https://github.com/leliyliu/figure_lib/blob/master/loognson/git/organization.png" alt="workgourp"></p>
<h3 id="创建仓库-new-repository"><a href="#创建仓库-new-repository" class="headerlink" title="创建仓库(new repository)"></a>创建仓库(new repository)</h3><p>其中包括了几项内容，需要填写或者选择：repository name , Description, initialization or not , gitignore and license.<br><img src="https://github.com/leliyliu/figure_lib/blob/master/loognson/git/create.jpg" alt="create"></p>
<p>选择clone or download,然后在本地打开git bash ，然后git clone：<br><img src="https://github.com/leliyliu/figure_lib/blob/master/loognson/git/clone.jpg" alt="clone"><br><img src="https://github.com/leliyliu/figure_lib/blob/master/loognson/git/gitclone.jpg" alt="git_clone"></p>
<h3 id="配置用户名和邮箱"><a href="#配置用户名和邮箱" class="headerlink" title="配置用户名和邮箱"></a>配置用户名和邮箱</h3><blockquote>
<p>第一次使用gitBash需要配置邮箱和用户名，邮箱可以填你自己的邮箱，用户名可以任意写，这不是做登录使用，就是保留自己的信息而已。</p>
</blockquote>
<ul>
<li>输入git config —global user.email按回车，然后输入你的邮箱</li>
<li>输入git config —global user.name按回车，然后输入你的用户名</li>
<li>邮箱和用户名都使用之后就可以正式使用git了</li>
</ul>
<h3 id="git-常用命令汇总"><a href="#git-常用命令汇总" class="headerlink" title="git 常用命令汇总"></a>git 常用命令汇总</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">克隆代码：git <span class="built_in">clone</span> 远程仓库的url</span><br><span class="line">配置邮箱：git config --global user.email</span><br><span class="line">配置用户名：git config --global user.name</span><br><span class="line">从远程仓库下拉代码到本地：git pull</span><br><span class="line">将本地代码添加到缓冲区：git add * .</span><br><span class="line">将本地代码提交到本地仓库：git commit -m<span class="string">"日志文字"</span></span><br><span class="line">将本地仓库同步到远程仓库：git push origin master</span><br><span class="line">查看日志：git <span class="built_in">log</span></span><br><span class="line">查看某个文件的提交日志：git <span class="built_in">log</span> 文件名</span><br><span class="line">查看某个用户的提交日志：git <span class="built_in">log</span> --author=“author”</span><br><span class="line">查看某条提交日志相信信息：git show 版本号</span><br><span class="line">查看git全部命令：git --<span class="built_in">help</span></span><br><span class="line">查看git某个命令的使用：git <span class="built_in">help</span> 命令名</span><br></pre></td></tr></table></figure>
<h3 id="more-commands"><a href="#more-commands" class="headerlink" title="more commands"></a>more commands</h3><p>参考<a href="https://www.jianshu.com/p/cf1e883d69d6" target="_blank" rel="noopener">Git 命令大全</a></p>
<h4 id="项目提交和拉取"><a href="#项目提交和拉取" class="headerlink" title="项目提交和拉取"></a>项目提交和拉取</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// 克隆远程仓库到本地(先<span class="built_in">cd</span>到指定文件夹下,再执行<span class="built_in">clone</span>操作）</span><br><span class="line">$ git <span class="built_in">clone</span> git@github.com:leliyliu/augmips.git</span><br><span class="line"></span><br><span class="line">// 添加本地库</span><br><span class="line">$ git add ProjectName         --------  <span class="string">"ProjectName"</span>项目名称</span><br><span class="line"></span><br><span class="line">// 添加提交日志</span><br><span class="line">$ git commit -m ‘Journal’     </span><br><span class="line"></span><br><span class="line">// 提交到远端</span><br><span class="line">$ git push origin master      --------  <span class="string">"master"</span>分支名</span><br><span class="line"></span><br><span class="line">// 从远端拉取代</span><br><span class="line">$ git pull origin master</span><br></pre></td></tr></table></figure>
<h4 id="常用辅助命令"><a href="#常用辅助命令" class="headerlink" title="常用辅助命令"></a>常用辅助命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 查看提交日志</span><br><span class="line">$ git <span class="built_in">log</span> -3  --------查看最近三次提交的记录</span><br><span class="line"></span><br><span class="line">// 查看文件提交状态</span><br><span class="line">$ git status</span><br></pre></td></tr></table></figure>
<h4 id="标签操作"><a href="#标签操作" class="headerlink" title="标签操作"></a>标签操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 打一个新标签</span><br><span class="line">$ git tag v1.0.0</span><br><span class="line"></span><br><span class="line">// 查看所有标签</span><br><span class="line">$ git tag</span><br><span class="line"></span><br><span class="line">// 根据commit id 打标签</span><br><span class="line">$ git tag v1.0.1 2fbb88d5fad5a03e5b4ef2df316b4d32f5339ef5</span><br><span class="line"></span><br><span class="line">// 删除标签</span><br><span class="line">$ git tag -d v1.1.0</span><br></pre></td></tr></table></figure>
<h4 id="关于分支"><a href="#关于分支" class="headerlink" title="关于分支"></a>关于分支</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">//1、 查看当前所有分支</span><br><span class="line">$ git branch</span><br><span class="line"></span><br><span class="line"><span class="comment"># * dev          ---- 当前分支</span></span><br><span class="line"><span class="comment">#   master       ---- 主分支</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//2、 创建分支</span><br><span class="line">$ git branch dev</span><br><span class="line"></span><br><span class="line">//3、 切换分支</span><br><span class="line">$ git checkout dev</span><br><span class="line"></span><br><span class="line">//4、 创建并切换分支（相当于前两步操作）</span><br><span class="line">$ git checkout -b dev</span><br><span class="line"></span><br><span class="line">//5.1、 合并分支</span><br><span class="line">$ git merge dev                 ------ ⚠️ （此命令为：合并某分支到当前分支，例：将dev合并到master），则当前所处于master分支。</span><br><span class="line"></span><br><span class="line">//5.2、 合并dev分支上的某条记录到master上</span><br><span class="line">//（例如：在dev上有三次提交记录，但是只想把其中的第二次合并到master上去，采取这个命令）</span><br><span class="line">git cherry-pick <span class="string">"ddec59e2..."</span>   ------⚠️ 在master分支下输入命令，参数为 commit-id</span><br><span class="line"></span><br><span class="line">// 如果在合并中存在以下冲突，进入文件夹手动解决冲突再次提交</span><br><span class="line">hint: after resolving the conflicts, mark the corrected paths</span><br><span class="line">hint: with <span class="string">'git add &lt;paths&gt;'</span> or <span class="string">'git rm &lt;paths&gt;'</span></span><br><span class="line"></span><br><span class="line">//6、 删除指定分支</span><br><span class="line">$ git branch -D dev              ------ ⚠️（保证当前分支为非删除分支）</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">//1、 查看当前所有分支</span><br><span class="line">$ git branch</span><br><span class="line"></span><br><span class="line"><span class="comment"># * dev          ---- 当前分支</span></span><br><span class="line"><span class="comment">#   master       ---- 主分支</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//2、 创建分支</span><br><span class="line">$ git branch dev</span><br><span class="line"></span><br><span class="line">//3、 切换分支</span><br><span class="line">$ git checkout dev</span><br><span class="line"></span><br><span class="line">//4、 创建并切换分支（相当于前两步操作）</span><br><span class="line">$ git checkout -b dev</span><br><span class="line"></span><br><span class="line">//5.1、 合并分支</span><br><span class="line">$ git merge dev                 ------ ⚠️ （此命令为：合并某分支到当前分支，例：将dev合并到master），则当前所处于master分支。</span><br><span class="line"></span><br><span class="line">//5.2、 合并dev分支上的某条记录到master上</span><br><span class="line">//（例如：在dev上有三次提交记录，但是只想把其中的第二次合并到master上去，采取这个命令）</span><br><span class="line">git cherry-pick <span class="string">"ddec59e2..."</span>   ------⚠️ 在master分支下输入命令，参数为 commit-id</span><br><span class="line"></span><br><span class="line">// 如果在合并中存在以下冲突，进入文件夹手动解决冲突再次提交</span><br><span class="line">hint: after resolving the conflicts, mark the corrected paths</span><br><span class="line">hint: with <span class="string">'git add &lt;paths&gt;'</span> or <span class="string">'git rm &lt;paths&gt;'</span></span><br><span class="line"></span><br><span class="line">//6、 删除指定分支</span><br><span class="line">$ git branch -D dev              ------ ⚠️（保证当前分支为非删除分支）</span><br></pre></td></tr></table></figure>
<h4 id="版本的回退"><a href="#版本的回退" class="headerlink" title="版本的回退"></a>版本的回退</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">log</span> -3</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit 65e19bef8eed336aefedaca636d78e71cea1d4f6 (HEAD -&gt; master, origin/master, origin/HEAD)</span></span><br><span class="line"><span class="comment"># Author: lizhiqiang &lt;601623654@qq.com&gt;</span></span><br><span class="line"><span class="comment"># Date:   Wed Mar 14 15:54:06 2018 +0800</span></span><br><span class="line"></span><br><span class="line">    增加1.1.3版本</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit 2fbb88d5fad5a03e5b4ef2df316b4d32f5339ef5</span></span><br><span class="line"><span class="comment"># Author: lizhiqiang &lt;601623654@qq.com&gt;</span></span><br><span class="line"><span class="comment"># Date:   Wed Mar 14 15:51:22 2018 +0800</span></span><br><span class="line"></span><br><span class="line">    增加1.1.2版本</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit aa0f5ce90153c76249a12b8fa638a42b5155612b</span></span><br><span class="line"><span class="comment"># Author: lizhiqiang &lt;601623654@qq.com&gt;</span></span><br><span class="line"><span class="comment"># Date:   Wed Mar 14 15:46:03 2018 +0800</span></span><br><span class="line"></span><br><span class="line">    增加1.1.1版本</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 退回到上一个版本</span><br><span class="line">$ git reset --hard HEAD^</span><br><span class="line"><span class="comment"># HEAD is now at 2fbb88d 增加1.1.2版本    </span></span><br><span class="line">-----在此我们可以看到，HEAD指针已经由1.1.3版本指向了1.1.2版本，如果你把xcode打开就可以看到，1.1.3的代码已经消失了</span><br><span class="line">-----如果你的命令窗口没有关闭的话，通过commit id 还是可以返回1.1.3的,具体请看下一条命令</span><br><span class="line"></span><br><span class="line">// 返回任意版本</span><br><span class="line">$ git reset --hard 65e19bef8eed336aefedaca636d78e71cea1d4f6</span><br><span class="line"><span class="comment"># HEAD is now at 65e19be 增加1.1.3版本</span></span><br><span class="line"></span><br><span class="line">// 将修改后的版本推送至服务器</span><br><span class="line">$ git push -f -u origin master</span><br></pre></td></tr></table></figure>
<h4 id="阶段的撤销更改"><a href="#阶段的撤销更改" class="headerlink" title="阶段的撤销更改"></a>阶段的撤销更改</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// 已修改，未暂存   ------------没有执行 git add</span><br><span class="line">$ git checkout .    （或 $ git reset --hard）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 已暂存，未提交   ------------你已经执行了 git add . ，但还没有执行 git commit -m <span class="string">"comment"</span> 。</span><br><span class="line">$ git reset</span><br><span class="line">$ git checkout .     (或 $ git reset --hard)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 已提交，未推送   ------------既执行了 git add . ，又执行了 git commit </span><br><span class="line">$ git reset --hard origin/master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 已推送          ------------既 git add 了，又 git commit 了，并且还 git push 了</span><br><span class="line">$ git reset --hard HEAD^</span><br><span class="line">$ git push -f</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/09/25/github&git/" data-id="ck0z6d1oi000dp8tq0bl1jkpt" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/github-git/">github/git</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-django-learning" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/05/django-learning/" class="article-date">
  <time datetime="2019-05-05T06:56:16.000Z" itemprop="datePublished">2019-05-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/05/05/django-learning/">django_learning</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/05/05/django-learning/" data-id="ck0z6d1op000ip8tq3l1vr2a1" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-paper-reading" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/05/paper-reading/" class="article-date">
  <time datetime="2019-05-05T00:07:26.000Z" itemprop="datePublished">2019-05-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/05/05/paper-reading/">paper_reading</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Neural-Collaborative-Filtering"><a href="#Neural-Collaborative-Filtering" class="headerlink" title="Neural Collaborative Filtering"></a>Neural Collaborative Filtering</h1><p>这篇文章主要介绍了深度学习在推荐系统方面的应用，主要是应用了神经网络搭建协同过滤的网络，形成一个较好的结果。</p>
<p>我将结合文章中所提及的主要方法及其代码来回顾整篇文章。</p>
<h2 id="3-NEURAL-COLLABORATIVE-FILTERING"><a href="#3-NEURAL-COLLABORATIVE-FILTERING" class="headerlink" title="3. NEURAL COLLABORATIVE FILTERING"></a>3. NEURAL COLLABORATIVE FILTERING</h2><p>从第三部分才来到实践的关键，所以我们直接跳过前两个部分，来到第三部分，并对它进行学习和理解。论文的主要部分在于，首先实现NCF，并对于NCF实例化之后利用DNN对其进行改善，提出了MLP，然后结合NCF和MLP来综合形成最后的结果。</p>
<h3 id="GMF"><a href="#GMF" class="headerlink" title="GMF"></a>GMF</h3><p>首先的input层是一个one-hot向量，将每一个user和每一个item都设置为one-hot向量之后再进行处理。在input 层之后是一个embedding 层，然后将item和user 的embedding层 的结果合在一起之后放入一个多层神经网络中，我们将这个多层的神经网络视作神经协同过滤层，隐藏层的最后一层的维度决定了这个模型的泛化能力。最终的输出层(output)得到的是最终预测的结果。</p>
<h4 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h4><p>关于range 和 xrange，如果只看效果的话，两者差距很小，但是xrange每次返回的是xrange 的一个数据结构，而不是range返回的list，因此，当对于大数据进行处理时，建议使用xrange，而不是range。</p>
<p>关于代码中的参数说明：<br>| 符号| 含义|<br>| —- | —- |<br>| num_factors|将其映射到的空间的维度大小|<br>|regs|即正则化过程中的偏移量|<br>|num_neg|展示的negtive数量|<br>|lr|学习率|<br>|learner|学习的方式，一般来说使用adam|<br>|verbose|实质上是设置多少次迭代后输出结果|<br>|out| 设置输出|<br>|epochs| 迭代次数（学习次数）|<br>|batch_size|每一个batch的数量，使用sgd进行训练时需要弄清楚|</p>
<p>重点看model函数，即训练的函数。<br>这里的模型极其简单，实际上加深模型，应该有助于最后的训练结果。加深应该在哪里呢？从predict_vector开始，多加入几层，同时应该考虑不要社会太少的latent_dim，毕竟是大数据量的结果，考虑将其加深。原文中主要是为了能使得CPU较快的运行，才使用了这样一种方式。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span><span class="params">(num_users, num_items, latent_dim, regs=[<span class="number">0</span>,<span class="number">0</span>])</span>:</span></span><br><span class="line">    <span class="comment"># Input variables</span></span><br><span class="line">    user_input = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>, name = <span class="string">'user_input'</span>)</span><br><span class="line">    item_input = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>, name = <span class="string">'item_input'</span>)</span><br><span class="line"></span><br><span class="line">    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = <span class="string">'user_embedding'</span>,</span><br><span class="line">                                  init = init_normal, W_regularizer = l2(regs[<span class="number">0</span>]), input_length=<span class="number">1</span>)</span><br><span class="line">    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = <span class="string">'item_embedding'</span>,</span><br><span class="line">                                  init = init_normal, W_regularizer = l2(regs[<span class="number">1</span>]), input_length=<span class="number">1</span>)   </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Crucial to flatten an embedding vector!</span></span><br><span class="line">    user_latent = Flatten()(MF_Embedding_User(user_input))</span><br><span class="line">    item_latent = Flatten()(MF_Embedding_Item(item_input))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Element-wise product of user and item embeddings </span></span><br><span class="line">    predict_vector = merge([user_latent, item_latent], mode = <span class="string">'mul'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Final prediction layer</span></span><br><span class="line">    <span class="comment">#prediction = Lambda(lambda x: K.sigmoid(K.sum(x)), output_shape=(1,))(predict_vector)</span></span><br><span class="line">    prediction = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>, init=<span class="string">'lecun_uniform'</span>, name = <span class="string">'prediction'</span>)(predict_vector)</span><br><span class="line">    </span><br><span class="line">    model = Model(input=[user_input, item_input], </span><br><span class="line">                output=prediction)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>get_train_instances函数将训练集传入并对其进行处理，构成one-hot向量。<br>但是实际上这里的label只是用于论文中所说的是否进行点击，对于后续的操作的意义不大。需要注意这里的区别。实际上，如果真正需要做评分系统的话，那么就需要将label定义为打分的结果，而不是0,1的二值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_instances</span><span class="params">(train, num_negatives)</span>:</span></span><br><span class="line">    user_input, item_input, labels = [],[],[]</span><br><span class="line">    num_users = train.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> (u, i) <span class="keyword">in</span> train.keys():</span><br><span class="line">        <span class="comment"># positive instance</span></span><br><span class="line">        user_input.append(u)</span><br><span class="line">        item_input.append(i)</span><br><span class="line">        labels.append(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># negative instances</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> xrange(num_negatives):</span><br><span class="line">            j = np.random.randint(num_items)<span class="comment">#从0到item_num的数量中选择一个</span></span><br><span class="line">            <span class="keyword">while</span> train.has_key((u, j)):</span><br><span class="line">                j = np.random.randint(num_items)</span><br><span class="line">            user_input.append(u)</span><br><span class="line">            item_input.append(j)</span><br><span class="line">            labels.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> user_input, item_input, labels</span><br></pre></td></tr></table></figure>
<p>自己的尝试，主要用于大数据作业的数据集，简要介绍一下这个数据集：</p>
<ol>
<li>大概有20000个用户和600000个item，同时，总共有5000000条的打分，打分从0-100，但是分布极其不均匀，因此，需要对其进行处理，为了避免与稀疏矩阵的重合，将score变为:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score=np.floor(score/<span class="number">10</span>)+<span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>因此，构建的模型为<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span><span class="params">(num_users, num_items, latent_dim=<span class="number">100</span>, regs=[<span class="number">0</span>,<span class="number">0</span>])</span>:</span></span><br><span class="line">    <span class="comment"># Input variables</span></span><br><span class="line">    user_input = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>, name = <span class="string">'user_input'</span>)</span><br><span class="line">    item_input = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>, name = <span class="string">'item_input'</span>)</span><br><span class="line"></span><br><span class="line">    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = <span class="string">'user_embedding'</span>,</span><br><span class="line">                                  init = <span class="string">'uniform'</span>, W_regularizer = l2(regs[<span class="number">0</span>]), input_length=<span class="number">1</span>)</span><br><span class="line">    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = <span class="string">'item_embedding'</span>,</span><br><span class="line">                                  init = <span class="string">'uniform'</span>, W_regularizer = l2(regs[<span class="number">1</span>]), input_length=<span class="number">1</span>)   </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Crucial to flatten an embedding vector!</span></span><br><span class="line">    user_latent = Flatten()(MF_Embedding_User(user_input))</span><br><span class="line">    item_latent = Flatten()(MF_Embedding_Item(item_input))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Element-wise product of user and item embeddings </span></span><br><span class="line">    <span class="comment">#predict_vector = merge([user_latent, item_latent], mode = 'mul')</span></span><br><span class="line">    predict_vector = keras.layers.Multiply()([user_latent,item_latent])</span><br><span class="line">    <span class="comment"># Final prediction layer</span></span><br><span class="line">    <span class="comment">#prediction = Lambda(lambda x: K.sigmoid(K.sum(x)), output_shape=(1,))(predict_vector)</span></span><br><span class="line">    predict_layer1=Dense(<span class="number">64</span>,activation=<span class="string">'sigmoid'</span>,init=<span class="string">'lecun_uniform'</span>,name=<span class="string">'predict_layer1'</span>)(predict_vector)</span><br><span class="line">    predict_layer2=Dense(<span class="number">32</span>,activation=<span class="string">'sigmoid'</span>,init=<span class="string">'lecun_uniform'</span>,name=<span class="string">'predict_layer2'</span>)(predict_layer1)</span><br><span class="line">    prediction = Dense(<span class="number">11</span>, activation=<span class="string">'softmax'</span>, init=<span class="string">'lecun_uniform'</span>, name = <span class="string">'prediction'</span>)(predict_layer2)</span><br><span class="line">    </span><br><span class="line">    model = Model(input=[user_input, item_input], </span><br><span class="line">                output=prediction)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>中间多加了几层，对于报错处的记录</p>
<blockquote>
<p>‘Dense’ object has no attribute ‘outbound_nodes’</p>
</blockquote>
<h3 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/05/05/paper-reading/" data-id="ck0z6d1p8000xp8tq1imz3llg" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paper-reading/">paper_reading</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-colab" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/04/colab/" class="article-date">
  <time datetime="2019-05-04T09:10:58.000Z" itemprop="datePublished">2019-05-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/05/04/colab/">colab</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Colab的使用"><a href="#Colab的使用" class="headerlink" title="Colab的使用"></a>Colab的使用</h1><hr>
<h2 id="Colab介绍"><a href="#Colab介绍" class="headerlink" title="Colab介绍"></a>Colab介绍</h2><p>好东西！！ 贫穷的人民，想拥有GPU或者TPU的难得的方式<br>对于一些基础的东西，都不加以介绍了，如果有兴趣，可以自己去查一下，或者ucadity的tensorflow教程里面就要用到这个东西，直接视频观看即可。<br>这里直接记录配置方式</p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><p>首先选择修改，改为GPU或者TPU</p>
<p>然后添加如下代码后执行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">!apt-get install -y -qq software-properties-common python-software-properties module-init-tools</span><br><span class="line">!add-apt-repository -y ppa:alessandro-strada/ppa <span class="number">2</span>&gt;&amp;<span class="number">1</span> &gt; /dev/null</span><br><span class="line">!apt-get update -qq <span class="number">2</span>&gt;&amp;<span class="number">1</span> &gt; /dev/null</span><br><span class="line">!apt-get -y install -qq google-drive-ocamlfuse fuse</span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> auth</span><br><span class="line">auth.authenticate_user()</span><br><span class="line"><span class="keyword">from</span> oauth2client.client <span class="keyword">import</span> GoogleCredentials</span><br><span class="line">creds = GoogleCredentials.get_application_default()</span><br><span class="line"><span class="keyword">import</span> getpass</span><br><span class="line">!google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125; &lt; /dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span> | grep URL</span><br><span class="line">vcode = getpass.getpass()</span><br><span class="line">!echo &#123;vcode&#125; | google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后挂载<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!mkdir -p drive</span><br><span class="line">!google-drive-ocamlfuse drive</span><br></pre></td></tr></table></figure></p>
<p>如果需要安装包的时候，比如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install http://download.pytorch.org/whl/cu80/torch<span class="number">-0.3</span><span class="number">.1</span>-cp36-cp36m-linux_x86_64.whl torchvision</span><br></pre></td></tr></table></figure></p>
<p>这样安装就ok了</p>
<p>当然在执行之前还需要更改目录：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(<span class="string">'drive/.../...'</span>)<span class="comment">#进入你希望进入的目录</span></span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/05/04/colab/" data-id="ck0z6d1p0000pp8tq2ufomdif" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/use-of-Colab-deep-learning/">use of Colab(deep learning)</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-recording2" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/28/recording2/" class="article-date">
  <time datetime="2019-04-28T10:59:18.000Z" itemprop="datePublished">2019-04-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/28/recording2/">AlexNet</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Paper-Reading"><a href="#Paper-Reading" class="headerlink" title="Paper Reading"></a>Paper Reading</h1><h2 id="ImageNet-Classification-with-Deep-Convolutional-Neural-Networks"><a href="#ImageNet-Classification-with-Deep-Convolutional-Neural-Networks" class="headerlink" title="ImageNet Classification with Deep Convolutional Neural Networks"></a>ImageNet Classification with Deep Convolutional Neural Networks</h2><hr>
<blockquote>
<p><code>references</code>: you can read this papar via <a href="https://linkinghub.elsevier.com/retrieve/pii/S138650561831195X" target="_blank" rel="noopener">BTS-DSN</a> or star/fork this github <a href="https://github.com/guomugong/BTS-DSN" target="_blank" rel="noopener">project</a></p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>To achieve a great result, using ImageNet LSVRC-2010 contest dataset, this network model ,including dropout and some other operations, is quite fancy.</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h3><ol>
<li><p>machine learning methods have achieved great result on small image dataset, but still been poor in big dataset.</p>
</li>
<li><p><code>To learn about thousands of objects from millions of images, we need a model with a large learning
capacity.</code></p>
</li>
</ol>
<h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p><code>ImageNet is a dataset of over 15 million labeled high-resolution images belonging to roughly 22,000
categories.</code><br>to show which dataset this paper trained to test its result.</p>
<h3 id="3-The-Architecture"><a href="#3-The-Architecture" class="headerlink" title="3.The Architecture!!!"></a>3.The Architecture!!!</h3><h4 id="1-ReLU-Nonlinearity"><a href="#1-ReLU-Nonlinearity" class="headerlink" title="1.ReLU Nonlinearity"></a>1.ReLU Nonlinearity</h4><p>why we use ReLU instead of sigmoid or tanh function?<br><code>In terms of training time
with gradient descent, these saturating nonlinearities
are much slower than the non-saturating nonlinearity
f(x) = max(0, x).</code></p>
<blockquote>
<p>ps : 当我们使用ReLU函数而不是sigmoid或者tanh函数进行激活时，主要原因在于其更快的速度。当然，我们可以使用Leaky ReLU甚至Randomized Leaky ReLU来防止其它一些问题。还有一些其它的变体，包括PReLU和RReLU。</p>
</blockquote>
<h4 id="2-Training-on-Multiple-GPUs"><a href="#2-Training-on-Multiple-GPUs" class="headerlink" title="2.Training on Multiple GPUs"></a>2.Training on Multiple GPUs</h4><p><code>Current GPUs
are particularly well-suited to cross-GPU parallelization, as they are able to read from and write to
one another’s memory directly, without going through host machine memory.</code>using a method to parallel the training process.Notice the parallelization scheme that is employed in this paper, which are quite inspirsed. </p>
<blockquote>
<p>ps : 在利用多个GPU进行并行处理的时候，需要注意之间的信息传递与交互。如何提高数据之间传输的效率，是能够提高计算速度的关键。</p>
</blockquote>
<h4 id="3-Local-Response-Normalization"><a href="#3-Local-Response-Normalization" class="headerlink" title="3.Local Response Normalization"></a>3.Local Response Normalization</h4><p>using local normalization to aid generation.</p>
<script type="math/tex; mode=display">b_{x,y}^i=a_{x,y}^i/(k+\alpha \sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}(a_{x,y}^i)^2)^\beta</script><blockquote>
<p>ps : 这一小节主要讲解了这个normalization的方式，这个公式的结果展示出来的效果在于，提高泛化能力（即b能更好地代表一个连续性的结果）简单分析三个超参数,k为一个偏移量，使得本身有一个偏移；n在于考虑其连续的范围，考虑泛化能力，在于一个权衡，$<br>\beta$在于调整参数的大小，使得与模型契合。</p>
</blockquote>
<h4 id="4-Overlapping-Pooling"><a href="#4-Overlapping-Pooling" class="headerlink" title="4. Overlapping Pooling"></a>4. Overlapping Pooling</h4><p>using overlapping can make our pooling result more precise than non-overlapping.<code>We generally observe during training that models with overlapping
pooling find it slightly more difficult to overfit</code> </p>
<blockquote>
<p>ps : 我们应该注意一个overlapping 与 non-overlapping之间的平衡，建议是首先不用overlapping，如果得到的结果处于欠拟合状态，则修改而使用overlapping pooling</p>
</blockquote>
<h4 id="5-Overall-Architecture"><a href="#5-Overall-Architecture" class="headerlink" title="5. Overall Architecture"></a>5. Overall Architecture</h4><p>the overall architecture will be shown in figure 1 below.</p>
<blockquote>
<p>ps : 主要理解这个结构一些中间的部分，需要掌握对其的理解并且与前面的相贯通。</p>
</blockquote>
<h3 id="Reducing-Overfitting"><a href="#Reducing-Overfitting" class="headerlink" title="Reducing Overfitting"></a>Reducing Overfitting</h3><p>too many parameters in this model(60 million) are not insufficient to learn.</p>
<h4 id="1-Data-Augmentation"><a href="#1-Data-Augmentation" class="headerlink" title="1.Data Augmentation"></a>1.Data Augmentation</h4><ol>
<li><code>The first form of data augmentation consists of generating image translations and horizontal reflections.</code></li>
<li><code>The second form of data augmentation consists of altering the intensities of the RGB channels in
training images.</code>using PCA on the set.</li>
</ol>
<script type="math/tex; mode=display">[p1,p2,p3][\alpha_1 \lambda_1,\alpha_2 \lambda_2,\alpha_3 \lambda_3]^T</script><blockquote>
<p>ps: 由于原来的网络模型过深，所以需要避免过拟合，第一种方法就是增加数据量，可以通过对图像的一些处理来进行，包括进行图像的裁剪和对颜色进行处理。</p>
</blockquote>
<h4 id="2-Dropout"><a href="#2-Dropout" class="headerlink" title="2.Dropout"></a>2.Dropout</h4><p>dropout 是一个重要的内容，我在附加的部分主要说明，这里就直接跳过。这里也只是运用了这种方法，没有做什么修改。</p>
<h3 id="5-Details-of-learning"><a href="#5-Details-of-learning" class="headerlink" title="5.Details of learning"></a>5.Details of learning</h3><p><code>We trained our models using stochastic gradient descent
with a batch size of 128 examples, momentum of 0.9, and
weight decay of 0.0005.</code></p>
<p><code>the update relu for weight w was</code>:</p>
<script type="math/tex; mode=display">v_{i+1} := 0.9v_i-0.0005 \epsilon w_i - \epsilon <\frac{\partial L}{\partial w}|_{w_i}>_{D_i}</script><script type="math/tex; mode=display">w_{i+1} := w_i+v_{i+1}</script><h3 id="6-Results"><a href="#6-Results" class="headerlink" title="6.Results"></a>6.Results</h3><p>this part is not so necessary, you should look through the paper to learn the result.</p>
<h3 id="7-Discussion"><a href="#7-Discussion" class="headerlink" title="7.Discussion"></a>7.Discussion</h3><p><code>the depth really is important for achieving our results</code>.you can see that, from the discussion in this paper, deep network on image classfication have been aroused. </p>
<h3 id="my-conclusion"><a href="#my-conclusion" class="headerlink" title="my conclusion"></a>my conclusion</h3><p>这篇文章主要提出了AlexNet这种结构，其主要有几个主要的因素构成：</p>
<ol>
<li>使用两个GPU交互训练的网络</li>
<li>使用dropout方法进行正则化的方法</li>
<li>使用深层的深度网络进行学习（这是使用深度神经网络的一个重要的开端，它有后来的工作很大的启发作用）</li>
<li>使用data augmentation来进行数据的预处理，防止过拟合</li>
<li>使用了normalization方法来处理原来的数据，同时采用ReLU激活函数，使得整个计算过程更加快捷，且没有降低最终的效果。</li>
</ol>
<h3 id="发散"><a href="#发散" class="headerlink" title="发散"></a>发散</h3><h4 id="1-dropout"><a href="#1-dropout" class="headerlink" title="1. dropout"></a>1. dropout</h4><h4 id="2-深层的神经网络的问题及其解决"><a href="#2-深层的神经网络的问题及其解决" class="headerlink" title="2.深层的神经网络的问题及其解决"></a>2.深层的神经网络的问题及其解决</h4>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/04/28/recording2/" data-id="ck0z6d1pd0013p8tqn5ii59kc" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paperReading/">paperReading</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-reading1" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/28/reading1/" class="article-date">
  <time datetime="2019-04-28T10:59:18.000Z" itemprop="datePublished">2019-04-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/28/reading1/">BTS-DSN</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Paper-Reading"><a href="#Paper-Reading" class="headerlink" title="Paper Reading"></a>Paper Reading</h1><h2 id="BTS-DSN-Deeply-supervised-neural-network-with-short-connections-forretinal-vessel-segmentation"><a href="#BTS-DSN-Deeply-supervised-neural-network-with-short-connections-forretinal-vessel-segmentation" class="headerlink" title="BTS-DSN: Deeply supervised neural network with short connections forretinal vessel segmentation"></a>BTS-DSN: Deeply supervised neural network with short connections forretinal vessel segmentation</h2><hr>
<blockquote>
<p><code>references</code>: you can read this papar via <a href="https://linkinghub.elsevier.com/retrieve/pii/S138650561831195X" target="_blank" rel="noopener">BTS-DSN</a> or star/fork this github <a href="https://github.com/guomugong/BTS-DSN" target="_blank" rel="noopener">project</a></p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><ol>
<li>An important method was proposed by this group called short-connection, that improve quite a lot the result of this model’s ability. They use sensitivity,specificity, AUC and F1-score to test their model. If you aren’t familiar with these indicators, you can read these two blogs to learn more<a href="https://tracholar.github.io/machine-learning/2018/01/26/auc.html" target="_blank" rel="noopener">AUC</a>  &amp;<a href="https://blog.csdn.net/u013385925/article/details/80385873" target="_blank" rel="noopener">AUC-2</a>. </li>
</ol>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><ol>
<li>why we hope to achieve early dignosis.</li>
<li>some researchs done by other scholar group<blockquote>
<p>(1) Unsupervised methods: some methods have been proposed by scholoars, mainly about detect the profile and contour of vessel. These methods are mostly based on geometric computation model. defects: <code>However, the unsupervised methods are sensitive to the
manually designed features and rules.</code>(poor in generalization)</p>
</blockquote>
</li>
</ol>
<blockquote>
<p>(2)supervised methods:when we use supervised method, we usually view this problem as a pixel-wise binary classification. deep learning methods are popular in this area. Other ways to solve this problem about semantic segmentation results. <code>defects:different methods have different disadvantages such as time-consuming and so on</code></p>
</blockquote>
<ol>
<li>the contributions of this paper<blockquote>
<p>(1)”We propose a deeply-supervised fully convolutional neural network with bottom-top and top-bottom short connections (BTS-DSN) for vessel segmentation. “</p>
</blockquote>
</li>
</ol>
<blockquote>
<p>(2)”We used VGGNet and ResNet-101 as backbone and conducted extensive experiments on DRIVE, STARE and CHASE_DB1”</p>
<p>“We employed cross-training experiments to show the generalization of BTS-DSN.”</p>
</blockquote>
<p>attributes : more about VGGNet and ResNet can be found in their papers.{<a href="https://github.com/machrisaa/tensorflow-vgg" target="_blank" rel="noopener">vgg(including vgg-16&amp;vgg-19)</a>&amp;<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">ResNet_paper</a>&amp;<a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py" target="_blank" rel="noopener">ResNet_github</a>}.If you want to understand these model better, baidu or google it may help you.</p>
<h3 id="2-BTS-DSN"><a href="#2-BTS-DSN" class="headerlink" title="2.BTS-DSN"></a>2.BTS-DSN</h3><ol>
<li><p>from HED to DSN, and then to BS-DSN and BST-DSN. this method was proposed to alleviate the gradient vanish problem in deep network. It’s a deep supervision</p>
</li>
<li><p>bottom-top short connnections: pass low level fine semantic information to high levels to alleviate the blurring situation.</p>
</li>
<li><p>top-bottom short connection: Bottom-top short connections aim to refine high-level segmentation results.</p>
</li>
<li><p>inference: do feature confusion</p>
</li>
</ol>
<h3 id="3-Implementation-details"><a href="#3-Implementation-details" class="headerlink" title="3. Implementation details"></a>3. Implementation details</h3><ol>
<li><p>data augmentation: using quite a lot various transformations to augment the training set, including rotation, flipping and scaling. </p>
</li>
<li><p>model implementation : using the network framework Caffe, short connections of the BTS-DSN. </p>
</li>
<li><p>Parameter settings</p>
</li>
</ol>
<p><code>When the backbone is VGGNet, we fine-tuned our network with a
learning rate of 1e-8, a weight decay of 0.0005, and a momentum of
0.9. We use a fixed learning rate.</code></p>
<p>in two different backbone(VGGNet &amp; ResNet-101),they use different type of parameters . </p>
<p>and for patch-level S-DSN, they split a raw retinal image into 9 patches, each of which was 1/4 the size of the raw image, meanwhile, patches were up-sampled $2 \times$ </p>
<p>4.running environment:……</p>
<h4 id="Evaluation-criteria"><a href="#Evaluation-criteria" class="headerlink" title="Evaluation criteria"></a>Evaluation criteria</h4><p><code>In vessel segmentation, each pixel belongs to a vessel or non-vessel
pixel.</code>(be seen as a binary classfication problem).they iemployed six evaluation criteria, including AUC,SE,SP,ACC,F1-score and MCC.</p>
<h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><p>the result are shown in the fig in this paper, so you can just look through and get them.</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>这篇文章成功实现了目前基本上是最高水平的眼底血管分类成果，其使用VGGNet或者ResNet-101作为支柱(backbone)来实现整个CNN卷积的过程，同时，为了缓解语义分割中语义分割之间的差距，使用top-bottom 和 bottom-top short connection来实现整个过程，最终实现了BTS-DSN网络，达到了好的效果。同时，这个网络也使用了特征融合的方法，可以加以了解。对于更多的细节，还需要继续了解。</p>
<h3 id="发散"><a href="#发散" class="headerlink" title="发散"></a>发散</h3><h4 id="（采样方法）上采样与下采样"><a href="#（采样方法）上采样与下采样" class="headerlink" title="（采样方法）上采样与下采样"></a>（采样方法）上采样与下采样</h4><h4 id="短连接与ResNet连接方式的不同"><a href="#短连接与ResNet连接方式的不同" class="headerlink" title="短连接与ResNet连接方式的不同"></a>短连接与ResNet连接方式的不同</h4><h4 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h4>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/04/28/reading1/" data-id="ck0z6d1pb0011p8tq0n3zn62a" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paperReading/">paperReading</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-龙芯杯6" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/23/龙芯杯6/" class="article-date">
  <time datetime="2019-04-23T11:31:25.000Z" itemprop="datePublished">2019-04-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/23/龙芯杯6/">龙芯杯备战4</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="龙芯杯备战4"><a href="#龙芯杯备战4" class="headerlink" title="龙芯杯备战4"></a>龙芯杯备战4</h1><h2 id="国科大试验系统迁移-LAB3-1"><a href="#国科大试验系统迁移-LAB3-1" class="headerlink" title="国科大试验系统迁移  LAB3-1"></a>国科大试验系统迁移  LAB3-1</h2><h3 id="代码对比"><a href="#代码对比" class="headerlink" title="代码对比"></a>代码对比</h3><h4 id="1-接口"><a href="#1-接口" class="headerlink" title="1.接口"></a>1.接口</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//机组cpu</span></span><br><span class="line"><span class="keyword">module</span> pipeline_cpu(  </span><br><span class="line">    <span class="keyword">input</span> clk,           </span><br><span class="line">    <span class="keyword">input</span> resetn,       </span><br><span class="line">    </span><br><span class="line">    <span class="comment">//display data</span></span><br><span class="line">    <span class="keyword">input</span>  [ <span class="number">4</span>:<span class="number">0</span>] rf_addr,<span class="comment">//regfile 的测试地址（用于测试regfile)</span></span><br><span class="line">    <span class="keyword">input</span>  [<span class="number">31</span>:<span class="number">0</span>] mem_addr,<span class="comment">//memory的地址，用于取出数据</span></span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] rf_data,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] mem_data,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] IF_pc,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] IF_inst,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] ID_pc,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] EXE_pc,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] MEM_pc,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] WB_pc,</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//最后需要用来检测的数据（检测5级的valid信号以及wb的数据)</span></span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] cpu_5_valid,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] HI_data,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] LO_data</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//国科大 CPU</span></span><br><span class="line"><span class="keyword">module</span> mycpu_top(</span><br><span class="line">	<span class="keyword">input</span>         clk,<span class="comment">//时钟</span></span><br><span class="line">	<span class="keyword">input</span>         resetn,<span class="comment">//复位信号</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//ram  指令</span></span><br><span class="line">	<span class="keyword">input</span> [<span class="number">31</span>:<span class="number">0</span>]  inst_sram_rdata,<span class="comment">//ram 读数据  -&gt; inst(所得到的指令)</span></span><br><span class="line">	<span class="keyword">output</span>        inst_sram_en,<span class="comment">//ram 使能信号   (需要自己添加这一信号的赋值)    ----&gt;还未修改</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">3</span>:<span class="number">0</span>]  inst_sram_wen,<span class="comment">//ram 字节写使能信号 (在机组的流水线中，并未实现)  ---&gt; 还未修改</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] inst_sram_addr,<span class="comment">//ram 读写地址，字节寻址  -&gt; pc  (inst_addr)   </span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] inst_sram_wdata,<span class="comment">//ram 写数据  (所需要修改的数据指令)    ---&gt; 还未修改</span></span><br><span class="line"><span class="comment">//ram  数据    -&gt;类似于inst_sram   可以直接在mem.v阶段使用</span></span><br><span class="line">	<span class="keyword">input</span> [<span class="number">31</span>:<span class="number">0</span>]  data_sram_rdata,<span class="comment">//ram 读数据</span></span><br><span class="line">	<span class="keyword">output</span>        data_sram_en,<span class="comment">//ram 使能信号，高电平有效    ----&gt; 还未修改</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">3</span>:<span class="number">0</span>]  data_sram_wen,<span class="comment">//ram 字节写使能信号</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] data_sram_addr,<span class="comment">//ram 读写地址</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] data_sram_wdata,<span class="comment">//ram 写数据 </span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] debug_wb_pc,<span class="comment">//wb级的PC，因而需要mycpu 的PC 一路带到写回级</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">3</span>:<span class="number">0</span>]  debug_wb_rf_wen,<span class="comment">// 写回级写寄存器堆(regfiles) 的写使能，为字节写使能</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">4</span>:<span class="number">0</span>]  debug_wb_rf_wnum,<span class="comment">// 写回级写regfiles的目的寄存器号</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] debug_wb_rf_wdata<span class="comment">// 写回级写regfiles的写数据</span></span><br><span class="line">	);</span><br></pre></td></tr></table></figure>
<h4 id="2-regfile"><a href="#2-regfile" class="headerlink" title="2.regfile"></a>2.regfile</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//regilfe 中原机组代码有test，但是由于在修改后的cpu后没有test的input信号，所以修改后直接删除就好</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">timescale</span> 1ns / 1ps</span></span><br><span class="line"><span class="comment">//*************************************************************************</span></span><br><span class="line"><span class="comment">//  LOONGSON</span></span><br><span class="line"><span class="comment">//  2016-04-14</span></span><br><span class="line"><span class="comment">//*************************************************************************</span></span><br><span class="line"><span class="keyword">module</span> regfile(</span><br><span class="line">    <span class="keyword">input</span>             clk,</span><br><span class="line">    <span class="keyword">input</span>             wen,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">4</span> :<span class="number">0</span>] raddr1,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">4</span> :<span class="number">0</span>] raddr2,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">4</span> :<span class="number">0</span>] waddr,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">31</span>:<span class="number">0</span>] wdata,</span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>] rdata1,</span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>] rdata2,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">4</span> :<span class="number">0</span>] test_addr,</span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>] test_data</span><br><span class="line">    );</span><br><span class="line">    <span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>] rf[<span class="number">31</span>:<span class="number">0</span>];</span><br><span class="line">     </span><br><span class="line">    <span class="comment">// three ported register file</span></span><br><span class="line">    <span class="comment">// read two ports combinationally</span></span><br><span class="line">    <span class="comment">// write third port on rising edge of clock</span></span><br><span class="line">    <span class="comment">// register 0 hardwired to 0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">always</span> @(<span class="keyword">posedge</span> clk)</span><br><span class="line">    <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">if</span> (wen) </span><br><span class="line">        <span class="keyword">begin</span></span><br><span class="line">            rf[waddr] &lt;= wdata;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">     </span><br><span class="line">    <span class="keyword">always</span> @(*)</span><br><span class="line">    <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">case</span> (raddr1)</span><br><span class="line">            <span class="number">5'd1</span> : rdata1 &lt;= rf[<span class="number">1</span> ];</span><br><span class="line">            <span class="number">5'd2</span> : rdata1 &lt;= rf[<span class="number">2</span> ];</span><br><span class="line">            <span class="number">5'd3</span> : rdata1 &lt;= rf[<span class="number">3</span> ];</span><br><span class="line">            <span class="number">5'd4</span> : rdata1 &lt;= rf[<span class="number">4</span> ];</span><br><span class="line">            <span class="number">5'd5</span> : rdata1 &lt;= rf[<span class="number">5</span> ];</span><br><span class="line">            <span class="number">5'd6</span> : rdata1 &lt;= rf[<span class="number">6</span> ];</span><br><span class="line">            <span class="number">5'd7</span> : rdata1 &lt;= rf[<span class="number">7</span> ];</span><br><span class="line">            <span class="number">5'd8</span> : rdata1 &lt;= rf[<span class="number">8</span> ];</span><br><span class="line">            <span class="number">5'd9</span> : rdata1 &lt;= rf[<span class="number">9</span> ];</span><br><span class="line">            <span class="number">5'd10</span>: rdata1 &lt;= rf[<span class="number">10</span>];</span><br><span class="line">            <span class="number">5'd11</span>: rdata1 &lt;= rf[<span class="number">11</span>];</span><br><span class="line">            <span class="number">5'd12</span>: rdata1 &lt;= rf[<span class="number">12</span>];</span><br><span class="line">            <span class="number">5'd13</span>: rdata1 &lt;= rf[<span class="number">13</span>];</span><br><span class="line">            <span class="number">5'd14</span>: rdata1 &lt;= rf[<span class="number">14</span>];</span><br><span class="line">            <span class="number">5'd15</span>: rdata1 &lt;= rf[<span class="number">15</span>];</span><br><span class="line">            <span class="number">5'd16</span>: rdata1 &lt;= rf[<span class="number">16</span>];</span><br><span class="line">            <span class="number">5'd17</span>: rdata1 &lt;= rf[<span class="number">17</span>];</span><br><span class="line">            <span class="number">5'd18</span>: rdata1 &lt;= rf[<span class="number">18</span>];</span><br><span class="line">            <span class="number">5'd19</span>: rdata1 &lt;= rf[<span class="number">19</span>];</span><br><span class="line">            <span class="number">5'd20</span>: rdata1 &lt;= rf[<span class="number">20</span>];</span><br><span class="line">            <span class="number">5'd21</span>: rdata1 &lt;= rf[<span class="number">21</span>];</span><br><span class="line">            <span class="number">5'd22</span>: rdata1 &lt;= rf[<span class="number">22</span>];</span><br><span class="line">            <span class="number">5'd23</span>: rdata1 &lt;= rf[<span class="number">23</span>];</span><br><span class="line">            <span class="number">5'd24</span>: rdata1 &lt;= rf[<span class="number">24</span>];</span><br><span class="line">            <span class="number">5'd25</span>: rdata1 &lt;= rf[<span class="number">25</span>];</span><br><span class="line">            <span class="number">5'd26</span>: rdata1 &lt;= rf[<span class="number">26</span>];</span><br><span class="line">            <span class="number">5'd27</span>: rdata1 &lt;= rf[<span class="number">27</span>];</span><br><span class="line">            <span class="number">5'd28</span>: rdata1 &lt;= rf[<span class="number">28</span>];</span><br><span class="line">            <span class="number">5'd29</span>: rdata1 &lt;= rf[<span class="number">29</span>];</span><br><span class="line">            <span class="number">5'd30</span>: rdata1 &lt;= rf[<span class="number">30</span>];</span><br><span class="line">            <span class="number">5'd31</span>: rdata1 &lt;= rf[<span class="number">31</span>];</span><br><span class="line">            <span class="keyword">default</span> : rdata1 &lt;= <span class="number">32'd0</span>;</span><br><span class="line">        <span class="keyword">endcase</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">always</span> @(*)</span><br><span class="line">    <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">case</span> (raddr2)</span><br><span class="line">            <span class="number">5'd1</span> : rdata2 &lt;= rf[<span class="number">1</span> ];</span><br><span class="line">            <span class="number">5'd2</span> : rdata2 &lt;= rf[<span class="number">2</span> ];</span><br><span class="line">            <span class="number">5'd3</span> : rdata2 &lt;= rf[<span class="number">3</span> ];</span><br><span class="line">            <span class="number">5'd4</span> : rdata2 &lt;= rf[<span class="number">4</span> ];</span><br><span class="line">            <span class="number">5'd5</span> : rdata2 &lt;= rf[<span class="number">5</span> ];</span><br><span class="line">            <span class="number">5'd6</span> : rdata2 &lt;= rf[<span class="number">6</span> ];</span><br><span class="line">            <span class="number">5'd7</span> : rdata2 &lt;= rf[<span class="number">7</span> ];</span><br><span class="line">            <span class="number">5'd8</span> : rdata2 &lt;= rf[<span class="number">8</span> ];</span><br><span class="line">            <span class="number">5'd9</span> : rdata2 &lt;= rf[<span class="number">9</span> ];</span><br><span class="line">            <span class="number">5'd10</span>: rdata2 &lt;= rf[<span class="number">10</span>];</span><br><span class="line">            <span class="number">5'd11</span>: rdata2 &lt;= rf[<span class="number">11</span>];</span><br><span class="line">            <span class="number">5'd12</span>: rdata2 &lt;= rf[<span class="number">12</span>];</span><br><span class="line">            <span class="number">5'd13</span>: rdata2 &lt;= rf[<span class="number">13</span>];</span><br><span class="line">            <span class="number">5'd14</span>: rdata2 &lt;= rf[<span class="number">14</span>];</span><br><span class="line">            <span class="number">5'd15</span>: rdata2 &lt;= rf[<span class="number">15</span>];</span><br><span class="line">            <span class="number">5'd16</span>: rdata2 &lt;= rf[<span class="number">16</span>];</span><br><span class="line">            <span class="number">5'd17</span>: rdata2 &lt;= rf[<span class="number">17</span>];</span><br><span class="line">            <span class="number">5'd18</span>: rdata2 &lt;= rf[<span class="number">18</span>];</span><br><span class="line">            <span class="number">5'd19</span>: rdata2 &lt;= rf[<span class="number">19</span>];</span><br><span class="line">            <span class="number">5'd20</span>: rdata2 &lt;= rf[<span class="number">20</span>];</span><br><span class="line">            <span class="number">5'd21</span>: rdata2 &lt;= rf[<span class="number">21</span>];</span><br><span class="line">            <span class="number">5'd22</span>: rdata2 &lt;= rf[<span class="number">22</span>];</span><br><span class="line">            <span class="number">5'd23</span>: rdata2 &lt;= rf[<span class="number">23</span>];</span><br><span class="line">            <span class="number">5'd24</span>: rdata2 &lt;= rf[<span class="number">24</span>];</span><br><span class="line">            <span class="number">5'd25</span>: rdata2 &lt;= rf[<span class="number">25</span>];</span><br><span class="line">            <span class="number">5'd26</span>: rdata2 &lt;= rf[<span class="number">26</span>];</span><br><span class="line">            <span class="number">5'd27</span>: rdata2 &lt;= rf[<span class="number">27</span>];</span><br><span class="line">            <span class="number">5'd28</span>: rdata2 &lt;= rf[<span class="number">28</span>];</span><br><span class="line">            <span class="number">5'd29</span>: rdata2 &lt;= rf[<span class="number">29</span>];</span><br><span class="line">            <span class="number">5'd30</span>: rdata2 &lt;= rf[<span class="number">30</span>];</span><br><span class="line">            <span class="number">5'd31</span>: rdata2 &lt;= rf[<span class="number">31</span>];</span><br><span class="line">            <span class="keyword">default</span> : rdata2 &lt;= <span class="number">32'd0</span>;</span><br><span class="line">        <span class="keyword">endcase</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">always</span> @(*)</span><br><span class="line">    <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">case</span> (test_addr)</span><br><span class="line">            <span class="number">5'd1</span> : test_data &lt;= rf[<span class="number">1</span> ];</span><br><span class="line">            <span class="number">5'd2</span> : test_data &lt;= rf[<span class="number">2</span> ];</span><br><span class="line">            <span class="number">5'd3</span> : test_data &lt;= rf[<span class="number">3</span> ];</span><br><span class="line">            <span class="number">5'd4</span> : test_data &lt;= rf[<span class="number">4</span> ];</span><br><span class="line">            <span class="number">5'd5</span> : test_data &lt;= rf[<span class="number">5</span> ];</span><br><span class="line">            <span class="number">5'd6</span> : test_data &lt;= rf[<span class="number">6</span> ];</span><br><span class="line">            <span class="number">5'd7</span> : test_data &lt;= rf[<span class="number">7</span> ];</span><br><span class="line">            <span class="number">5'd8</span> : test_data &lt;= rf[<span class="number">8</span> ];</span><br><span class="line">            <span class="number">5'd9</span> : test_data &lt;= rf[<span class="number">9</span> ];</span><br><span class="line">            <span class="number">5'd10</span>: test_data &lt;= rf[<span class="number">10</span>];</span><br><span class="line">            <span class="number">5'd11</span>: test_data &lt;= rf[<span class="number">11</span>];</span><br><span class="line">            <span class="number">5'd12</span>: test_data &lt;= rf[<span class="number">12</span>];</span><br><span class="line">            <span class="number">5'd13</span>: test_data &lt;= rf[<span class="number">13</span>];</span><br><span class="line">            <span class="number">5'd14</span>: test_data &lt;= rf[<span class="number">14</span>];</span><br><span class="line">            <span class="number">5'd15</span>: test_data &lt;= rf[<span class="number">15</span>];</span><br><span class="line">            <span class="number">5'd16</span>: test_data &lt;= rf[<span class="number">16</span>];</span><br><span class="line">            <span class="number">5'd17</span>: test_data &lt;= rf[<span class="number">17</span>];</span><br><span class="line">            <span class="number">5'd18</span>: test_data &lt;= rf[<span class="number">18</span>];</span><br><span class="line">            <span class="number">5'd19</span>: test_data &lt;= rf[<span class="number">19</span>];</span><br><span class="line">            <span class="number">5'd20</span>: test_data &lt;= rf[<span class="number">20</span>];</span><br><span class="line">            <span class="number">5'd21</span>: test_data &lt;= rf[<span class="number">21</span>];</span><br><span class="line">            <span class="number">5'd22</span>: test_data &lt;= rf[<span class="number">22</span>];</span><br><span class="line">            <span class="number">5'd23</span>: test_data &lt;= rf[<span class="number">23</span>];</span><br><span class="line">            <span class="number">5'd24</span>: test_data &lt;= rf[<span class="number">24</span>];</span><br><span class="line">            <span class="number">5'd25</span>: test_data &lt;= rf[<span class="number">25</span>];</span><br><span class="line">            <span class="number">5'd26</span>: test_data &lt;= rf[<span class="number">26</span>];</span><br><span class="line">            <span class="number">5'd27</span>: test_data &lt;= rf[<span class="number">27</span>];</span><br><span class="line">            <span class="number">5'd28</span>: test_data &lt;= rf[<span class="number">28</span>];</span><br><span class="line">            <span class="number">5'd29</span>: test_data &lt;= rf[<span class="number">29</span>];</span><br><span class="line">            <span class="number">5'd30</span>: test_data &lt;= rf[<span class="number">30</span>];</span><br><span class="line">            <span class="number">5'd31</span>: test_data &lt;= rf[<span class="number">31</span>];</span><br><span class="line">            <span class="keyword">default</span> : test_data &lt;= <span class="number">32'd0</span>;</span><br><span class="line">        <span class="keyword">endcase</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure>
<h4 id="其它过程"><a href="#其它过程" class="headerlink" title="其它过程"></a>其它过程</h4><blockquote>
<p>对于整个迁移的其它过程，都主要是按照接口来做，没有什么特别的地方需要说明。</p>
<p>另外需要说明的一点是，在机组实现的流水线cpu中，是在整个cpu的总线中进行调用inst_sram和data_sram，而在国科大的lab中，由更高一层的soc_lite_top.v进行调用和控制，而my_cpu中只需要调用fetch,decode,exe,mem,wb以及regfile进行执行即可。</p>
</blockquote>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//*************************************************************************</span></span><br><span class="line"><span class="comment">//   &gt; File Name   : soc_top.v</span></span><br><span class="line"><span class="comment">//   &gt; Description : SoC, included cpu, 2 x 3 bridge,</span></span><br><span class="line"><span class="comment">//                   inst ram, confreg, data ram</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">//           -------------------------</span></span><br><span class="line"><span class="comment">//           |           cpu         |</span></span><br><span class="line"><span class="comment">//           -------------------------</span></span><br><span class="line"><span class="comment">//         inst|                  | data</span></span><br><span class="line"><span class="comment">//             |                  | </span></span><br><span class="line"><span class="comment">//             |        ---------------------</span></span><br><span class="line"><span class="comment">//             |        |    1 x 2 bridge   |</span></span><br><span class="line"><span class="comment">//             |        ---------------------</span></span><br><span class="line"><span class="comment">//             |             |            |           </span></span><br><span class="line"><span class="comment">//             |             |            |           </span></span><br><span class="line"><span class="comment">//      -------------   -----------   -----------</span></span><br><span class="line"><span class="comment">//      | inst ram  |   | data ram|   | confreg |</span></span><br><span class="line"><span class="comment">//      -------------   -----------   -----------</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//   &gt; Author      : LOONGSON</span></span><br><span class="line"><span class="comment">//   &gt; Date        : 2017-08-04</span></span><br><span class="line"><span class="comment">//*************************************************************************</span></span><br></pre></td></tr></table></figure>
<p>其主要框架如图所示，需要更具体地进行了解</p>
<h4 id="IP核锁定解决方案"><a href="#IP核锁定解决方案" class="headerlink" title="IP核锁定解决方案"></a>IP核锁定解决方案</h4><blockquote>
<p>由于从旧的vivado版本迁移到新的版本中，会遇到IP核锁定的问题，所以我跑simulation的时候，发现跑不过，我开始以为是coe文件的问题，后来重新导入coe文件后，发现还是报错，于是我发现，是IP核锁定了。</p>
<p>首先查看网上的解决方案，在工具栏找到report-&gt;Report IP Status,然后发现没办法upgrade selected,这个时候点击右键，可以发现有UPGRADE IP的选项，果断选择，然后好像就OK了。容我跑一跑simulation(时间有点长，现在很慌~~)什么信息也不报一个</p>
</blockquote>
<h4 id="其它还需要修改的错误"><a href="#其它还需要修改的错误" class="headerlink" title="其它还需要修改的错误"></a>其它还需要修改的错误</h4><p>wb端实际上还需要修改，同时，并没有将所有需要的output实现，目前还有很多X与Z的存在，需要进一步修改其中的代码。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/04/23/龙芯杯6/" data-id="ck0z6d1qj0025p8tq8f6zch7e" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/computer-system/">computer_system</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ma_model_pre5" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/28/ma_model_pre5/" class="article-date">
  <time datetime="2019-03-28T13:31:55.000Z" itemprop="datePublished">2019-03-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/28/ma_model_pre5/">ma_model_preparation5</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><p>关于SVM的内容介绍，主要参考了这位博主的SVM文章<a href="http://www.blogjava.net/zhenandaci/category/31868.html" target="_blank" rel="noopener">点击此处进行查看</a>（讲得太好了）</p>
<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h2><p>支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中.</p>
<p>支持向量机方法是建立在统计学习理论的VC维理论和结构风险最小原理基础上的，根据有限的样本信息在模型的复杂性（即对特定训练样本的学习精度，Accuracy）和学习能力（即无错误地识别任意样本的能力）之间寻求最佳折衷，以期获得最好的推广能力（泛化能力）<br>所谓VC维是对函数类的一种度量，可以简单的理解为问题的复杂程度，VC维越高，一个问题就越复杂。正是因为SVM关注的是VC维，后面我们可以看到，SVM解决问题的时候，和样本的维数是无关的（甚至样本是上万维的都可以，这使得SVM很适合用来解决文本分类的问题，当然，有这样的能力也因为引入了核函数）。</p>
<p>与问题真实解之间的误差，就叫做风险（更严格的说，误差的累积叫做风险）。统计学习因此而引入了泛化误差界的概念，就是指真实风险应该由两部分内容刻画，一是经验风险，代表了分类器在给定样本上的误差；二是置信风险，代表了我们在多大程度上可以信任分类器在未知文本上分类的结果。很显然，第二部分是没有办法精确计算的，因此只能给出一个估计的区间，也使得整个误差只能计算上界，而无法计算准确的值（所以叫做泛化误差界，而不叫泛化误差）。置信风险与两个量有关，一是样本数量，显然给定的样本数量越大，我们的学习结果越有可能正确，此时置信风险越小；二是分类函数的VC维，显然VC维越大，推广能力越差，置信风险会变大。<br>SVM 有如下的优点</p>
<blockquote>
<p>小样本  非线性  高维模式识别</p>
</blockquote>
<h2 id="2-数学定义"><a href="#2-数学定义" class="headerlink" title="2.数学定义"></a>2.数学定义</h2><h3 id="考虑线性分类器"><a href="#考虑线性分类器" class="headerlink" title="考虑线性分类器"></a>考虑线性分类器</h3><blockquote>
<p>假设线性分类函数 g(x)=wx+b ，当然，其中w,x,b 均为高维向量，那么，不妨假设以g(x)=0为分界面，对于每个$x_i$而言，即有$y_i=sign(g(x_i))$,那么$y_i$要么为1，要么为-1，如此，定义$\sigma_i =\frac{y_i*g(x_i)}{||w||_2}$ ,因此，实际上$\sigma = \sum_{i=1}^n {\sigma_i}$为所有的距离之和,因而，我们找到一个最好的分类的目标变为$min ||w||$,为了在后续过程中使得我们的计算简单，我们将目标函数变为</p>
</blockquote>
<script type="math/tex; mode=display">min  \frac{1}{2}||w||^2</script><blockquote>
<p>但如若着这样，会存在一个问题，即分类的结果都会存在于两个分类器的中间地带，那么这样会导致$||w||=0$实际上不是我们需要的值，故在此基础上，我们还需要加上约束条件$y_i*g(x_i)&gt;=1(i=1,2,\ldots,n)$ 故，最终结果表示为</p>
</blockquote>
<script type="math/tex; mode=display">min \quad  \frac{1}{2}||w||^2</script><script type="math/tex; mode=display">subject\quad to: \quad y_i*g(x_i)-1>=0 \,\,(i=1,2,\ldots,n)</script><blockquote>
<p>实际上，这里的问题变为了一个凸优化问题，同时也是一个二次规划问题。我们知道，这样一个凸的规划问题，完全可以求得最优解，故我们的问题能够得到实际上的解决。那么需要怎么解决呢？</p>
</blockquote>
<h2 id="3-问题解决"><a href="#3-问题解决" class="headerlink" title="3.问题解决"></a>3.问题解决</h2><blockquote>
<p>实际上，我们求解的目标就是w，因为求得了w之后，可以求得b，则最终可以求到我们想要得到的g(x)这个函数，也就是分界面。而实际上，w与样本有关，那么我们可以定义$w=a_1x_1+a_2x_2+\ldots+a_nx_n$ 其中$a$为拉格朗日乘子，那么再次回顾$g(x)=\vec{w} \cdot \vec{x} +\vec{b}$,再次分析$\vec{w}$ 的表达式，我们可以发现，依然有错误，实际上，w还与y有关，故，我们可以将w这样表示</p>
</blockquote>
<script type="math/tex; mode=display">\vec{w}=\sum_{i=1}^n{(a_iy_ix_i)}</script><blockquote>
<p>因此 $g(x) =<w,x> +b= \sum_{i=1}^n{(a_iy_i<x_i,x>)}+b$,因此我们可以看到，我们实际上把w给消掉了，没有了w，实际上也减少了很多约束条件，接下来，我们将开始很重要的一个介绍，核函数</x_i,x></w,x></p>
</blockquote>
<h2 id="4-核函数"><a href="#4-核函数" class="headerlink" title="4.核函数"></a>4.核函数</h2><blockquote>
<p>一个解决线性不可分问题的基本思路————向高维空间转化，使其变得线性可分（一个二维空间中的问题，当映射到四维空间中的时候，就变得线性可分了），然而于此同时，也出现了很多问题，例如对于一个文本分类问题，将其映射到上万维的空间中，依旧是线性不可分的，然而，对于高维空间的计算，需要耗费大量的计算资源，因此，这就带来了不可计算的问题（这是实际工程中的一个重要的问题）</p>
<p>因此我们的目标已经明确了，找到一种能够映射到很高维的方法（要是能到无穷维就更好了！），并且能保证其在有限时间中可计算（如果能与没有升维之前有同样的计算阶那就再好不过了，即是线性的）。因此我们幻想，是否能有这样一种函数K(w,x),他接受低维空间的输入值，却能算出高维空间的内积值<w’,x’>。我们不妨假设这个函数为核函数K，那么即有</w’,x’></p>
</blockquote>
<script type="math/tex; mode=display">g(x)=K(w,x)+b\\
f(x')=<w',x'>+b</script><blockquote>
<p>这两个函数完全相等。因此，我们的目标变为了对非线性的分类问题，有$g(x)=\sum_{i=1}^n a_iy_i<x_i',x'>+b$<br>那么核函数(kernel)存在吗？万幸的是，这样的K(w,x)确实存在（发现凡是我们人类能解决的问题，大都是巧得不能再巧，特殊得不能再特殊的问题，总是恰好有些能投机取巧的地方才能解决，由此感到人类的渺小），它被称作核函数（核，kernel），而且还不止一个，事实上，只要是满足了Mercer条件的函数，都可以作为核函数。核函数的基本作用就是接受两个低维空间里的向量，能够计算出经过某个变换后在高维空间里的向量内积值。<br>常用的核函数有哪些呢？这里可以直接参考这一篇<a href="https://blog.csdn.net/batuwuhanpei/article/details/52354822" target="_blank" rel="noopener">blog</a>，常用的核函数有四个，分别为线性核函数,多项式核函数，高斯(RBF)核函数与sigmoid核函数,对于其的比较，我在这里就不区分了，在实践中，多用，就能更好地理解这几个核函数的区别。</x_i',x'></p>
</blockquote>
<h2 id="5-其它问题"><a href="#5-其它问题" class="headerlink" title="5.其它问题"></a>5.其它问题</h2><blockquote>
<p>我们必须再次思考其它的问题，即如果使用核函数向高维空间映射后，问题仍然是线性不可分的，那怎么办？</p>
<p>这一问题实际上我们可以理解为噪声问题，在实际过程中，我们所采集到的数据通常都会有噪声，那么，噪声会改变我们本来正确的分类结果，对程序而言，会导致一种情况，即我们无法对这样的数据，甚至映射到高维空间中后，也线性不可分。那么如何抑制此现象的产生呢？这实际上与我们之前提出的思路有极大的关联，即我们之前给出定义为</p>
</blockquote>
<script type="math/tex; mode=display">y_i[(wx_i)+b]>=1\quad(i=1,2,\ldots,n)</script><blockquote>
<p>这实际上要求了所有的点，均必须满足这一条件，那么这会导致不可分（纵然在极高维的空间中，或许它也可分，但所分出来的结果必然是过拟合的，而不是我们想要的），所以我们模仿人类的思想，只保证绝大多数分类正确，因此,我们给这个阈值加上一个松弛变量，使得原式变为：</p>
</blockquote>
<script type="math/tex; mode=display">y_i[(wx_i)+b]>=1-\zeta_i \quad (i=1,2,\ldots,n)</script><blockquote>
<p>在此基础上，我们的优化问题的目标有所改变</p>
</blockquote>
<script type="math/tex; mode=display">min \quad \frac{1}{2}||w||^2+C\sum_{i=1}^n{\zeta_i}\\
subject \quad to \quad y_i[(wx_i)+b]\geq 1-\zeta_i \quad(i=1,2,\ldots,n)\\
 \zeta_i\geq0</script><blockquote>
<p>其中，C是一个超参数，建议设一组值来进行尝试。这里在具体对C进行一个讨论，C是一个固定参数，对此可以这样理解，如果C设置得较大，则说明我们很care那些被丢弃掉的点，如果我们不care那些点的话，我们则可以将C设置得小一点，同时，我们也能对不同的点设置不同的C，那么，则代表我们对某些点有特殊的偏好,这被称作数据集偏斜。对于特定的问题，读者应该对C的设置有不同的思考，要把握C的实质内容。</p>
</blockquote>
<h2 id="6-将SVM用于多类分类"><a href="#6-将SVM用于多类分类" class="headerlink" title="6. 将SVM用于多类分类"></a>6. 将SVM用于多类分类</h2><blockquote>
<p>我们实际上可以将一个多分类问题，看做一个”一类对其余“的问题，那么每次仍然是解一个两类分类的问题。比如我们有5个类别，第一次就把类别1的样本定为正样本，其余2，3，4，5的样本合起来定为负样本，这样得到一个两类分类器，它能够指出一篇文章是还是不是第1类的；第二次我们把类别2 的样本定为正样本，把1，3，4，5的样本合起来定为负样本，得到一个分类器，如此下去，我们可以得到5个这样的两类分类器（总是和类别的数目一致）。到了有文章需要分类的时候，我们就拿着这篇文章挨个分类器的问：是属于你的么？是属于你的么？哪个分类器点头说是了，文章的类别就确定了。这种方法的好处是每个优化问题的规模比较小，而且分类的时候速度很快（只需要调用5个分类器就知道了结果）。但有时也会出现两种很尴尬的情况，例如拿一篇文章问了一圈，每一个分类器都说它是属于它那一类的，或者每一个分类器都说它不是它那一类的，前者叫分类重叠现象，后者叫不可分类现象。分类重叠倒还好办，随便选一个结果都不至于太离谱，或者看看这篇文章到各个超平面的距离，哪个远就判给哪个。不可分类现象就着实难办了，只能把它分给第6个类别了……更要命的是，本来各个类别的样本数目是差不多的，但“其余”的那一类样本数总是要数倍于正类（因为它是除正类以外其他类别的样本之和嘛），这就人为的造成了上一节所说的“数据集偏斜”问题。<br>因此，这样一个思路看上去可行，但实际上也需要一定的调整才能对实际的多分类问题进行应用。那需要哪些改善呢？还是解两类分类问题，还是每次选一个类的样本作正类样本，而负类样本则变成只选一个类（称为“一对一单挑”的方法，哦，不对，没有单挑，就是“一对一”的方法），这就避免了偏斜。但这样，会大量增加分类器的数量。<br>看来我们必须再退一步，在分类的时候下功夫，我们还是像一对一方法那样来训练，只是在对一篇文章进行分类之前，我们先按照下面图的样子来组织分类器（如你所见，这是一个有向无环图，因此这种方法也叫做DAG SVM）</p>
</blockquote>
<p><img src="https://github.com/leliyliu/ICM-MCM-preparation/blob/master/picture/clip_image002_thumb.gif?raw=true" alt="DAG SVM"></p>
<blockquote>
<p>这样在分类时,我们就可以先问分类器“1对5”（意思是它能够回答“是第1类还是第5类”），如果它回答5，我们就往左走，再问“2对5”这个分类器，如果它还说是“5”，我们就继续往左走，这样一直问下去，就可以得到分类结果。好处在哪？我们其实只调用了4个分类器（如果类别数是k，则只调用k-1个），分类速度飞快，且没有分类重叠和不可分类现象！缺点在哪？假如最一开始的分类器回答错误（明明是类别1的文章，它说成了5），那么后面的分类器是无论如何也无法纠正它的错误的（因为后面的分类器压根没有出现“1”这个类别标签），其实对下面每一层的分类器都存在这种错误向下累积的现象。</p>
<p>关于SMO算法的学习，在这里就不加以重点介绍，需要的可以参考<a href="https://www.cnblogs.com/bentuwuying/p/6444516.html" target="_blank" rel="noopener">SMO</a>这一篇博客</p>
</blockquote>
<h2 id="python-代码实现"><a href="#python-代码实现" class="headerlink" title="python 代码实现"></a>python 代码实现</h2><blockquote>
<p>在python中，scikit-learn是一个广泛使用的用于实现机器学习算法的库（也许后面我也会对这个库的使用方法作一系列的博客介绍），SVM算法可以在这个库中找到并用于实现。<br>这里的python实现借用了<a href="https://blog.csdn.net/u010665216/article/details/78382984" target="_blank" rel="noopener">blog</a>的实现方式，需要源码的也可以从中进行下载</p>
<p>sklearn中的SVC函数是基于libsvm实现的，所以在参数设置上有很多相似的地方。（PS: libsvm中的二次规划问题的解决算法是SMO）。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Import Library</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></span><br><span class="line"><span class="comment"># Create SVM classification object </span></span><br><span class="line">model = svm.svc(kernel=<span class="string">'linear'</span>, c=<span class="number">1</span>, gamma=<span class="number">1</span>) </span><br><span class="line"><span class="comment"># there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">model.score(X, y)</span><br><span class="line"><span class="comment">#Predict Output</span></span><br><span class="line">predicted= model.predict(x_test)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.svm.SVC(C=<span class="number">1.0</span>, kernel=<span class="string">'rbf'</span>, degree=<span class="number">3</span>, gamma=<span class="number">0.0</span>, coef0=<span class="number">0.0</span>, shrinking=<span class="keyword">True</span>, probability=<span class="keyword">False</span>,tol=<span class="number">0.001</span>, cache_size=<span class="number">200</span>, class_weight=<span class="keyword">None</span>, verbose=<span class="keyword">False</span>, max_iter=<span class="number">-1</span>, random_state=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里展示了sklearn.svm.SVC的主要的参数，其中C为我们设置的超参数，而kernel有多种选择，这里为’rbf’,即高斯核函数。除此之外，还可以选择’linear’:线性核函数 ‘poly’ 多项式核函数 ‘sigmoid’ sigmoid核函数 ‘precomputed’:核矩阵（precomputed表示自己提前计算好核函数矩阵，这时候算法内部就不再用核函数去计算核矩阵，而是直接用你给的核矩阵。）</p>
<p>degree: int型参数 默认为3这个参数只对多项式核函数有用，是指多项式核函数的阶数n如果给的核函数参数是其他核函数，则会自动忽略该参数。</p>
<p>gamma: float参数 默认为auto核函数系数，只对‘rbf’,‘poly’,‘sigmod’有效。如果gamma为auto，代表其值为样本特征数的倒数，即1/n_features.</p>
<p>coef0: float参数 默认为0.0。核函数中的独立项，只有对‘poly’和‘sigmod’核函数有用，是指其中的参数c</p>
<p>probability： bool参数 默认为False。是否启用概率估计。 这必须在调用fit()之前启用，并且会fit()方法速度变慢。</p>
</blockquote>
<p>还有其它的参数，都可以参照<a href="https://blog.csdn.net/github_39261590/article/details/75009069" target="_blank" rel="noopener">svm参数说明</a>进行学习，这里就不再具体说明。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/28/ma_model_pre5/" data-id="ck0z6d1q90021p8tqqzkv55rd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/math-model-preparation/">math_model_preparation</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ma_model_pre4" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/22/ma_model_pre4/" class="article-date">
  <time datetime="2019-03-22T01:12:32.000Z" itemprop="datePublished">2019-03-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/22/ma_model_pre4/">ma_model_preparation1</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="图与网络"><a href="#图与网络" class="headerlink" title="图与网络"></a>图与网络</h2><h3 id="basic-conception"><a href="#basic-conception" class="headerlink" title="basic conception"></a>basic conception</h3><pre><code>无向图 有向图 赋权图 有限图 简单图
完全图 二分图 子图 母图 顶点的度（入度，出度）
</code></pre><p>一个图称为<font color="blue">简单图(simple graph)</font>，如果它既没有环也没有两条边连接同一对顶点。</p>
<pre><code>邻接矩阵表示法  邻接链表表示法   弧表表示法   关联矩阵  星形表示法（前向和反向）
</code></pre><p><font color="0xffffff">弧表表示法</font>将图以弧表（arc list）的形式存储在计算机中。所谓图的弧表，也就是图的弧集合中的所有有序对。弧表表示法直接列出所有弧的起点和终点，共需2m个存储单元，因此当网络比较稀疏时比较方便。</p>
<p><font color="0xffffff">也就是说，在关联矩阵中，每行对应于图的一个节点，每列对应于图的一条弧。</font>如果一个节点是一条弧的起点，则关联矩阵中对应的元素为1；如果一个节点是一条弧的终点，则关联矩阵中对应的元素为−1；如果一个节点与一条弧不关联，则关联矩阵中对应的元素为 0。</p>
<pre><code>道路(walk) 迹(trail) 轨(path) 圈(cycle)
</code></pre><p>一个连通图的生成树很多,用 $\tau(G)$ 来表示图的生成树的个数，则有如下公式：</p>
<script type="math/tex; mode=display">\tau(K_n)=n^{n-2}</script><script type="math/tex; mode=display">\tau(G)=\tau(G-e)+\tau(G\cdot e)</script><h3 id="匹配问题"><a href="#匹配问题" class="headerlink" title="匹配问题"></a>匹配问题</h3><h4 id="1-几个定义"><a href="#1-几个定义" class="headerlink" title="1.几个定义"></a>1.几个定义</h4><p> 对集  匹配   完美对集    最大对集  交错轨  可增广轨</p>
<h4 id="2-定理"><a href="#2-定理" class="headerlink" title="2.定理:"></a>2.定理:</h4><p>(1)M是图G的最大对集当且仅当G中无M可增广轨</p>
<p>(2)G 为二分图， X与Y是顶点集的划分，G中存在把X中顶点皆许配的对集的充要条件是，∀S ⊂ X ，则|N(S)|≥|S|，其中N(S)是S中顶点的邻集。</p>
<blockquote>
<p>推论 若G是k次正则二分图（每个顶点皆K度的图），则G有完美对集</p>
</blockquote>
<h4 id="3-人员分派问题"><a href="#3-人员分派问题" class="headerlink" title="3.人员分派问题"></a>3.人员分派问题</h4><p>1.匈牙利算法：利用匈牙利算法可以直接解决人员分派问题，其思路非常简单，故在这里不做介绍。</p>
<p>2.-&gt;最优分派问题<br>这个问题的数学模型是：在人员分派问题的模型中，图 G 的每边加了权$w(x_i,y_j)&gt;=0$表示$x_i$干$y_j$ 工作的效益，求加权图G 上的权最大的完美对集。</p>
<p>解决这个问题可以参照<a href="http://vdisk.weibo.com/s/D8miedWz2uXT" target="_blank" rel="noopener">《数学建模算法与应用》（司守奎）</a>（P84）所给出的定义以及Kuhn-Munkres算法，其实质上是在匈牙利算法的进一步改善<br>如果想要对KM算法作深入的理解，可以参考这个<a href="https://blog.csdn.net/liu_y_r/article/details/79219405?utm_source=blogxgwz7" target="_blank" rel="noopener">blog</a></p>
<p>可行顶标$l$,对于任意弧,满足$e(x \rightarrow y)  都有 l_x+l_y\ge w_e$，后定义相等子图，其包含所有的点，但只包含满足$l_x+l_y=w_e$的所有弧$e(x \rightarrow y)$,这些弧已经是最大的弧，如果有完美匹配，那么可以得到最优分派。KM 算法仅仅只适用于找二分图最佳完美匹配，如果无完美匹配，那么算法很可能陷入死循环（如果不存在的边为 -INF 的话就不会，但正确性就无法保证了），对于这种情况要小心处理。</p>
<h4 id="4-Euler-图和Hamilton-图"><a href="#4-Euler-图和Hamilton-图" class="headerlink" title="4. Euler 图和Hamilton 图"></a>4. Euler 图和Hamilton 图</h4><p>1.基本概念</p>
<p>经过G 的每条边的迹叫做G 的Euler 迹；闭的Euler 迹叫做Euler 回路或E<br>回路；含Euler 回路的图叫做Euler 图。</p>
<p>定理<br>（i）G 是Euler 图的充分必要条件是G 连通且每顶点皆偶次。</p>
<p>（ ii ） G 是Euler 图的充分必要条件是G 连通且$G=\bigcup_{i=1}^dC_i,C_i$是圈，$E（C_i)\bigcap E(C_j)(i \neq j)$</p>
<p>（iii）G 中有Euler 迹的充要条件是G 连通且至多有两个奇次点。</p>
<p>包含G 的每个顶点的轨叫做Hamilton(哈密顿)轨；闭的Hamilton 轨叫做Hamilton 圈或H 圈；含Hamilton 圈的图叫做Hamilton 图。</p>
<p>Fleury 算法给出了求Euler 回路的算法</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/22/ma_model_pre4/" data-id="ck0z6d1p4000tp8tq4xxrrw7l" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/math-model-preparation/">math_model_preparation</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/English-learning/">English_learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MCM-ICM-preparation/">MCM/ICM preparation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Modern-Anglo-American-philosophy/">Modern Anglo-American philosophy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Philosophy-of-Science/">Philosophy of Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/computer-system/">computer_system</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github-git/">github/git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/math-model-preparation/">math_model_preparation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paperReading/">paperReading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paper-reading/">paper_reading</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/use-of-Colab-deep-learning/">use of Colab(deep learning)</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/English-learning/" style="font-size: 10px;">English_learning</a> <a href="/tags/MCM-ICM-preparation/" style="font-size: 12.5px;">MCM/ICM preparation</a> <a href="/tags/Modern-Anglo-American-philosophy/" style="font-size: 20px;">Modern Anglo-American philosophy</a> <a href="/tags/Philosophy-of-Science/" style="font-size: 10px;">Philosophy of Science</a> <a href="/tags/computer-system/" style="font-size: 17.5px;">computer_system</a> <a href="/tags/github-git/" style="font-size: 15px;">github/git</a> <a href="/tags/math-model-preparation/" style="font-size: 17.5px;">math_model_preparation</a> <a href="/tags/paperReading/" style="font-size: 12.5px;">paperReading</a> <a href="/tags/paper-reading/" style="font-size: 10px;">paper_reading</a> <a href="/tags/use-of-Colab-deep-learning/" style="font-size: 10px;">use of Colab(deep learning)</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/09/25/github-use-1/">github&amp;git</a>
          </li>
        
          <li>
            <a href="/2019/09/25/github&git/">github&amp;git</a>
          </li>
        
          <li>
            <a href="/2019/05/05/django-learning/">django_learning</a>
          </li>
        
          <li>
            <a href="/2019/05/05/paper-reading/">paper_reading</a>
          </li>
        
          <li>
            <a href="/2019/05/04/colab/">colab</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Leliyliu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>