<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="record">
<meta property="og:type" content="website">
<meta property="og:title" content="禾声">
<meta property="og:url" content="http://leliyliu.github.io/index.html">
<meta property="og:site_name" content="禾声">
<meta property="og:description" content="record">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="禾声">
<meta name="twitter:description" content="record">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://leliyliu.github.io/">





  <title>禾声</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">禾声</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">in the arm of the angel, fly away</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2020/02/16/pytorch2/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/16/pytorch2/" itemprop="url">pytorch2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-16T19:59:51+08:00">
                2020-02-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="动手学深度学习-task2"><a href="#动手学深度学习-task2" class="headerlink" title="动手学深度学习 task2"></a>动手学深度学习 task2</h1><hr>
<h2 id="梯度消失、梯度爆炸"><a href="#梯度消失、梯度爆炸" class="headerlink" title="梯度消失、梯度爆炸"></a>梯度消失、梯度爆炸</h2><h2 id="机器翻译及相关技术"><a href="#机器翻译及相关技术" class="headerlink" title="机器翻译及相关技术"></a>机器翻译及相关技术</h2><p>机器翻译（MT）：将一段文本从一种语言自动翻译为另一种语言，用神经网络解决这个问题通常称为神经机器翻译（NMT）。 主要特征：输出是单词序列而不是单个单词。 输出序列的长度可能与源序列的长度不同。</p>
<h3 id="数据预处理过程"><a href="#数据预处理过程" class="headerlink" title="数据预处理过程"></a>数据预处理过程</h3><p>对于一般的数据预处理过程，首先要保证编码方式的正确。然后需要转换大小写，这里没有许多多余的处理操作。</p>
<h4 id="载入数据集"><a href="#载入数据集" class="headerlink" title="载入数据集"></a>载入数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pad</span><span class="params">(line, max_len, padding_token)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(line) &gt; max_len:</span><br><span class="line">        <span class="keyword">return</span> line[:max_len]</span><br><span class="line">    <span class="keyword">return</span> line + [padding_token] * (max_len - len(line))</span><br><span class="line">pad(src_vocab[source[<span class="number">0</span>]], <span class="number">10</span>, src_vocab.pad)</span><br></pre></td></tr></table></figure>
<p>这个pad 函数的作用在于保持每个句子的长度是一样的，如果是大于的话，那么就进行阶段，否则进行相应的补足。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_array</span><span class="params">(lines, vocab, max_len, is_source)</span>:</span></span><br><span class="line">    lines = [vocab[line] <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_source:</span><br><span class="line">        lines = [[vocab.bos] + line + [vocab.eos] <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    array = torch.tensor([pad(line, max_len, vocab.pad) <span class="keyword">for</span> line <span class="keyword">in</span> lines])</span><br><span class="line">    valid_len = (array != vocab.pad).sum(<span class="number">1</span>) <span class="comment">#第一个维度</span></span><br><span class="line">    <span class="keyword">return</span> array, valid_len</span><br></pre></td></tr></table></figure>
<p>注意这里关于有效长度的计算，也就是计算非补足的长度。</p>
<h3 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h3><p>其结构是如此表示的，即所有的可能是以这样一种方式显现出来</p>
<p><img src="https://cdn.kesci.com/upload/image/q5jcat3c8m.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<p>因为本身的RNN的网络结构不能保持具体的翻译过程中长度的变化，那么要达到这样的目标，使用了这样一种方式，即首先对输入进行了编码，然后进行解码后输出。</p>
<h4 id="Sequence-to-Sequence-模型"><a href="#Sequence-to-Sequence-模型" class="headerlink" title="Sequence to Sequence 模型"></a>Sequence to Sequence 模型</h4><p><img src="https://cdn.kesci.com/upload/image/q5jc7a53pt.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<p><img src="https://cdn.kesci.com/upload/image/q5jccjhkii.png?imageView2/0/w/500/h/500" alt="Image Name"></p>
<p>这里进行了相应的embedding，是将相应的输入转换为词向量来作为相应的输入。词向量的长度是相同的维度。</p>
<h4 id="训练模型和测试模型"><a href="#训练模型和测试模型" class="headerlink" title="训练模型和测试模型"></a>训练模型和测试模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch7</span><span class="params">(model, data_iter, lr, num_epochs, device)</span>:</span>  <span class="comment"># Saved in d2l</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=lr)</span><br><span class="line">    loss = MaskedSoftmaxCELoss()</span><br><span class="line">    tic = time.time()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, num_epochs+<span class="number">1</span>):</span><br><span class="line">        l_sum, num_tokens_sum = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> data_iter:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            X, X_vlen, Y, Y_vlen = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> batch]</span><br><span class="line">            Y_input, Y_label, Y_vlen = Y[:,:<span class="number">-1</span>], Y[:,<span class="number">1</span>:], Y_vlen<span class="number">-1</span></span><br><span class="line">            </span><br><span class="line">            Y_hat, _ = model(X, Y_input, X_vlen, Y_vlen)</span><br><span class="line">            l = loss(Y_hat, Y_label, Y_vlen).sum()</span><br><span class="line">            l.backward()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                d2l.grad_clipping_nn(model, <span class="number">5</span>, device)</span><br><span class="line">            num_tokens = Y_vlen.sum().item()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            l_sum += l.sum().item()</span><br><span class="line">            num_tokens_sum += num_tokens</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"epoch &#123;0:4d&#125;,loss &#123;1:.3f&#125;, time &#123;2:.1f&#125; sec"</span>.format( </span><br><span class="line">                  epoch, (l_sum/num_tokens_sum), time.time()-tic))</span><br><span class="line">            tic = time.time()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">translate_ch7</span><span class="params">(model, src_sentence, src_vocab, tgt_vocab, max_len, device)</span>:</span></span><br><span class="line">    src_tokens = src_vocab[src_sentence.lower().split(<span class="string">' '</span>)]</span><br><span class="line">    src_len = len(src_tokens)</span><br><span class="line">    <span class="keyword">if</span> src_len &lt; max_len:</span><br><span class="line">        src_tokens += [src_vocab.pad] * (max_len - src_len)</span><br><span class="line">    enc_X = torch.tensor(src_tokens, device=device)</span><br><span class="line">    enc_valid_length = torch.tensor([src_len], device=device)</span><br><span class="line">    <span class="comment"># use expand_dim to add the batch_size dimension.</span></span><br><span class="line">    enc_outputs = model.encoder(enc_X.unsqueeze(dim=<span class="number">0</span>), enc_valid_length)</span><br><span class="line">    dec_state = model.decoder.init_state(enc_outputs, enc_valid_length)</span><br><span class="line">    dec_X = torch.tensor([tgt_vocab.bos], device=device).unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">    predict_tokens = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(max_len):</span><br><span class="line">        Y, dec_state = model.decoder(dec_X, dec_state)</span><br><span class="line">        <span class="comment"># The token with highest score is used as the next time step input.</span></span><br><span class="line">        dec_X = Y.argmax(dim=<span class="number">2</span>)</span><br><span class="line">        py = dec_X.squeeze(dim=<span class="number">0</span>).int().item()</span><br><span class="line">        <span class="keyword">if</span> py == tgt_vocab.eos:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        predict_tokens.append(py)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">' '</span>.join(tgt_vocab.to_tokens(predict_tokens))</span><br></pre></td></tr></table></figure>
<h2 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h2><p><img src="https://cdn.kesci.com/upload/image/q5km4dwgf9.PNG?imageView2/0/w/960/h/960" alt="Image Name"></p>
<p>Attention 是一种通用的带权池化方法，输入由两部分构成：询问（query）和键值对（key-value pairs）。$𝐤_𝑖∈ℝ^{𝑑_𝑘}, 𝐯_𝑖∈ℝ^{𝑑_𝑣}$. Query  $𝐪∈ℝ^{𝑑_𝑞}$ , attention layer得到输出与value的维度一致 $𝐨∈ℝ^{𝑑_𝑣}$. 对于一个query来说，attention layer 会与每一个key计算注意力分数并进行权重的归一化，输出的向量$o$则是value的加权求和，而每个key计算的权重与value一一对应。</p>
<p>为了计算输出，我们首先假设有一个函数$\alpha$ 用于计算query和key的相似性，然后可以计算所有的 attention scores $a_1, \ldots, a_n$ by</p>
<script type="math/tex; mode=display">
a_i = \alpha(\mathbf q, \mathbf k_i).</script><p>我们使用<code>softmax</code>函数 获得注意力权重：</p>
<script type="math/tex; mode=display">
b_1, \ldots, b_n = \textrm{softmax}(a_1, \ldots, a_n).</script><p>最终的输出就是value的加权求和：</p>
<script type="math/tex; mode=display">
\mathbf o = \sum_{i=1}^n b_i \mathbf v_i.</script><h3 id="softmax-屏蔽"><a href="#softmax-屏蔽" class="headerlink" title="softmax 屏蔽"></a>softmax 屏蔽</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">masked_softmax</span><span class="params">(X, valid_length)</span>:</span></span><br><span class="line">    <span class="comment"># X: 3-D tensor, valid_length: 1-D or 2-D tensor</span></span><br><span class="line">    softmax = nn.Softmax(dim=<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> valid_length <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> softmax(X)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        shape = X.shape</span><br><span class="line">        <span class="keyword">if</span> valid_length.dim() == <span class="number">1</span>: </span><br><span class="line"><span class="comment">#如果是一维的话，表示没有考虑到有多个batch_size，那么需要进行考虑</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(valid_length.numpy().repeat(shape[<span class="number">1</span>], axis=<span class="number">0</span>))<span class="comment">#[2,2,3,3] 进行repeat 是指需要repeat了相应的步长维度给每个batch</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(valid_length.cpu().numpy().repeat(shape[<span class="number">1</span>], axis=<span class="number">0</span>))<span class="comment">#[2,2,3,3] 这里考虑了是在具体哪个device 上进行训练</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_length = valid_length.reshape((<span class="number">-1</span>,))</span><br><span class="line">        <span class="comment"># fill masked elements with a large negative, whose exp is 0</span></span><br><span class="line">        X = SequenceMask(X.reshape((<span class="number">-1</span>, shape[<span class="number">-1</span>])), valid_length)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> softmax(X).reshape(shape)</span><br></pre></td></tr></table></figure>
<p>这里的mask 的作用和上一节中实际上是一样的，由于每一句的长度是不同的，但是在进行训练的时候，我们需要保持每一句所展现出来的维度是相同的，故而对于缺少的，会进行相应的padding ,但是补足的部分不应该纳入<code>softmax</code>的计算当中。</p>
<h4 id="维度"><a href="#维度" class="headerlink" title="维度"></a>维度</h4><p>深度学习在自然语言处理方面进行应用的时候，维度是比较复杂的一个点，这里主要进行一下说明。</p>
<p>一般来说，输入的维度一般都包括了这样几个方面，batch_size ，步长，输入维度。对于语言而言，其本身的网络，不仅包括了原来的小批量训练时候的batch_size 和 本来一个语句的维度，同时还有一个时间维度。</p>
<p>例如在进行相应的mask的时候，可以参见上面的代码中所给出的注释的含义。</p>
<h4 id="高维矩阵相乘"><a href="#高维矩阵相乘" class="headerlink" title="高维矩阵相乘"></a>高维矩阵相乘</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.bmm(torch.ones((<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>), dtype = torch.float), torch.ones((<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>), dtype = torch.float)) <span class="comment">#两个矩阵乘法</span></span><br></pre></td></tr></table></figure>
<p><code>torch.bmm</code>是矩阵的乘法，对于高维矩阵，比如上面的代码所展示的那样，得到的shape = (2,1,2)</p>
<p>两个数组尺寸要求：</p>
<ul>
<li>“<strong>2维以上</strong>“的尺寸必须完全对应相等；</li>
<li>“<strong>2维</strong>“具有实际意义的单位，只要满足矩阵相乘的尺寸规律即可。</li>
</ul>
<h3 id="点积注意力"><a href="#点积注意力" class="headerlink" title="点积注意力"></a>点积注意力</h3><p>The dot product 假设query和keys有相同的维度, 即 $\forall i, 𝐪,𝐤_𝑖 ∈ ℝ_𝑑 $. 通过计算query和key转置的乘积来计算attention score,通常还会除去 $\sqrt{d}$ 减少计算出来的score对维度𝑑的依赖性，如下</p>
<script type="math/tex; mode=display">
𝛼(𝐪,𝐤)=⟨𝐪,𝐤⟩/ \sqrt{d}</script><p>假设 $ 𝐐∈ℝ^{𝑚×𝑑}$ 有 $m$ 个query，$𝐊∈ℝ^{𝑛×𝑑}$ 有 $n$ 个keys. 我们可以通过矩阵运算的方式计算所有 $mn$ 个score：</p>
<script type="math/tex; mode=display">
𝛼(𝐐,𝐊)=𝐐𝐊^𝑇/\sqrt{d}</script><p>现在让我们实现这个层，它支持一批查询和键值对。此外，它支持作为正则化随机删除一些注意力权重.</p>
<h3 id="多层感知机注意力"><a href="#多层感知机注意力" class="headerlink" title="多层感知机注意力"></a>多层感知机注意力</h3><p>在多层感知器中，我们首先将 query and keys 投影到  $ℝ^ℎ$ .为了更具体，我们将可以学习的参数做如下映射<br>$𝐖_𝑘∈ℝ^{ℎ×𝑑_𝑘}$ ,  $𝐖_𝑞∈ℝ^{ℎ×𝑑_𝑞}$ , and  $𝐯∈ℝ^h$ . 将score函数定义</p>
<script type="math/tex; mode=display">
𝛼(𝐤,𝐪)=𝐯^𝑇tanh(𝐖_𝑘𝐤+𝐖_𝑞𝐪)</script><p>.<br>然后将key 和 value 在特征的维度上合并（concatenate），然后送至 a single hidden layer perceptron 这层中 hidden layer 为  ℎ  and 输出的size为 1 .隐层激活函数为tanh，无偏置.</p>
<h3 id="引入注意力机制的Seq2seq模型"><a href="#引入注意力机制的Seq2seq模型" class="headerlink" title="引入注意力机制的Seq2seq模型"></a>引入注意力机制的Seq2seq模型</h3><p>将注意机制添加到sequence to sequence 模型中，以显式地使用权重聚合states。下图展示encoding 和decoding的模型结构，在时间步为t的时候。此刻attention layer保存着encodering看到的所有信息——即encoding的每一步输出。在decoding阶段，解码器的$t$时刻的隐藏状态被当作query，encoder的每个时间步的hidden states作为key和value进行attention聚合. Attetion model的输出当作成上下文信息context vector，并与解码器输入$D_t$拼接起来一起送到解码器：</p>
<p><img src="https://cdn.kesci.com/upload/image/q5km7o8z93.PNG?imageView2/0/w/800/h/800" alt="Image Name"></p>
<script type="math/tex; mode=display">
Fig1具有注意机制的seq-to-seq模型解码的第二步</script><p>下图展示了seq2seq机制的所有层的关系，下面展示了encoder和decoder的layer结构</p>
<p><img src="https://cdn.kesci.com/upload/image/q5km8dihlr.PNG?imageView2/0/w/800/h/800" alt="Image Name"></p>
<script type="math/tex; mode=display">
Fig2具有注意机制的seq-to-seq模型中层结构</script><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>在之前的章节中，我们已经介绍了主流的神经网络架构如卷积神经网络（CNNs）和循环神经网络（RNNs）。让我们进行一些回顾：</p>
<ul>
<li>CNNs 易于并行化，却不适合捕捉变长序列内的依赖关系。</li>
<li>RNNs 适合捕捉长距离变长序列的依赖，但是却难以实现并行化处理序列。</li>
</ul>
<p>为了整合CNN和RNN的优势，<a href="https://d2l.ai/chapter_references/zreferences.html#vaswani-shazeer-parmar-ea-2017" target="_blank" rel="noopener">[Vaswani et al., 2017]</a> 创新性地使用注意力机制设计了Transformer模型。该模型利用attention机制实现了并行化捕捉序列依赖，并且同时处理序列的每个位置的tokens，上述优势使得Transformer模型在性能优异的同时大大减少了训练时间。</p>
<p>图10.3.1展示了Transformer模型的架构，与seq2seq模型相似，Transformer同样基于编码器-解码器架构，其区别主要在于以下三点：</p>
<ol>
<li>Transformer blocks：将seq2seq模型重的循环网络替换为了Transformer Blocks，该模块包含一个多头注意力层（Multi-head Attention Layers）以及两个position-wise feed-forward networks（FFN）。对于解码器来说，另一个多头注意力层被用于接受编码器的隐藏状态。</li>
<li>Add and norm：多头注意力层和前馈网络的输出被送到两个“add and norm”层进行处理，该层包含残差结构以及层归一化。</li>
<li>Position encoding：由于自注意力层并没有区分元素的顺序，所以一个位置编码层被用于向序列元素里添加位置信息。</li>
</ol>
<p><img src="https://cdn.kesci.com/upload/image/q5kpbj2cj5.png?imageView2/0/w/960/h/960" alt="Fig. 10.3.1 The Transformer architecture."></p>
<script type="math/tex; mode=display">
Fig.10.3.1\ Transformer 架构.</script><h3 id="多头注意力层"><a href="#多头注意力层" class="headerlink" title="多头注意力层"></a>多头注意力层</h3><p>在我们讨论多头注意力层之前，先来迅速理解以下自注意力（self-attention）的结构。自注意力模型是一个正规的注意力模型，序列的每一个元素对应的key，value，query是完全一致的。如图10.3.2 自注意力输出了一个与输入长度相同的表征序列，与循环神经网络相比，自注意力对每个元素输出的计算是并行的，所以我们可以高效的实现这个模块。</p>
<p><img src="https://cdn.kesci.com/upload/image/q5kpckv38q.png?imageView2/0/w/320/h/320" alt="Fig. 10.3.2 自注意力结构"></p>
<script type="math/tex; mode=display">
Fig.10.3.2\ 自注意力结构</script><p>多头注意力层包含$h$个并行的自注意力层，每一个这种层被成为一个head。对每个头来说，在进行注意力计算之前，我们会将query、key和value用三个现行层进行映射，这$h$个注意力头的输出将会被拼接之后输入最后一个线性层进行整合。</p>
<p><img src="https://cdn.kesci.com/upload/image/q5kpcsozid.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<script type="math/tex; mode=display">
Fig.10.3.3\ 多头注意力</script><p>假设query，key和value的维度分别是$d_q$、$d_k$和$d_v$。那么对于每一个头$i=1,\ldots,h$，我们可以训练相应的模型权重$W_q^{(i)} \in \mathbb{R}^{p_q\times d_q}$、$W_k^{(i)} \in \mathbb{R}^{p_k\times d_k}$和$W_v^{(i)} \in \mathbb{R}^{p_v\times d_v}$，以得到每个头的输出：</p>
<script type="math/tex; mode=display">
o^{(i)} = attention(W_q^{(i)}q, W_k^{(i)}k, W_v^{(i)}v)</script><p>这里的attention可以是任意的attention function，比如前一节介绍的dot-product attention以及MLP attention。之后我们将所有head对应的输出拼接起来，送入最后一个线性层进行整合，这个层的权重可以表示为$W_o\in \mathbb{R}^{d_0 \times hp_v}$</p>
<script type="math/tex; mode=display">
o = W_o[o^{(1)}, \ldots, o^{(h)}]</script><p>接下来我们就可以来实现多头注意力了，假设我们有h个头，隐藏层权重 $hidden_size = p_q = p_k = p_v$ 与query，key，value的维度一致。除此之外，因为多头注意力层保持输入与输出张量的维度不变，所以输出feature的维度也设置为 $d_0 = hidden_size$。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, num_heads, dropout, **kwargs)</span>:</span></span><br><span class="line">        super(MultiHeadAttention, self).__init__(**kwargs)</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.attention = DotProductAttention(dropout)</span><br><span class="line">        self.W_q = nn.Linear(input_size, hidden_size, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.W_k = nn.Linear(input_size, hidden_size, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.W_v = nn.Linear(input_size, hidden_size, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.W_o = nn.Linear(hidden_size, hidden_size, bias=<span class="keyword">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, valid_length)</span>:</span></span><br><span class="line">        <span class="comment"># query, key, and value shape: (batch_size, seq_len, dim),</span></span><br><span class="line">        <span class="comment"># where seq_len is the length of input sequence</span></span><br><span class="line">        <span class="comment"># valid_length shape is either (batch_size, )</span></span><br><span class="line">        <span class="comment"># or (batch_size, seq_len).</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Project and transpose query, key, and value from</span></span><br><span class="line">        <span class="comment"># (batch_size, seq_len, hidden_size * num_heads) to</span></span><br><span class="line">        <span class="comment"># (batch_size * num_heads, seq_len, hidden_size).</span></span><br><span class="line">        </span><br><span class="line">        query = transpose_qkv(self.W_q(query), self.num_heads)</span><br><span class="line">        key = transpose_qkv(self.W_k(key), self.num_heads)</span><br><span class="line">        value = transpose_qkv(self.W_v(value), self.num_heads)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> valid_length <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="comment"># Copy valid_length by num_heads times</span></span><br><span class="line">            device = valid_length.device</span><br><span class="line">            valid_length = valid_length.cpu().numpy() <span class="keyword">if</span> valid_length.is_cuda <span class="keyword">else</span> valid_length.numpy()</span><br><span class="line">            <span class="keyword">if</span> valid_length.ndim == <span class="number">1</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(np.tile(valid_length, self.num_heads))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(np.tile(valid_length, (self.num_heads,<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">            valid_length = valid_length.to(device)</span><br><span class="line">            </span><br><span class="line">        output = self.attention(query, key, value, valid_length)</span><br><span class="line">        output_concat = transpose_output(output, self.num_heads)</span><br><span class="line">        <span class="keyword">return</span> self.W_o(output_concat)</span><br></pre></td></tr></table></figure>
<p>关于其中实现的代码，首先要注意其维度上的变化，对于query , key 和 value ，其本身在维度上都是(batch_size , seq_len , dim )，这和之前的是相同的，然后利用transpose 会将最后一维变成两维，倒数第二维是head_nums，然后再进行变换，具体可参见如下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transpose_qkv</span><span class="params">(X, num_heads)</span>:</span></span><br><span class="line">    <span class="comment"># Original X shape: (batch_size, seq_len, hidden_size * num_heads),</span></span><br><span class="line">    <span class="comment"># -1 means inferring its value, after first reshape, X shape:</span></span><br><span class="line">    <span class="comment"># (batch_size, seq_len, num_heads, hidden_size)</span></span><br><span class="line">    X = X.view(X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>], num_heads, <span class="number">-1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># After transpose, X shape: (batch_size, num_heads, seq_len, hidden_size)</span></span><br><span class="line">    X = X.transpose(<span class="number">2</span>, <span class="number">1</span>).contiguous()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Merge the first two dimensions. Use reverse=True to infer shape from</span></span><br><span class="line">    <span class="comment"># right to left.</span></span><br><span class="line">    <span class="comment"># output shape: (batch_size * num_heads, seq_len, hidden_size)</span></span><br><span class="line">    output = X.view(<span class="number">-1</span>, X.shape[<span class="number">2</span>], X.shape[<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>关于<code>np.tile</code>函数：官方文档为</p>
<p><code>Construct an array by repeating A the number of times given by reps.</code></p>
<p>If <em>reps</em> has length <code>d</code>, the result will have dimension of <code>max(d, A.ndim)</code>.</p>
<p>If <code>A.ndim &lt; d</code>, <em>A</em> is promoted to be d-dimensional by prepending new axes. So a shape (3,) array is promoted to (1, 3) for 2-D replication, or shape (1, 1, 3) for 3-D replication. If this is not the desired behavior, promote <em>A</em> to d-dimensions manually before calling this function.</p>
<p>If <code>A.ndim &gt; d</code>, <em>reps</em> is promoted to <em>A</em>.ndim by pre-pending 1’s to it. Thus for an <em>A</em> of shape (2, 3, 4, 5), a <em>reps</em> of (2, 2) is treated as (1, 1, 2, 2).</p>
<p>注意维度的调换</p>
<p>最后的output 的 shape  : (batch_size,seq_len,hide_size * head_nums)</p>
<h3 id="基于位置的前馈网络"><a href="#基于位置的前馈网络" class="headerlink" title="基于位置的前馈网络"></a>基于位置的前馈网络</h3><p>其效果主要用于变换维度，实际上就等同于一个$1 \times 1$的卷积层</p>
<h3 id="Add-and-Norm"><a href="#Add-and-Norm" class="headerlink" title="Add and Norm"></a>Add and Norm</h3><p>除了上面两个模块之外，Transformer还有一个重要的相加归一化层，它可以平滑地整合输入和其他层的输出，因此我们在每个多头注意力层和FFN层后面都添加一个含残差连接的Layer Norm层。这里 Layer Norm 与7.5小节的Batch Norm很相似，唯一的区别在于Batch Norm是对于batch size这个维度进行计算均值和方差的，而Layer Norm则是对最后一维进行计算。层归一化可以防止层内的数值变化过大，从而有利于加快训练速度并且提高泛化性能。 <a href="https://zhuanlan.zhihu.com/p/54530247" target="_blank" rel="noopener">(ref)</a> </p>
<p>与循环神经网络不同，无论是多头注意力网络还是前馈神经网络都是独立地对每个位置的元素进行更新，这种特性帮助我们实现了高效的并行，却丢失了重要的序列顺序的信息。为了更好的捕捉序列信息，Transformer模型引入了位置编码去保持输入序列元素的位置。</p>
<p>假设输入序列的嵌入表示 $X\in \mathbb{R}^{l\times d}$, 序列长度为$l$嵌入向量维度为$d$，则其位置编码为$P \in \mathbb{R}^{l\times d}$ ，输出的向量就是二者相加 $X + P$。</p>
<h3 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h3><p>位置编码是一个二维的矩阵，i对应着序列中的顺序，j对应其embedding vector内部的维度索引。我们可以通过以下等式计算位置编码：</p>
<script type="math/tex; mode=display">
P_{i,2j} = sin(i/10000^{2j/d})</script><script type="math/tex; mode=display">
P_{i,2j+1} = cos(i/10000^{2j/d})</script><script type="math/tex; mode=display">
for\ i=0,\ldots, l-1\ and\ j=0,\ldots,\lfloor (d-1)/2 \rfloor</script><p><img src="https://cdn.kesci.com/upload/image/q5kpe0lu38.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<script type="math/tex; mode=display">
Fig. 10.3.4\ 位置编码</script><p>对于transformer而言，本身没有包含位置的性质。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.training:</span><br><span class="line">            batch_size, seq_len, _ = X.shape</span><br><span class="line">            <span class="comment"># Shape: (batch_size, seq_len), the values in the j-th column are j+1</span></span><br><span class="line">            valid_length = torch.FloatTensor(np.tile(np.arange(<span class="number">1</span>, seq_len+<span class="number">1</span>), (batch_size, <span class="number">1</span>))) </span><br><span class="line">            valid_length = valid_length.to(X.device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_length = <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<p>在这里，要理解一下，对于训练和预测，其输入是不同的，在训练过程中，会直接输入整个targets的所有tokens，那么这个时候为了保证其不看到后面的结果来进行loss的训练，需要设定当前的<code>valid_length</code>，相当于只看到了seq_len+1 这一个tokens为止。</p>
<h2 id="卷积神经网络基础"><a href="#卷积神经网络基础" class="headerlink" title="卷积神经网络基础"></a>卷积神经网络基础</h2><p>输入维度：</p>
<p>对于卷积神经网络来说，一般的输入X和中间的隐藏层，都具有4个维度，其分别是：</p>
<p>(batch_size, channels,length,width)</p>
<p>对于其他部分，应该就比较好理解。</p>
<h2 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h2><p>LeNet是一个最经典的卷积神经网络。</p>
<p>使用全连接层的局限性：</p>
<ul>
<li>图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。</li>
<li>对于大尺寸的输入图像，使用全连接层容易导致模型过大。</li>
</ul>
<p>使用卷积层的优势：</p>
<ul>
<li>卷积层保留输入形状。</li>
<li>卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。</li>
</ul>
<h2 id="卷积神经网络进阶"><a href="#卷积神经网络进阶" class="headerlink" title="卷积神经网络进阶"></a>卷积神经网络进阶</h2><p>主要介绍了几个经典的卷积神经网络</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>首次证明了学习到的特征可以超越⼿⼯设计的特征，从而⼀举打破计算机视觉研究的前状。<br> <strong>特征：</strong></p>
<ol>
<li>8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。</li>
<li>将sigmoid激活函数改成了更加简单的ReLU激活函数。</li>
<li>用Dropout来控制全连接层的模型复杂度。</li>
<li>引入数据增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。</li>
</ol>
<h3 id="使用重复元素的网络（VGG）"><a href="#使用重复元素的网络（VGG）" class="headerlink" title="使用重复元素的网络（VGG）"></a>使用重复元素的网络（VGG）</h3><p>VGG：通过重复使⽤简单的基础块来构建深度模型。<br> Block:数个相同的填充为1、窗口形状为</p>
<p>的卷积层,接上一个步幅为2、窗口形状为的最大池化层。<br> 卷积层保持输入的高和宽不变，而池化层则对其减半。</p>
<p><img src="https://cdn.kesci.com/upload/image/q5l6vut7h1.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<h3 id="网络中的网络-NiN"><a href="#网络中的网络-NiN" class="headerlink" title="网络中的网络(NiN)"></a>网络中的网络(NiN)</h3><p>LeNet、AlexNet和VGG：先以由卷积层构成的模块充分抽取 空间特征，再以由全连接层构成的模块来输出分类结果。<br> NiN：串联多个由卷积层和“全连接”层构成的小⽹络来构建⼀个深层⽹络。<br> ⽤了输出通道数等于标签类别数的NiN块，然后使⽤全局平均池化层对每个通道中所有元素求平均并直接⽤于分类。</p>
<p><img src="https://cdn.kesci.com/upload/image/q5l6u1p5vy.png?imageView2/0/w/960/h/960" alt="Image Name"></p>
<h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><ol>
<li>由Inception基础块组成。  </li>
<li>Inception块相当于⼀个有4条线路的⼦⽹络。它通过不同窗口形状的卷积层和最⼤池化层来并⾏抽取信息，并使⽤1×1卷积层减少通道数从而降低模型复杂度。   </li>
<li>可以⾃定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。 </li>
</ol>
<p><img src="https://cdn.kesci.com/upload/image/q5l6uortw.png?imageView2/0/w/640/h/640" alt="Image Name"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2020/02/14/pytorch1/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/14/pytorch1/" itemprop="url">pytorch1</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-14T11:51:18+08:00">
                2020-02-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="动手学深度学习-task1"><a href="#动手学深度学习-task1" class="headerlink" title="动手学深度学习 task1"></a>动手学深度学习 task1</h1><hr>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>对于简单的线性回归而言，实际上就非常简单，只需要一个线性层即可。对于python而言，一般来说，使用科学计算提供的矢量运算要比利用循环实现的效率高很多。这里实际上跟CPU本身的指令集扩展有关，包括AVX和MME的矢量运算指令。</p>
<h3 id="yield-使用"><a href="#yield-使用" class="headerlink" title="yield 使用"></a>yield 使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter</span><span class="params">(batch_size, features, labels)</span>:</span></span><br><span class="line">    num_examples = len(features)</span><br><span class="line">    indices = list(range(num_examples))</span><br><span class="line">    random.shuffle(indices)  <span class="comment"># random read 10 samples</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) <span class="comment"># the last time may be not enough for a whole batch</span></span><br><span class="line">        <span class="keyword">yield</span>  features.index_select(<span class="number">0</span>, j), labels.index_select(<span class="number">0</span>, j)</span><br></pre></td></tr></table></figure>
<p>在这里，使用了yield，这里的yield 有两个作用，包括return 和一个迭代器的作用。在python 中，这样的例子还包括之前有的xrange，即现在的range，如果去打印type(range(10))，可以看到，当前的range返回的也是这样一个迭代器。</p>
<h3 id="小批量计算"><a href="#小批量计算" class="headerlink" title="小批量计算"></a>小批量计算</h3><p>batch normalization 是两种不同方式的中和，既不需要计算整个批量的所有数据来进行梯度下降，也不由于某些极少数的点来导致下降的方向不对。一般而言，小批量的计算是用于对于大量数据的梯度下降， 而对于少量的数据，直接使用批量梯度下降即可。</p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>一般而言，神经网络都是BP神经网络，也就是反向传播是很重要的一个过程，故而在训练的过程中，需要保持参数的反向传播（能计算其导数），在pytorch中，给出了相应的方法来进行反向传播。</p>
<h2 id="softmax-与分类模型"><a href="#softmax-与分类模型" class="headerlink" title="softmax 与分类模型"></a>softmax 与分类模型</h2><h3 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h3><p>softmax的提出，很大程度上是为了数值计算的方便。对于softmax的理解，主要要通过信息论和数值计算这两方面来进行，softmax函数本身所具有的特性，让他能够很好地运用在分类网络中。</p>
<h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><p>对于交叉熵，这里实际上是信息论的一个重要概念，其本身用在分类模型中，表示我们只关心分类出来的那个结果的概率比的大小，而不在意其它的结果。</p>
<h2 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h2><p>多层感知机其原理就是通过在一层和一层之间加上激活函数，使得本来很简单的过程可以映射到更复杂的网络结构和高维的数据分布结构当中。</p>
<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><h3 id="两种不同采样方式下的处理"><a href="#两种不同采样方式下的处理" class="headerlink" title="两种不同采样方式下的处理"></a>两种不同采样方式下的处理</h3><p>在实现RNN 的训练过程中，有这样一段代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> is_random_iter:  <span class="comment"># 如使用相邻采样，在epoch开始时初始化隐藏状态</span></span><br><span class="line">    state = init_rnn_state(batch_size, num_hiddens, device)</span><br><span class="line">l_sum, n, start = <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, device)</span><br><span class="line"><span class="keyword">for</span> X, Y <span class="keyword">in</span> data_iter:</span><br><span class="line">    <span class="keyword">if</span> is_random_iter:  <span class="comment"># 如使用随机采样，在每个小批量更新前初始化隐藏状态</span></span><br><span class="line">        state = init_rnn_state(batch_size, num_hiddens, device)</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 否则需要使用detach函数从计算图分离隐藏状态</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> state:</span><br><span class="line">            s.detach_()</span><br></pre></td></tr></table></figure>
<p>对于两种不同的采样方式，采用了不同的对于隐藏状态H 的处理方式，对此进行理解</p>
<h4 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h4><p>对于随机采样，由于采样结果的不连续，那么之前所具有的状态H对当前是没有意义的，故需要重新初始化状态<code>`init_rnn_state</code>。</p>
<h4 id="相邻采样"><a href="#相邻采样" class="headerlink" title="相邻采样"></a>相邻采样</h4><p>在相邻采样开始前，首先进行了<code>init_rnn_state</code> 函数调用，即进行了相应的初始化。由于使用的是相邻采样，那么正如例子所展示的那样，得到的数据应该是相邻连续的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X:  tensor([[ 0,  1,  2,  3,  4,  5],</span><br><span class="line">        [15, 16, 17, 18, 19, 20]]) </span><br><span class="line">Y: tensor([[ 1,  2,  3,  4,  5,  6],</span><br><span class="line">        [16, 17, 18, 19, 20, 21]]) </span><br><span class="line"></span><br><span class="line">X:  tensor([[ 6,  7,  8,  9, 10, 11],</span><br><span class="line">        [21, 22, 23, 24, 25, 26]]) </span><br><span class="line">Y: tensor([[ 7,  8,  9, 10, 11, 12],</span><br><span class="line">        [22, 23, 24, 25, 26, 27]])</span><br></pre></td></tr></table></figure>
<p>所以实际上，进行<code>data_iter_fn</code>迭代的时候，所得到的数据，即是连续的，那么其本身的状态是可以保持的，正如用[0,1,2,3,4,5]的状态推出到[1,2,3,4,5,6]的状态一样，这样的过程是连续进行的，所以状态也应该是连续的。所以这个时候，应该保持状态H不变，而不需要像随机采样那样重新<code>init_rnn_state</code>，所以我们需要使用detach_来保留当前H的状态，来进行后续的推导，那么为什么要使用<code>detach_</code>而不直接保留呢？</p>
<p>可以参见detach_的源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># detach_ 的源码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detach_</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""Detaches the Variable from the graph that created it, making it a</span></span><br><span class="line"><span class="string">    leaf.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    self._grad_fn = <span class="keyword">None</span></span><br><span class="line">    self.requires_grad = <span class="keyword">False</span></span><br></pre></td></tr></table></figure>
<p>可以看到，这里将其将 Variable 的grad_fn 设置为 None，这样，BP 的时候，到这个 Variable 就找不到 它的 grad_fn，所以就不会再往后BP了。</p>
<p>因为采样的时候，已经预设了相应的前提，即确定的时间步长，不应该再向前BP（反向传播），故而需要将其detach掉。</p>
<p>对于detach_函数的理解，可以参考这篇博客<a href="https://www.cnblogs.com/jiangkejie/p/9981707.html" target="_blank" rel="noopener">pytorch中的detach_和detach</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2019/11/01/hello-world/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/01/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-01T19:51:23+08:00">
                2019-11-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2019/09/25/github&git/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/25/github&git/" itemprop="url">github&git</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-09-25T19:15:03+08:00">
                2019-09-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Git-amp-github"><a href="#Git-amp-github" class="headerlink" title="Git &amp; github"></a>Git &amp; github</h1><hr>
<h2 id="github-账号申请"><a href="#github-账号申请" class="headerlink" title="github 账号申请"></a>github 账号申请</h2><h3 id="personal-or-workgroup"><a href="#personal-or-workgroup" class="headerlink" title="personal or workgroup"></a>personal or workgroup</h3><ul>
<li>个人账号注册-&gt; 登录<a href="https://github.com/" target="_blank" rel="noopener">github</a> 根据相关信息注册账号(sign up 表示注册，sign in 表示登录)</li>
</ul>
<p>当需要注册organization的时候，则可以如图，选择new organization 来创建一个workgroup。<br><img src="https://github.com/leliyliu/figure_lib/blob/master/loognson/git/organization.png?raw=true" alt="workgourp"></p>
<h3 id="创建仓库-new-repository"><a href="#创建仓库-new-repository" class="headerlink" title="创建仓库(new repository)"></a>创建仓库(new repository)</h3><p>其中包括了几项内容，需要填写或者选择：repository name , Description, initialization or not , gitignore and license.</p>
<p><img src="https://github.com/leliyliu/figure_lib/blob/master/loognson/git/create.jpg?raw=true" alt="create"><br>选择clone or download,然后在本地打开git bash ，然后git clone：</p>
<p><img src="https://github.com/leliyliu/figure_lib/blob/master/loognson/git/clone.jpg?raw=true" alt="clone"></p>
<p><img src="https://github.com/leliyliu/figure_lib/blob/master/loognson/git/gitclone.jpg?raw=true" alt="git_clone"></p>
<h3 id="配置用户名和邮箱"><a href="#配置用户名和邮箱" class="headerlink" title="配置用户名和邮箱"></a>配置用户名和邮箱</h3><blockquote>
<p>第一次使用gitBash需要配置邮箱和用户名，邮箱可以填你自己的邮箱，用户名可以任意写，这不是做登录使用，就是保留自己的信息而已。</p>
</blockquote>
<ul>
<li>输入git config —global user.email按回车，然后输入你的邮箱</li>
<li>输入git config —global user.name按回车，然后输入你的用户名</li>
<li>邮箱和用户名都使用之后就可以正式使用git了</li>
</ul>
<h3 id="git-常用命令汇总"><a href="#git-常用命令汇总" class="headerlink" title="git 常用命令汇总"></a>git 常用命令汇总</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">克隆代码：git <span class="built_in">clone</span> 远程仓库的url</span><br><span class="line">配置邮箱：git config --global user.email</span><br><span class="line">配置用户名：git config --global user.name</span><br><span class="line">从远程仓库下拉代码到本地：git pull</span><br><span class="line">将本地代码添加到缓冲区：git add * .</span><br><span class="line">将本地代码提交到本地仓库：git commit -m<span class="string">"日志文字"</span></span><br><span class="line">将本地仓库同步到远程仓库：git push origin master</span><br><span class="line">查看日志：git <span class="built_in">log</span></span><br><span class="line">查看某个文件的提交日志：git <span class="built_in">log</span> 文件名</span><br><span class="line">查看某个用户的提交日志：git <span class="built_in">log</span> --author=“author”</span><br><span class="line">查看某条提交日志相信信息：git show 版本号</span><br><span class="line">查看git全部命令：git --<span class="built_in">help</span></span><br><span class="line">查看git某个命令的使用：git <span class="built_in">help</span> 命令名</span><br></pre></td></tr></table></figure>
<h3 id="more-commands"><a href="#more-commands" class="headerlink" title="more commands"></a>more commands</h3><p>参考<a href="https://www.jianshu.com/p/cf1e883d69d6" target="_blank" rel="noopener">Git 命令大全</a></p>
<h4 id="项目提交和拉取"><a href="#项目提交和拉取" class="headerlink" title="项目提交和拉取"></a>项目提交和拉取</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// 克隆远程仓库到本地(先<span class="built_in">cd</span>到指定文件夹下,再执行<span class="built_in">clone</span>操作）</span><br><span class="line">$ git <span class="built_in">clone</span> git@github.com:leliyliu/augmips.git</span><br><span class="line"></span><br><span class="line">// 添加本地库</span><br><span class="line">$ git add ProjectName         --------  <span class="string">"ProjectName"</span>项目名称</span><br><span class="line"></span><br><span class="line">// 添加提交日志</span><br><span class="line">$ git commit -m ‘Journal’     </span><br><span class="line"></span><br><span class="line">// 提交到远端</span><br><span class="line">$ git push origin master      --------  <span class="string">"master"</span>分支名</span><br><span class="line"></span><br><span class="line">// 从远端拉取代</span><br><span class="line">$ git pull origin master</span><br></pre></td></tr></table></figure>
<h4 id="常用辅助命令"><a href="#常用辅助命令" class="headerlink" title="常用辅助命令"></a>常用辅助命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 查看提交日志</span><br><span class="line">$ git <span class="built_in">log</span> -3  --------查看最近三次提交的记录</span><br><span class="line"></span><br><span class="line">// 查看文件提交状态</span><br><span class="line">$ git status</span><br></pre></td></tr></table></figure>
<h4 id="标签操作"><a href="#标签操作" class="headerlink" title="标签操作"></a>标签操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 打一个新标签</span><br><span class="line">$ git tag v1.0.0</span><br><span class="line"></span><br><span class="line">// 查看所有标签</span><br><span class="line">$ git tag</span><br><span class="line"></span><br><span class="line">// 根据commit id 打标签</span><br><span class="line">$ git tag v1.0.1 2fbb88d5fad5a03e5b4ef2df316b4d32f5339ef5</span><br><span class="line"></span><br><span class="line">// 删除标签</span><br><span class="line">$ git tag -d v1.1.0</span><br></pre></td></tr></table></figure>
<h4 id="关于分支"><a href="#关于分支" class="headerlink" title="关于分支"></a>关于分支</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">//1、 查看当前所有分支</span><br><span class="line">$ git branch</span><br><span class="line"></span><br><span class="line"><span class="comment"># * dev          ---- 当前分支</span></span><br><span class="line"><span class="comment">#   master       ---- 主分支</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//2、 创建分支</span><br><span class="line">$ git branch dev</span><br><span class="line"></span><br><span class="line">//3、 切换分支</span><br><span class="line">$ git checkout dev</span><br><span class="line"></span><br><span class="line">//4、 创建并切换分支（相当于前两步操作）</span><br><span class="line">$ git checkout -b dev</span><br><span class="line"></span><br><span class="line">//5.1、 合并分支</span><br><span class="line">$ git merge dev                 ------ ⚠️ （此命令为：合并某分支到当前分支，例：将dev合并到master），则当前所处于master分支。</span><br><span class="line"></span><br><span class="line">//5.2、 合并dev分支上的某条记录到master上</span><br><span class="line">//（例如：在dev上有三次提交记录，但是只想把其中的第二次合并到master上去，采取这个命令）</span><br><span class="line">git cherry-pick <span class="string">"ddec59e2..."</span>   ------⚠️ 在master分支下输入命令，参数为 commit-id</span><br><span class="line"></span><br><span class="line">// 如果在合并中存在以下冲突，进入文件夹手动解决冲突再次提交</span><br><span class="line">hint: after resolving the conflicts, mark the corrected paths</span><br><span class="line">hint: with <span class="string">'git add &lt;paths&gt;'</span> or <span class="string">'git rm &lt;paths&gt;'</span></span><br><span class="line"></span><br><span class="line">//6、 删除指定分支</span><br><span class="line">$ git branch -D dev              ------ ⚠️（保证当前分支为非删除分支）</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">//1、 查看当前所有分支</span><br><span class="line">$ git branch</span><br><span class="line"></span><br><span class="line"><span class="comment"># * dev          ---- 当前分支</span></span><br><span class="line"><span class="comment">#   master       ---- 主分支</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//2、 创建分支</span><br><span class="line">$ git branch dev</span><br><span class="line"></span><br><span class="line">//3、 切换分支</span><br><span class="line">$ git checkout dev</span><br><span class="line"></span><br><span class="line">//4、 创建并切换分支（相当于前两步操作）</span><br><span class="line">$ git checkout -b dev</span><br><span class="line"></span><br><span class="line">//5.1、 合并分支</span><br><span class="line">$ git merge dev                 ------ ⚠️ （此命令为：合并某分支到当前分支，例：将dev合并到master），则当前所处于master分支。</span><br><span class="line"></span><br><span class="line">//5.2、 合并dev分支上的某条记录到master上</span><br><span class="line">//（例如：在dev上有三次提交记录，但是只想把其中的第二次合并到master上去，采取这个命令）</span><br><span class="line">git cherry-pick <span class="string">"ddec59e2..."</span>   ------⚠️ 在master分支下输入命令，参数为 commit-id</span><br><span class="line"></span><br><span class="line">// 如果在合并中存在以下冲突，进入文件夹手动解决冲突再次提交</span><br><span class="line">hint: after resolving the conflicts, mark the corrected paths</span><br><span class="line">hint: with <span class="string">'git add &lt;paths&gt;'</span> or <span class="string">'git rm &lt;paths&gt;'</span></span><br><span class="line"></span><br><span class="line">//6、 删除指定分支</span><br><span class="line">$ git branch -D dev              ------ ⚠️（保证当前分支为非删除分支）</span><br></pre></td></tr></table></figure>
<h4 id="版本的回退"><a href="#版本的回退" class="headerlink" title="版本的回退"></a>版本的回退</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">log</span> -3</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit 65e19bef8eed336aefedaca636d78e71cea1d4f6 (HEAD -&gt; master, origin/master, origin/HEAD)</span></span><br><span class="line"><span class="comment"># Author: lizhiqiang &lt;601623654@qq.com&gt;</span></span><br><span class="line"><span class="comment"># Date:   Wed Mar 14 15:54:06 2018 +0800</span></span><br><span class="line"></span><br><span class="line">    增加1.1.3版本</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit 2fbb88d5fad5a03e5b4ef2df316b4d32f5339ef5</span></span><br><span class="line"><span class="comment"># Author: lizhiqiang &lt;601623654@qq.com&gt;</span></span><br><span class="line"><span class="comment"># Date:   Wed Mar 14 15:51:22 2018 +0800</span></span><br><span class="line"></span><br><span class="line">    增加1.1.2版本</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit aa0f5ce90153c76249a12b8fa638a42b5155612b</span></span><br><span class="line"><span class="comment"># Author: lizhiqiang &lt;601623654@qq.com&gt;</span></span><br><span class="line"><span class="comment"># Date:   Wed Mar 14 15:46:03 2018 +0800</span></span><br><span class="line"></span><br><span class="line">    增加1.1.1版本</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 退回到上一个版本</span><br><span class="line">$ git reset --hard HEAD^</span><br><span class="line"><span class="comment"># HEAD is now at 2fbb88d 增加1.1.2版本    </span></span><br><span class="line">-----在此我们可以看到，HEAD指针已经由1.1.3版本指向了1.1.2版本，如果你把xcode打开就可以看到，1.1.3的代码已经消失了</span><br><span class="line">-----如果你的命令窗口没有关闭的话，通过commit id 还是可以返回1.1.3的,具体请看下一条命令</span><br><span class="line"></span><br><span class="line">// 返回任意版本</span><br><span class="line">$ git reset --hard 65e19bef8eed336aefedaca636d78e71cea1d4f6</span><br><span class="line"><span class="comment"># HEAD is now at 65e19be 增加1.1.3版本</span></span><br><span class="line"></span><br><span class="line">// 将修改后的版本推送至服务器</span><br><span class="line">$ git push -f -u origin master</span><br></pre></td></tr></table></figure>
<h4 id="阶段的撤销更改"><a href="#阶段的撤销更改" class="headerlink" title="阶段的撤销更改"></a>阶段的撤销更改</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// 已修改，未暂存   ------------没有执行 git add</span><br><span class="line">$ git checkout .    （或 $ git reset --hard）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 已暂存，未提交   ------------你已经执行了 git add . ，但还没有执行 git commit -m <span class="string">"comment"</span> 。</span><br><span class="line">$ git reset</span><br><span class="line">$ git checkout .     (或 $ git reset --hard)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 已提交，未推送   ------------既执行了 git add . ，又执行了 git commit </span><br><span class="line">$ git reset --hard origin/master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 已推送          ------------既 git add 了，又 git commit 了，并且还 git push 了</span><br><span class="line">$ git reset --hard HEAD^</span><br><span class="line">$ git push -f</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2019/05/05/django-learning/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/05/django-learning/" itemprop="url">django_learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-05T14:56:16+08:00">
                2019-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2019/05/05/paper-reading/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/05/paper-reading/" itemprop="url">paper_reading</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-05T08:07:26+08:00">
                2019-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Neural-Collaborative-Filtering"><a href="#Neural-Collaborative-Filtering" class="headerlink" title="Neural Collaborative Filtering"></a>Neural Collaborative Filtering</h1><p>这篇文章主要介绍了深度学习在推荐系统方面的应用，主要是应用了神经网络搭建协同过滤的网络，形成一个较好的结果。</p>
<p>我将结合文章中所提及的主要方法及其代码来回顾整篇文章。</p>
<h2 id="3-NEURAL-COLLABORATIVE-FILTERING"><a href="#3-NEURAL-COLLABORATIVE-FILTERING" class="headerlink" title="3. NEURAL COLLABORATIVE FILTERING"></a>3. NEURAL COLLABORATIVE FILTERING</h2><p>从第三部分才来到实践的关键，所以我们直接跳过前两个部分，来到第三部分，并对它进行学习和理解。论文的主要部分在于，首先实现NCF，并对于NCF实例化之后利用DNN对其进行改善，提出了MLP，然后结合NCF和MLP来综合形成最后的结果。</p>
<h3 id="GMF"><a href="#GMF" class="headerlink" title="GMF"></a>GMF</h3><p>首先的input层是一个one-hot向量，将每一个user和每一个item都设置为one-hot向量之后再进行处理。在input 层之后是一个embedding 层，然后将item和user 的embedding层 的结果合在一起之后放入一个多层神经网络中，我们将这个多层的神经网络视作神经协同过滤层，隐藏层的最后一层的维度决定了这个模型的泛化能力。最终的输出层(output)得到的是最终预测的结果。</p>
<h4 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h4><p>关于range 和 xrange，如果只看效果的话，两者差距很小，但是xrange每次返回的是xrange 的一个数据结构，而不是range返回的list，因此，当对于大数据进行处理时，建议使用xrange，而不是range。</p>
<p>关于代码中的参数说明：<br>| 符号| 含义|<br>| —- | —- |<br>| num_factors|将其映射到的空间的维度大小|<br>|regs|即正则化过程中的偏移量|<br>|num_neg|展示的negtive数量|<br>|lr|学习率|<br>|learner|学习的方式，一般来说使用adam|<br>|verbose|实质上是设置多少次迭代后输出结果|<br>|out| 设置输出|<br>|epochs| 迭代次数（学习次数）|<br>|batch_size|每一个batch的数量，使用sgd进行训练时需要弄清楚|</p>
<p>重点看model函数，即训练的函数。<br>这里的模型极其简单，实际上加深模型，应该有助于最后的训练结果。加深应该在哪里呢？从predict_vector开始，多加入几层，同时应该考虑不要社会太少的latent_dim，毕竟是大数据量的结果，考虑将其加深。原文中主要是为了能使得CPU较快的运行，才使用了这样一种方式。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span><span class="params">(num_users, num_items, latent_dim, regs=[<span class="number">0</span>,<span class="number">0</span>])</span>:</span></span><br><span class="line">    <span class="comment"># Input variables</span></span><br><span class="line">    user_input = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>, name = <span class="string">'user_input'</span>)</span><br><span class="line">    item_input = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>, name = <span class="string">'item_input'</span>)</span><br><span class="line"></span><br><span class="line">    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = <span class="string">'user_embedding'</span>,</span><br><span class="line">                                  init = init_normal, W_regularizer = l2(regs[<span class="number">0</span>]), input_length=<span class="number">1</span>)</span><br><span class="line">    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = <span class="string">'item_embedding'</span>,</span><br><span class="line">                                  init = init_normal, W_regularizer = l2(regs[<span class="number">1</span>]), input_length=<span class="number">1</span>)   </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Crucial to flatten an embedding vector!</span></span><br><span class="line">    user_latent = Flatten()(MF_Embedding_User(user_input))</span><br><span class="line">    item_latent = Flatten()(MF_Embedding_Item(item_input))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Element-wise product of user and item embeddings </span></span><br><span class="line">    predict_vector = merge([user_latent, item_latent], mode = <span class="string">'mul'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Final prediction layer</span></span><br><span class="line">    <span class="comment">#prediction = Lambda(lambda x: K.sigmoid(K.sum(x)), output_shape=(1,))(predict_vector)</span></span><br><span class="line">    prediction = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>, init=<span class="string">'lecun_uniform'</span>, name = <span class="string">'prediction'</span>)(predict_vector)</span><br><span class="line">    </span><br><span class="line">    model = Model(input=[user_input, item_input], </span><br><span class="line">                output=prediction)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>get_train_instances函数将训练集传入并对其进行处理，构成one-hot向量。<br>但是实际上这里的label只是用于论文中所说的是否进行点击，对于后续的操作的意义不大。需要注意这里的区别。实际上，如果真正需要做评分系统的话，那么就需要将label定义为打分的结果，而不是0,1的二值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_instances</span><span class="params">(train, num_negatives)</span>:</span></span><br><span class="line">    user_input, item_input, labels = [],[],[]</span><br><span class="line">    num_users = train.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> (u, i) <span class="keyword">in</span> train.keys():</span><br><span class="line">        <span class="comment"># positive instance</span></span><br><span class="line">        user_input.append(u)</span><br><span class="line">        item_input.append(i)</span><br><span class="line">        labels.append(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># negative instances</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> xrange(num_negatives):</span><br><span class="line">            j = np.random.randint(num_items)<span class="comment">#从0到item_num的数量中选择一个</span></span><br><span class="line">            <span class="keyword">while</span> train.has_key((u, j)):</span><br><span class="line">                j = np.random.randint(num_items)</span><br><span class="line">            user_input.append(u)</span><br><span class="line">            item_input.append(j)</span><br><span class="line">            labels.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> user_input, item_input, labels</span><br></pre></td></tr></table></figure>
<p>自己的尝试，主要用于大数据作业的数据集，简要介绍一下这个数据集：</p>
<ol>
<li>大概有20000个用户和600000个item，同时，总共有5000000条的打分，打分从0-100，但是分布极其不均匀，因此，需要对其进行处理，为了避免与稀疏矩阵的重合，将score变为:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score=np.floor(score/<span class="number">10</span>)+<span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>因此，构建的模型为<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span><span class="params">(num_users, num_items, latent_dim=<span class="number">100</span>, regs=[<span class="number">0</span>,<span class="number">0</span>])</span>:</span></span><br><span class="line">    <span class="comment"># Input variables</span></span><br><span class="line">    user_input = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>, name = <span class="string">'user_input'</span>)</span><br><span class="line">    item_input = Input(shape=(<span class="number">1</span>,), dtype=<span class="string">'int32'</span>, name = <span class="string">'item_input'</span>)</span><br><span class="line"></span><br><span class="line">    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = <span class="string">'user_embedding'</span>,</span><br><span class="line">                                  init = <span class="string">'uniform'</span>, W_regularizer = l2(regs[<span class="number">0</span>]), input_length=<span class="number">1</span>)</span><br><span class="line">    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = <span class="string">'item_embedding'</span>,</span><br><span class="line">                                  init = <span class="string">'uniform'</span>, W_regularizer = l2(regs[<span class="number">1</span>]), input_length=<span class="number">1</span>)   </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Crucial to flatten an embedding vector!</span></span><br><span class="line">    user_latent = Flatten()(MF_Embedding_User(user_input))</span><br><span class="line">    item_latent = Flatten()(MF_Embedding_Item(item_input))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Element-wise product of user and item embeddings </span></span><br><span class="line">    <span class="comment">#predict_vector = merge([user_latent, item_latent], mode = 'mul')</span></span><br><span class="line">    predict_vector = keras.layers.Multiply()([user_latent,item_latent])</span><br><span class="line">    <span class="comment"># Final prediction layer</span></span><br><span class="line">    <span class="comment">#prediction = Lambda(lambda x: K.sigmoid(K.sum(x)), output_shape=(1,))(predict_vector)</span></span><br><span class="line">    predict_layer1=Dense(<span class="number">64</span>,activation=<span class="string">'sigmoid'</span>,init=<span class="string">'lecun_uniform'</span>,name=<span class="string">'predict_layer1'</span>)(predict_vector)</span><br><span class="line">    predict_layer2=Dense(<span class="number">32</span>,activation=<span class="string">'sigmoid'</span>,init=<span class="string">'lecun_uniform'</span>,name=<span class="string">'predict_layer2'</span>)(predict_layer1)</span><br><span class="line">    prediction = Dense(<span class="number">11</span>, activation=<span class="string">'softmax'</span>, init=<span class="string">'lecun_uniform'</span>, name = <span class="string">'prediction'</span>)(predict_layer2)</span><br><span class="line">    </span><br><span class="line">    model = Model(input=[user_input, item_input], </span><br><span class="line">                output=prediction)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>中间多加了几层，对于报错处的记录</p>
<blockquote>
<p>‘Dense’ object has no attribute ‘outbound_nodes’</p>
</blockquote>
<h3 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h3>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2019/05/04/colab/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/04/colab/" itemprop="url">colab</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-04T17:10:58+08:00">
                2019-05-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Colab的使用"><a href="#Colab的使用" class="headerlink" title="Colab的使用"></a>Colab的使用</h1><hr>
<h2 id="Colab介绍"><a href="#Colab介绍" class="headerlink" title="Colab介绍"></a>Colab介绍</h2><p>好东西！！ 贫穷的人民，想拥有GPU或者TPU的难得的方式<br>对于一些基础的东西，都不加以介绍了，如果有兴趣，可以自己去查一下，或者ucadity的tensorflow教程里面就要用到这个东西，直接视频观看即可。<br>这里直接记录配置方式</p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><p>首先选择修改，改为GPU或者TPU</p>
<p>然后添加如下代码后执行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">!apt-get install -y -qq software-properties-common python-software-properties module-init-tools</span><br><span class="line">!add-apt-repository -y ppa:alessandro-strada/ppa <span class="number">2</span>&gt;&amp;<span class="number">1</span> &gt; /dev/null</span><br><span class="line">!apt-get update -qq <span class="number">2</span>&gt;&amp;<span class="number">1</span> &gt; /dev/null</span><br><span class="line">!apt-get -y install -qq google-drive-ocamlfuse fuse</span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> auth</span><br><span class="line">auth.authenticate_user()</span><br><span class="line"><span class="keyword">from</span> oauth2client.client <span class="keyword">import</span> GoogleCredentials</span><br><span class="line">creds = GoogleCredentials.get_application_default()</span><br><span class="line"><span class="keyword">import</span> getpass</span><br><span class="line">!google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125; &lt; /dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span> | grep URL</span><br><span class="line">vcode = getpass.getpass()</span><br><span class="line">!echo &#123;vcode&#125; | google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后挂载<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!mkdir -p drive</span><br><span class="line">!google-drive-ocamlfuse drive</span><br></pre></td></tr></table></figure></p>
<p>如果需要安装包的时候，比如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install http://download.pytorch.org/whl/cu80/torch<span class="number">-0.3</span><span class="number">.1</span>-cp36-cp36m-linux_x86_64.whl torchvision</span><br></pre></td></tr></table></figure></p>
<p>这样安装就ok了</p>
<p>当然在执行之前还需要更改目录：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(<span class="string">'drive/.../...'</span>)<span class="comment">#进入你希望进入的目录</span></span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2019/04/28/reading1/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/28/reading1/" itemprop="url">BTS-DSN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-28T18:59:18+08:00">
                2019-04-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Paper-Reading"><a href="#Paper-Reading" class="headerlink" title="Paper Reading"></a>Paper Reading</h1><h2 id="BTS-DSN-Deeply-supervised-neural-network-with-short-connections-forretinal-vessel-segmentation"><a href="#BTS-DSN-Deeply-supervised-neural-network-with-short-connections-forretinal-vessel-segmentation" class="headerlink" title="BTS-DSN: Deeply supervised neural network with short connections forretinal vessel segmentation"></a>BTS-DSN: Deeply supervised neural network with short connections forretinal vessel segmentation</h2><hr>
<blockquote>
<p><code>references</code>: you can read this papar via <a href="https://linkinghub.elsevier.com/retrieve/pii/S138650561831195X" target="_blank" rel="noopener">BTS-DSN</a> or star/fork this github <a href="https://github.com/guomugong/BTS-DSN" target="_blank" rel="noopener">project</a></p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><ol>
<li>An important method was proposed by this group called short-connection, that improve quite a lot the result of this model’s ability. They use sensitivity,specificity, AUC and F1-score to test their model. If you aren’t familiar with these indicators, you can read these two blogs to learn more<a href="https://tracholar.github.io/machine-learning/2018/01/26/auc.html" target="_blank" rel="noopener">AUC</a>  &amp;<a href="https://blog.csdn.net/u013385925/article/details/80385873" target="_blank" rel="noopener">AUC-2</a>. </li>
</ol>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><ol>
<li>why we hope to achieve early dignosis.</li>
<li>some researchs done by other scholar group<blockquote>
<p>(1) Unsupervised methods: some methods have been proposed by scholoars, mainly about detect the profile and contour of vessel. These methods are mostly based on geometric computation model. defects: <code>However, the unsupervised methods are sensitive to the
manually designed features and rules.</code>(poor in generalization)</p>
</blockquote>
</li>
</ol>
<blockquote>
<p>(2)supervised methods:when we use supervised method, we usually view this problem as a pixel-wise binary classification. deep learning methods are popular in this area. Other ways to solve this problem about semantic segmentation results. <code>defects:different methods have different disadvantages such as time-consuming and so on</code></p>
</blockquote>
<ol>
<li>the contributions of this paper<blockquote>
<p>(1)”We propose a deeply-supervised fully convolutional neural network with bottom-top and top-bottom short connections (BTS-DSN) for vessel segmentation. “</p>
</blockquote>
</li>
</ol>
<blockquote>
<p>(2)”We used VGGNet and ResNet-101 as backbone and conducted extensive experiments on DRIVE, STARE and CHASE_DB1”</p>
<p>“We employed cross-training experiments to show the generalization of BTS-DSN.”</p>
</blockquote>
<p>attributes : more about VGGNet and ResNet can be found in their papers.{<a href="https://github.com/machrisaa/tensorflow-vgg" target="_blank" rel="noopener">vgg(including vgg-16&amp;vgg-19)</a>&amp;<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">ResNet_paper</a>&amp;<a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py" target="_blank" rel="noopener">ResNet_github</a>}.If you want to understand these model better, baidu or google it may help you.</p>
<h3 id="2-BTS-DSN"><a href="#2-BTS-DSN" class="headerlink" title="2.BTS-DSN"></a>2.BTS-DSN</h3><ol>
<li><p>from HED to DSN, and then to BS-DSN and BST-DSN. this method was proposed to alleviate the gradient vanish problem in deep network. It’s a deep supervision</p>
</li>
<li><p>bottom-top short connnections: pass low level fine semantic information to high levels to alleviate the blurring situation.</p>
</li>
<li><p>top-bottom short connection: Bottom-top short connections aim to refine high-level segmentation results.</p>
</li>
<li><p>inference: do feature confusion</p>
</li>
</ol>
<h3 id="3-Implementation-details"><a href="#3-Implementation-details" class="headerlink" title="3. Implementation details"></a>3. Implementation details</h3><ol>
<li><p>data augmentation: using quite a lot various transformations to augment the training set, including rotation, flipping and scaling. </p>
</li>
<li><p>model implementation : using the network framework Caffe, short connections of the BTS-DSN. </p>
</li>
<li><p>Parameter settings</p>
</li>
</ol>
<p><code>When the backbone is VGGNet, we fine-tuned our network with a
learning rate of 1e-8, a weight decay of 0.0005, and a momentum of
0.9. We use a fixed learning rate.</code></p>
<p>in two different backbone(VGGNet &amp; ResNet-101),they use different type of parameters . </p>
<p>and for patch-level S-DSN, they split a raw retinal image into 9 patches, each of which was 1/4 the size of the raw image, meanwhile, patches were up-sampled $2 \times$ </p>
<p>4.running environment:……</p>
<h4 id="Evaluation-criteria"><a href="#Evaluation-criteria" class="headerlink" title="Evaluation criteria"></a>Evaluation criteria</h4><p><code>In vessel segmentation, each pixel belongs to a vessel or non-vessel
pixel.</code>(be seen as a binary classfication problem).they iemployed six evaluation criteria, including AUC,SE,SP,ACC,F1-score and MCC.</p>
<h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><p>the result are shown in the fig in this paper, so you can just look through and get them.</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>这篇文章成功实现了目前基本上是最高水平的眼底血管分类成果，其使用VGGNet或者ResNet-101作为支柱(backbone)来实现整个CNN卷积的过程，同时，为了缓解语义分割中语义分割之间的差距，使用top-bottom 和 bottom-top short connection来实现整个过程，最终实现了BTS-DSN网络，达到了好的效果。同时，这个网络也使用了特征融合的方法，可以加以了解。对于更多的细节，还需要继续了解。</p>
<h3 id="发散"><a href="#发散" class="headerlink" title="发散"></a>发散</h3><h4 id="（采样方法）上采样与下采样"><a href="#（采样方法）上采样与下采样" class="headerlink" title="（采样方法）上采样与下采样"></a>（采样方法）上采样与下采样</h4><h4 id="短连接与ResNet连接方式的不同"><a href="#短连接与ResNet连接方式的不同" class="headerlink" title="短连接与ResNet连接方式的不同"></a>短连接与ResNet连接方式的不同</h4><h4 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h4>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2019/04/28/recording2/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/28/recording2/" itemprop="url">AlexNet</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-28T18:59:18+08:00">
                2019-04-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Paper-Reading"><a href="#Paper-Reading" class="headerlink" title="Paper Reading"></a>Paper Reading</h1><h2 id="ImageNet-Classification-with-Deep-Convolutional-Neural-Networks"><a href="#ImageNet-Classification-with-Deep-Convolutional-Neural-Networks" class="headerlink" title="ImageNet Classification with Deep Convolutional Neural Networks"></a>ImageNet Classification with Deep Convolutional Neural Networks</h2><hr>
<blockquote>
<p><code>references</code>: you can read this papar via <a href="https://linkinghub.elsevier.com/retrieve/pii/S138650561831195X" target="_blank" rel="noopener">BTS-DSN</a> or star/fork this github <a href="https://github.com/guomugong/BTS-DSN" target="_blank" rel="noopener">project</a></p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>To achieve a great result, using ImageNet LSVRC-2010 contest dataset, this network model ,including dropout and some other operations, is quite fancy.</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h3><ol>
<li><p>machine learning methods have achieved great result on small image dataset, but still been poor in big dataset.</p>
</li>
<li><p><code>To learn about thousands of objects from millions of images, we need a model with a large learning
capacity.</code></p>
</li>
</ol>
<h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p><code>ImageNet is a dataset of over 15 million labeled high-resolution images belonging to roughly 22,000
categories.</code><br>to show which dataset this paper trained to test its result.</p>
<h3 id="3-The-Architecture"><a href="#3-The-Architecture" class="headerlink" title="3.The Architecture!!!"></a>3.The Architecture!!!</h3><h4 id="1-ReLU-Nonlinearity"><a href="#1-ReLU-Nonlinearity" class="headerlink" title="1.ReLU Nonlinearity"></a>1.ReLU Nonlinearity</h4><p>why we use ReLU instead of sigmoid or tanh function?<br><code>In terms of training time
with gradient descent, these saturating nonlinearities
are much slower than the non-saturating nonlinearity
f(x) = max(0, x).</code></p>
<blockquote>
<p>ps : 当我们使用ReLU函数而不是sigmoid或者tanh函数进行激活时，主要原因在于其更快的速度。当然，我们可以使用Leaky ReLU甚至Randomized Leaky ReLU来防止其它一些问题。还有一些其它的变体，包括PReLU和RReLU。</p>
</blockquote>
<h4 id="2-Training-on-Multiple-GPUs"><a href="#2-Training-on-Multiple-GPUs" class="headerlink" title="2.Training on Multiple GPUs"></a>2.Training on Multiple GPUs</h4><p><code>Current GPUs
are particularly well-suited to cross-GPU parallelization, as they are able to read from and write to
one another’s memory directly, without going through host machine memory.</code>using a method to parallel the training process.Notice the parallelization scheme that is employed in this paper, which are quite inspirsed. </p>
<blockquote>
<p>ps : 在利用多个GPU进行并行处理的时候，需要注意之间的信息传递与交互。如何提高数据之间传输的效率，是能够提高计算速度的关键。</p>
</blockquote>
<h4 id="3-Local-Response-Normalization"><a href="#3-Local-Response-Normalization" class="headerlink" title="3.Local Response Normalization"></a>3.Local Response Normalization</h4><p>using local normalization to aid generation.</p>
<script type="math/tex; mode=display">b_{x,y}^i=a_{x,y}^i/(k+\alpha \sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}(a_{x,y}^i)^2)^\beta</script><blockquote>
<p>ps : 这一小节主要讲解了这个normalization的方式，这个公式的结果展示出来的效果在于，提高泛化能力（即b能更好地代表一个连续性的结果）简单分析三个超参数,k为一个偏移量，使得本身有一个偏移；n在于考虑其连续的范围，考虑泛化能力，在于一个权衡，$<br>\beta$在于调整参数的大小，使得与模型契合。</p>
</blockquote>
<h4 id="4-Overlapping-Pooling"><a href="#4-Overlapping-Pooling" class="headerlink" title="4. Overlapping Pooling"></a>4. Overlapping Pooling</h4><p>using overlapping can make our pooling result more precise than non-overlapping.<code>We generally observe during training that models with overlapping
pooling find it slightly more difficult to overfit</code> </p>
<blockquote>
<p>ps : 我们应该注意一个overlapping 与 non-overlapping之间的平衡，建议是首先不用overlapping，如果得到的结果处于欠拟合状态，则修改而使用overlapping pooling</p>
</blockquote>
<h4 id="5-Overall-Architecture"><a href="#5-Overall-Architecture" class="headerlink" title="5. Overall Architecture"></a>5. Overall Architecture</h4><p>the overall architecture will be shown in figure 1 below.</p>
<blockquote>
<p>ps : 主要理解这个结构一些中间的部分，需要掌握对其的理解并且与前面的相贯通。</p>
</blockquote>
<h3 id="Reducing-Overfitting"><a href="#Reducing-Overfitting" class="headerlink" title="Reducing Overfitting"></a>Reducing Overfitting</h3><p>too many parameters in this model(60 million) are not insufficient to learn.</p>
<h4 id="1-Data-Augmentation"><a href="#1-Data-Augmentation" class="headerlink" title="1.Data Augmentation"></a>1.Data Augmentation</h4><ol>
<li><code>The first form of data augmentation consists of generating image translations and horizontal reflections.</code></li>
<li><code>The second form of data augmentation consists of altering the intensities of the RGB channels in
training images.</code>using PCA on the set.</li>
</ol>
<script type="math/tex; mode=display">[p1,p2,p3][\alpha_1 \lambda_1,\alpha_2 \lambda_2,\alpha_3 \lambda_3]^T</script><blockquote>
<p>ps: 由于原来的网络模型过深，所以需要避免过拟合，第一种方法就是增加数据量，可以通过对图像的一些处理来进行，包括进行图像的裁剪和对颜色进行处理。</p>
</blockquote>
<h4 id="2-Dropout"><a href="#2-Dropout" class="headerlink" title="2.Dropout"></a>2.Dropout</h4><p>dropout 是一个重要的内容，我在附加的部分主要说明，这里就直接跳过。这里也只是运用了这种方法，没有做什么修改。</p>
<h3 id="5-Details-of-learning"><a href="#5-Details-of-learning" class="headerlink" title="5.Details of learning"></a>5.Details of learning</h3><p><code>We trained our models using stochastic gradient descent
with a batch size of 128 examples, momentum of 0.9, and
weight decay of 0.0005.</code></p>
<p><code>the update relu for weight w was</code>:</p>
<script type="math/tex; mode=display">v_{i+1} := 0.9v_i-0.0005 \epsilon w_i - \epsilon <\frac{\partial L}{\partial w}|_{w_i}>_{D_i}</script><script type="math/tex; mode=display">w_{i+1} := w_i+v_{i+1}</script><h3 id="6-Results"><a href="#6-Results" class="headerlink" title="6.Results"></a>6.Results</h3><p>this part is not so necessary, you should look through the paper to learn the result.</p>
<h3 id="7-Discussion"><a href="#7-Discussion" class="headerlink" title="7.Discussion"></a>7.Discussion</h3><p><code>the depth really is important for achieving our results</code>.you can see that, from the discussion in this paper, deep network on image classfication have been aroused. </p>
<h3 id="my-conclusion"><a href="#my-conclusion" class="headerlink" title="my conclusion"></a>my conclusion</h3><p>这篇文章主要提出了AlexNet这种结构，其主要有几个主要的因素构成：</p>
<ol>
<li>使用两个GPU交互训练的网络</li>
<li>使用dropout方法进行正则化的方法</li>
<li>使用深层的深度网络进行学习（这是使用深度神经网络的一个重要的开端，它有后来的工作很大的启发作用）</li>
<li>使用data augmentation来进行数据的预处理，防止过拟合</li>
<li>使用了normalization方法来处理原来的数据，同时采用ReLU激活函数，使得整个计算过程更加快捷，且没有降低最终的效果。</li>
</ol>
<h3 id="发散"><a href="#发散" class="headerlink" title="发散"></a>发散</h3><h4 id="1-dropout"><a href="#1-dropout" class="headerlink" title="1. dropout"></a>1. dropout</h4><h4 id="2-深层的神经网络的问题及其解决"><a href="#2-深层的神经网络的问题及其解决" class="headerlink" title="2.深层的神经网络的问题及其解决"></a>2.深层的神经网络的问题及其解决</h4>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2019/04/23/龙芯杯6/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="禾声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/23/龙芯杯6/" itemprop="url">龙芯杯备战4</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-23T19:31:25+08:00">
                2019-04-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="龙芯杯备战4"><a href="#龙芯杯备战4" class="headerlink" title="龙芯杯备战4"></a>龙芯杯备战4</h1><h2 id="国科大试验系统迁移-LAB3-1"><a href="#国科大试验系统迁移-LAB3-1" class="headerlink" title="国科大试验系统迁移  LAB3-1"></a>国科大试验系统迁移  LAB3-1</h2><h3 id="代码对比"><a href="#代码对比" class="headerlink" title="代码对比"></a>代码对比</h3><h4 id="1-接口"><a href="#1-接口" class="headerlink" title="1.接口"></a>1.接口</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//机组cpu</span></span><br><span class="line"><span class="keyword">module</span> pipeline_cpu(  </span><br><span class="line">    <span class="keyword">input</span> clk,           </span><br><span class="line">    <span class="keyword">input</span> resetn,       </span><br><span class="line">    </span><br><span class="line">    <span class="comment">//display data</span></span><br><span class="line">    <span class="keyword">input</span>  [ <span class="number">4</span>:<span class="number">0</span>] rf_addr,<span class="comment">//regfile 的测试地址（用于测试regfile)</span></span><br><span class="line">    <span class="keyword">input</span>  [<span class="number">31</span>:<span class="number">0</span>] mem_addr,<span class="comment">//memory的地址，用于取出数据</span></span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] rf_data,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] mem_data,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] IF_pc,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] IF_inst,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] ID_pc,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] EXE_pc,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] MEM_pc,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] WB_pc,</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//最后需要用来检测的数据（检测5级的valid信号以及wb的数据)</span></span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] cpu_5_valid,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] HI_data,</span><br><span class="line">    <span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] LO_data</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//国科大 CPU</span></span><br><span class="line"><span class="keyword">module</span> mycpu_top(</span><br><span class="line">	<span class="keyword">input</span>         clk,<span class="comment">//时钟</span></span><br><span class="line">	<span class="keyword">input</span>         resetn,<span class="comment">//复位信号</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//ram  指令</span></span><br><span class="line">	<span class="keyword">input</span> [<span class="number">31</span>:<span class="number">0</span>]  inst_sram_rdata,<span class="comment">//ram 读数据  -&gt; inst(所得到的指令)</span></span><br><span class="line">	<span class="keyword">output</span>        inst_sram_en,<span class="comment">//ram 使能信号   (需要自己添加这一信号的赋值)    ----&gt;还未修改</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">3</span>:<span class="number">0</span>]  inst_sram_wen,<span class="comment">//ram 字节写使能信号 (在机组的流水线中，并未实现)  ---&gt; 还未修改</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] inst_sram_addr,<span class="comment">//ram 读写地址，字节寻址  -&gt; pc  (inst_addr)   </span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] inst_sram_wdata,<span class="comment">//ram 写数据  (所需要修改的数据指令)    ---&gt; 还未修改</span></span><br><span class="line"><span class="comment">//ram  数据    -&gt;类似于inst_sram   可以直接在mem.v阶段使用</span></span><br><span class="line">	<span class="keyword">input</span> [<span class="number">31</span>:<span class="number">0</span>]  data_sram_rdata,<span class="comment">//ram 读数据</span></span><br><span class="line">	<span class="keyword">output</span>        data_sram_en,<span class="comment">//ram 使能信号，高电平有效    ----&gt; 还未修改</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">3</span>:<span class="number">0</span>]  data_sram_wen,<span class="comment">//ram 字节写使能信号</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] data_sram_addr,<span class="comment">//ram 读写地址</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] data_sram_wdata,<span class="comment">//ram 写数据 </span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] debug_wb_pc,<span class="comment">//wb级的PC，因而需要mycpu 的PC 一路带到写回级</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">3</span>:<span class="number">0</span>]  debug_wb_rf_wen,<span class="comment">// 写回级写寄存器堆(regfiles) 的写使能，为字节写使能</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">4</span>:<span class="number">0</span>]  debug_wb_rf_wnum,<span class="comment">// 写回级写regfiles的目的寄存器号</span></span><br><span class="line">	<span class="keyword">output</span> [<span class="number">31</span>:<span class="number">0</span>] debug_wb_rf_wdata<span class="comment">// 写回级写regfiles的写数据</span></span><br><span class="line">	);</span><br></pre></td></tr></table></figure>
<h4 id="2-regfile"><a href="#2-regfile" class="headerlink" title="2.regfile"></a>2.regfile</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//regilfe 中原机组代码有test，但是由于在修改后的cpu后没有test的input信号，所以修改后直接删除就好</span></span><br><span class="line"><span class="meta">`<span class="meta-keyword">timescale</span> 1ns / 1ps</span></span><br><span class="line"><span class="comment">//*************************************************************************</span></span><br><span class="line"><span class="comment">//  LOONGSON</span></span><br><span class="line"><span class="comment">//  2016-04-14</span></span><br><span class="line"><span class="comment">//*************************************************************************</span></span><br><span class="line"><span class="keyword">module</span> regfile(</span><br><span class="line">    <span class="keyword">input</span>             clk,</span><br><span class="line">    <span class="keyword">input</span>             wen,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">4</span> :<span class="number">0</span>] raddr1,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">4</span> :<span class="number">0</span>] raddr2,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">4</span> :<span class="number">0</span>] waddr,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">31</span>:<span class="number">0</span>] wdata,</span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>] rdata1,</span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>] rdata2,</span><br><span class="line">    <span class="keyword">input</span>      [<span class="number">4</span> :<span class="number">0</span>] test_addr,</span><br><span class="line">    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>] test_data</span><br><span class="line">    );</span><br><span class="line">    <span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>] rf[<span class="number">31</span>:<span class="number">0</span>];</span><br><span class="line">     </span><br><span class="line">    <span class="comment">// three ported register file</span></span><br><span class="line">    <span class="comment">// read two ports combinationally</span></span><br><span class="line">    <span class="comment">// write third port on rising edge of clock</span></span><br><span class="line">    <span class="comment">// register 0 hardwired to 0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">always</span> @(<span class="keyword">posedge</span> clk)</span><br><span class="line">    <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">if</span> (wen) </span><br><span class="line">        <span class="keyword">begin</span></span><br><span class="line">            rf[waddr] &lt;= wdata;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">     </span><br><span class="line">    <span class="keyword">always</span> @(*)</span><br><span class="line">    <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">case</span> (raddr1)</span><br><span class="line">            <span class="number">5'd1</span> : rdata1 &lt;= rf[<span class="number">1</span> ];</span><br><span class="line">            <span class="number">5'd2</span> : rdata1 &lt;= rf[<span class="number">2</span> ];</span><br><span class="line">            <span class="number">5'd3</span> : rdata1 &lt;= rf[<span class="number">3</span> ];</span><br><span class="line">            <span class="number">5'd4</span> : rdata1 &lt;= rf[<span class="number">4</span> ];</span><br><span class="line">            <span class="number">5'd5</span> : rdata1 &lt;= rf[<span class="number">5</span> ];</span><br><span class="line">            <span class="number">5'd6</span> : rdata1 &lt;= rf[<span class="number">6</span> ];</span><br><span class="line">            <span class="number">5'd7</span> : rdata1 &lt;= rf[<span class="number">7</span> ];</span><br><span class="line">            <span class="number">5'd8</span> : rdata1 &lt;= rf[<span class="number">8</span> ];</span><br><span class="line">            <span class="number">5'd9</span> : rdata1 &lt;= rf[<span class="number">9</span> ];</span><br><span class="line">            <span class="number">5'd10</span>: rdata1 &lt;= rf[<span class="number">10</span>];</span><br><span class="line">            <span class="number">5'd11</span>: rdata1 &lt;= rf[<span class="number">11</span>];</span><br><span class="line">            <span class="number">5'd12</span>: rdata1 &lt;= rf[<span class="number">12</span>];</span><br><span class="line">            <span class="number">5'd13</span>: rdata1 &lt;= rf[<span class="number">13</span>];</span><br><span class="line">            <span class="number">5'd14</span>: rdata1 &lt;= rf[<span class="number">14</span>];</span><br><span class="line">            <span class="number">5'd15</span>: rdata1 &lt;= rf[<span class="number">15</span>];</span><br><span class="line">            <span class="number">5'd16</span>: rdata1 &lt;= rf[<span class="number">16</span>];</span><br><span class="line">            <span class="number">5'd17</span>: rdata1 &lt;= rf[<span class="number">17</span>];</span><br><span class="line">            <span class="number">5'd18</span>: rdata1 &lt;= rf[<span class="number">18</span>];</span><br><span class="line">            <span class="number">5'd19</span>: rdata1 &lt;= rf[<span class="number">19</span>];</span><br><span class="line">            <span class="number">5'd20</span>: rdata1 &lt;= rf[<span class="number">20</span>];</span><br><span class="line">            <span class="number">5'd21</span>: rdata1 &lt;= rf[<span class="number">21</span>];</span><br><span class="line">            <span class="number">5'd22</span>: rdata1 &lt;= rf[<span class="number">22</span>];</span><br><span class="line">            <span class="number">5'd23</span>: rdata1 &lt;= rf[<span class="number">23</span>];</span><br><span class="line">            <span class="number">5'd24</span>: rdata1 &lt;= rf[<span class="number">24</span>];</span><br><span class="line">            <span class="number">5'd25</span>: rdata1 &lt;= rf[<span class="number">25</span>];</span><br><span class="line">            <span class="number">5'd26</span>: rdata1 &lt;= rf[<span class="number">26</span>];</span><br><span class="line">            <span class="number">5'd27</span>: rdata1 &lt;= rf[<span class="number">27</span>];</span><br><span class="line">            <span class="number">5'd28</span>: rdata1 &lt;= rf[<span class="number">28</span>];</span><br><span class="line">            <span class="number">5'd29</span>: rdata1 &lt;= rf[<span class="number">29</span>];</span><br><span class="line">            <span class="number">5'd30</span>: rdata1 &lt;= rf[<span class="number">30</span>];</span><br><span class="line">            <span class="number">5'd31</span>: rdata1 &lt;= rf[<span class="number">31</span>];</span><br><span class="line">            <span class="keyword">default</span> : rdata1 &lt;= <span class="number">32'd0</span>;</span><br><span class="line">        <span class="keyword">endcase</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">always</span> @(*)</span><br><span class="line">    <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">case</span> (raddr2)</span><br><span class="line">            <span class="number">5'd1</span> : rdata2 &lt;= rf[<span class="number">1</span> ];</span><br><span class="line">            <span class="number">5'd2</span> : rdata2 &lt;= rf[<span class="number">2</span> ];</span><br><span class="line">            <span class="number">5'd3</span> : rdata2 &lt;= rf[<span class="number">3</span> ];</span><br><span class="line">            <span class="number">5'd4</span> : rdata2 &lt;= rf[<span class="number">4</span> ];</span><br><span class="line">            <span class="number">5'd5</span> : rdata2 &lt;= rf[<span class="number">5</span> ];</span><br><span class="line">            <span class="number">5'd6</span> : rdata2 &lt;= rf[<span class="number">6</span> ];</span><br><span class="line">            <span class="number">5'd7</span> : rdata2 &lt;= rf[<span class="number">7</span> ];</span><br><span class="line">            <span class="number">5'd8</span> : rdata2 &lt;= rf[<span class="number">8</span> ];</span><br><span class="line">            <span class="number">5'd9</span> : rdata2 &lt;= rf[<span class="number">9</span> ];</span><br><span class="line">            <span class="number">5'd10</span>: rdata2 &lt;= rf[<span class="number">10</span>];</span><br><span class="line">            <span class="number">5'd11</span>: rdata2 &lt;= rf[<span class="number">11</span>];</span><br><span class="line">            <span class="number">5'd12</span>: rdata2 &lt;= rf[<span class="number">12</span>];</span><br><span class="line">            <span class="number">5'd13</span>: rdata2 &lt;= rf[<span class="number">13</span>];</span><br><span class="line">            <span class="number">5'd14</span>: rdata2 &lt;= rf[<span class="number">14</span>];</span><br><span class="line">            <span class="number">5'd15</span>: rdata2 &lt;= rf[<span class="number">15</span>];</span><br><span class="line">            <span class="number">5'd16</span>: rdata2 &lt;= rf[<span class="number">16</span>];</span><br><span class="line">            <span class="number">5'd17</span>: rdata2 &lt;= rf[<span class="number">17</span>];</span><br><span class="line">            <span class="number">5'd18</span>: rdata2 &lt;= rf[<span class="number">18</span>];</span><br><span class="line">            <span class="number">5'd19</span>: rdata2 &lt;= rf[<span class="number">19</span>];</span><br><span class="line">            <span class="number">5'd20</span>: rdata2 &lt;= rf[<span class="number">20</span>];</span><br><span class="line">            <span class="number">5'd21</span>: rdata2 &lt;= rf[<span class="number">21</span>];</span><br><span class="line">            <span class="number">5'd22</span>: rdata2 &lt;= rf[<span class="number">22</span>];</span><br><span class="line">            <span class="number">5'd23</span>: rdata2 &lt;= rf[<span class="number">23</span>];</span><br><span class="line">            <span class="number">5'd24</span>: rdata2 &lt;= rf[<span class="number">24</span>];</span><br><span class="line">            <span class="number">5'd25</span>: rdata2 &lt;= rf[<span class="number">25</span>];</span><br><span class="line">            <span class="number">5'd26</span>: rdata2 &lt;= rf[<span class="number">26</span>];</span><br><span class="line">            <span class="number">5'd27</span>: rdata2 &lt;= rf[<span class="number">27</span>];</span><br><span class="line">            <span class="number">5'd28</span>: rdata2 &lt;= rf[<span class="number">28</span>];</span><br><span class="line">            <span class="number">5'd29</span>: rdata2 &lt;= rf[<span class="number">29</span>];</span><br><span class="line">            <span class="number">5'd30</span>: rdata2 &lt;= rf[<span class="number">30</span>];</span><br><span class="line">            <span class="number">5'd31</span>: rdata2 &lt;= rf[<span class="number">31</span>];</span><br><span class="line">            <span class="keyword">default</span> : rdata2 &lt;= <span class="number">32'd0</span>;</span><br><span class="line">        <span class="keyword">endcase</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">always</span> @(*)</span><br><span class="line">    <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">case</span> (test_addr)</span><br><span class="line">            <span class="number">5'd1</span> : test_data &lt;= rf[<span class="number">1</span> ];</span><br><span class="line">            <span class="number">5'd2</span> : test_data &lt;= rf[<span class="number">2</span> ];</span><br><span class="line">            <span class="number">5'd3</span> : test_data &lt;= rf[<span class="number">3</span> ];</span><br><span class="line">            <span class="number">5'd4</span> : test_data &lt;= rf[<span class="number">4</span> ];</span><br><span class="line">            <span class="number">5'd5</span> : test_data &lt;= rf[<span class="number">5</span> ];</span><br><span class="line">            <span class="number">5'd6</span> : test_data &lt;= rf[<span class="number">6</span> ];</span><br><span class="line">            <span class="number">5'd7</span> : test_data &lt;= rf[<span class="number">7</span> ];</span><br><span class="line">            <span class="number">5'd8</span> : test_data &lt;= rf[<span class="number">8</span> ];</span><br><span class="line">            <span class="number">5'd9</span> : test_data &lt;= rf[<span class="number">9</span> ];</span><br><span class="line">            <span class="number">5'd10</span>: test_data &lt;= rf[<span class="number">10</span>];</span><br><span class="line">            <span class="number">5'd11</span>: test_data &lt;= rf[<span class="number">11</span>];</span><br><span class="line">            <span class="number">5'd12</span>: test_data &lt;= rf[<span class="number">12</span>];</span><br><span class="line">            <span class="number">5'd13</span>: test_data &lt;= rf[<span class="number">13</span>];</span><br><span class="line">            <span class="number">5'd14</span>: test_data &lt;= rf[<span class="number">14</span>];</span><br><span class="line">            <span class="number">5'd15</span>: test_data &lt;= rf[<span class="number">15</span>];</span><br><span class="line">            <span class="number">5'd16</span>: test_data &lt;= rf[<span class="number">16</span>];</span><br><span class="line">            <span class="number">5'd17</span>: test_data &lt;= rf[<span class="number">17</span>];</span><br><span class="line">            <span class="number">5'd18</span>: test_data &lt;= rf[<span class="number">18</span>];</span><br><span class="line">            <span class="number">5'd19</span>: test_data &lt;= rf[<span class="number">19</span>];</span><br><span class="line">            <span class="number">5'd20</span>: test_data &lt;= rf[<span class="number">20</span>];</span><br><span class="line">            <span class="number">5'd21</span>: test_data &lt;= rf[<span class="number">21</span>];</span><br><span class="line">            <span class="number">5'd22</span>: test_data &lt;= rf[<span class="number">22</span>];</span><br><span class="line">            <span class="number">5'd23</span>: test_data &lt;= rf[<span class="number">23</span>];</span><br><span class="line">            <span class="number">5'd24</span>: test_data &lt;= rf[<span class="number">24</span>];</span><br><span class="line">            <span class="number">5'd25</span>: test_data &lt;= rf[<span class="number">25</span>];</span><br><span class="line">            <span class="number">5'd26</span>: test_data &lt;= rf[<span class="number">26</span>];</span><br><span class="line">            <span class="number">5'd27</span>: test_data &lt;= rf[<span class="number">27</span>];</span><br><span class="line">            <span class="number">5'd28</span>: test_data &lt;= rf[<span class="number">28</span>];</span><br><span class="line">            <span class="number">5'd29</span>: test_data &lt;= rf[<span class="number">29</span>];</span><br><span class="line">            <span class="number">5'd30</span>: test_data &lt;= rf[<span class="number">30</span>];</span><br><span class="line">            <span class="number">5'd31</span>: test_data &lt;= rf[<span class="number">31</span>];</span><br><span class="line">            <span class="keyword">default</span> : test_data &lt;= <span class="number">32'd0</span>;</span><br><span class="line">        <span class="keyword">endcase</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure>
<h4 id="其它过程"><a href="#其它过程" class="headerlink" title="其它过程"></a>其它过程</h4><blockquote>
<p>对于整个迁移的其它过程，都主要是按照接口来做，没有什么特别的地方需要说明。</p>
<p>另外需要说明的一点是，在机组实现的流水线cpu中，是在整个cpu的总线中进行调用inst_sram和data_sram，而在国科大的lab中，由更高一层的soc_lite_top.v进行调用和控制，而my_cpu中只需要调用fetch,decode,exe,mem,wb以及regfile进行执行即可。</p>
</blockquote>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//*************************************************************************</span></span><br><span class="line"><span class="comment">//   &gt; File Name   : soc_top.v</span></span><br><span class="line"><span class="comment">//   &gt; Description : SoC, included cpu, 2 x 3 bridge,</span></span><br><span class="line"><span class="comment">//                   inst ram, confreg, data ram</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">//           -------------------------</span></span><br><span class="line"><span class="comment">//           |           cpu         |</span></span><br><span class="line"><span class="comment">//           -------------------------</span></span><br><span class="line"><span class="comment">//         inst|                  | data</span></span><br><span class="line"><span class="comment">//             |                  | </span></span><br><span class="line"><span class="comment">//             |        ---------------------</span></span><br><span class="line"><span class="comment">//             |        |    1 x 2 bridge   |</span></span><br><span class="line"><span class="comment">//             |        ---------------------</span></span><br><span class="line"><span class="comment">//             |             |            |           </span></span><br><span class="line"><span class="comment">//             |             |            |           </span></span><br><span class="line"><span class="comment">//      -------------   -----------   -----------</span></span><br><span class="line"><span class="comment">//      | inst ram  |   | data ram|   | confreg |</span></span><br><span class="line"><span class="comment">//      -------------   -----------   -----------</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//   &gt; Author      : LOONGSON</span></span><br><span class="line"><span class="comment">//   &gt; Date        : 2017-08-04</span></span><br><span class="line"><span class="comment">//*************************************************************************</span></span><br></pre></td></tr></table></figure>
<p>其主要框架如图所示，需要更具体地进行了解</p>
<h4 id="IP核锁定解决方案"><a href="#IP核锁定解决方案" class="headerlink" title="IP核锁定解决方案"></a>IP核锁定解决方案</h4><blockquote>
<p>由于从旧的vivado版本迁移到新的版本中，会遇到IP核锁定的问题，所以我跑simulation的时候，发现跑不过，我开始以为是coe文件的问题，后来重新导入coe文件后，发现还是报错，于是我发现，是IP核锁定了。</p>
<p>首先查看网上的解决方案，在工具栏找到report-&gt;Report IP Status,然后发现没办法upgrade selected,这个时候点击右键，可以发现有UPGRADE IP的选项，果断选择，然后好像就OK了。容我跑一跑simulation(时间有点长，现在很慌~~)什么信息也不报一个</p>
</blockquote>
<h4 id="其它还需要修改的错误"><a href="#其它还需要修改的错误" class="headerlink" title="其它还需要修改的错误"></a>其它还需要修改的错误</h4><p>wb端实际上还需要修改，同时，并没有将所有需要的output实现，目前还有很多X与Z的存在，需要进一步修改其中的代码。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Leliyliu</p>
              <p class="site-description motion-element" itemprop="description">record</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">33</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leliyliu</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
