<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  pytorch,">










<meta name="description" content="[TOC] åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  task2 æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ï¼šå°†ä¸€æ®µæ–‡æœ¬ä»ä¸€ç§è¯­è¨€è‡ªåŠ¨ç¿»è¯‘ä¸ºå¦ä¸€ç§è¯­è¨€ï¼Œç”¨ç¥ç»ç½‘ç»œè§£å†³è¿™ä¸ªé—®é¢˜é€šå¸¸ç§°ä¸ºç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰ã€‚ ä¸»è¦ç‰¹å¾ï¼šè¾“å‡ºæ˜¯å•è¯åºåˆ—è€Œä¸æ˜¯å•ä¸ªå•è¯ã€‚ è¾“å‡ºåºåˆ—çš„é•¿åº¦å¯èƒ½ä¸æºåºåˆ—çš„é•¿åº¦ä¸åŒã€‚ æ•°æ®é¢„å¤„ç†è¿‡ç¨‹å¯¹äºä¸€èˆ¬çš„æ•°æ®é¢„å¤„ç†è¿‡ç¨‹ï¼Œé¦–å…ˆè¦ä¿è¯ç¼–ç æ–¹å¼çš„æ­£ç¡®ã€‚ç„¶åéœ€è¦è½¬æ¢å¤§å°å†™ï¼Œè¿™é‡Œæ²¡æœ‰è®¸å¤šå¤šä½™çš„å¤„ç†æ“ä½œã€‚ è½½å…¥æ•°æ®é›†">
<meta name="keywords" content="åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  pytorch">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch2">
<meta property="og:url" content="http://leliyliu.github.io/2020/02/16/pytorch2/index.html">
<meta property="og:site_name" content="ç¦¾å£°">
<meta property="og:description" content="[TOC] åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  task2 æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ï¼šå°†ä¸€æ®µæ–‡æœ¬ä»ä¸€ç§è¯­è¨€è‡ªåŠ¨ç¿»è¯‘ä¸ºå¦ä¸€ç§è¯­è¨€ï¼Œç”¨ç¥ç»ç½‘ç»œè§£å†³è¿™ä¸ªé—®é¢˜é€šå¸¸ç§°ä¸ºç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰ã€‚ ä¸»è¦ç‰¹å¾ï¼šè¾“å‡ºæ˜¯å•è¯åºåˆ—è€Œä¸æ˜¯å•ä¸ªå•è¯ã€‚ è¾“å‡ºåºåˆ—çš„é•¿åº¦å¯èƒ½ä¸æºåºåˆ—çš„é•¿åº¦ä¸åŒã€‚ æ•°æ®é¢„å¤„ç†è¿‡ç¨‹å¯¹äºä¸€èˆ¬çš„æ•°æ®é¢„å¤„ç†è¿‡ç¨‹ï¼Œé¦–å…ˆè¦ä¿è¯ç¼–ç æ–¹å¼çš„æ­£ç¡®ã€‚ç„¶åéœ€è¦è½¬æ¢å¤§å°å†™ï¼Œè¿™é‡Œæ²¡æœ‰è®¸å¤šå¤šä½™çš„å¤„ç†æ“ä½œã€‚ è½½å…¥æ•°æ®é›†">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5jcat3c8m.png?imageView2/0/w/640/h/640">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5jc7a53pt.png?imageView2/0/w/640/h/640">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5jccjhkii.png?imageView2/0/w/500/h/500">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5km4dwgf9.PNG?imageView2/0/w/960/h/960">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5km7o8z93.PNG?imageView2/0/w/800/h/800">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5km8dihlr.PNG?imageView2/0/w/800/h/800">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5kpbj2cj5.png?imageView2/0/w/960/h/960">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5kpckv38q.png?imageView2/0/w/320/h/320">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5kpcsozid.png?imageView2/0/w/640/h/640">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5kpe0lu38.png?imageView2/0/w/640/h/640">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5l6vut7h1.png?imageView2/0/w/640/h/640">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5l6u1p5vy.png?imageView2/0/w/960/h/960">
<meta property="og:image" content="https://cdn.kesci.com/upload/image/q5l6uortw.png?imageView2/0/w/640/h/640">
<meta property="og:updated_time" content="2020-02-16T12:00:43.589Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="pytorch2">
<meta name="twitter:description" content="[TOC] åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  task2 æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ï¼šå°†ä¸€æ®µæ–‡æœ¬ä»ä¸€ç§è¯­è¨€è‡ªåŠ¨ç¿»è¯‘ä¸ºå¦ä¸€ç§è¯­è¨€ï¼Œç”¨ç¥ç»ç½‘ç»œè§£å†³è¿™ä¸ªé—®é¢˜é€šå¸¸ç§°ä¸ºç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰ã€‚ ä¸»è¦ç‰¹å¾ï¼šè¾“å‡ºæ˜¯å•è¯åºåˆ—è€Œä¸æ˜¯å•ä¸ªå•è¯ã€‚ è¾“å‡ºåºåˆ—çš„é•¿åº¦å¯èƒ½ä¸æºåºåˆ—çš„é•¿åº¦ä¸åŒã€‚ æ•°æ®é¢„å¤„ç†è¿‡ç¨‹å¯¹äºä¸€èˆ¬çš„æ•°æ®é¢„å¤„ç†è¿‡ç¨‹ï¼Œé¦–å…ˆè¦ä¿è¯ç¼–ç æ–¹å¼çš„æ­£ç¡®ã€‚ç„¶åéœ€è¦è½¬æ¢å¤§å°å†™ï¼Œè¿™é‡Œæ²¡æœ‰è®¸å¤šå¤šä½™çš„å¤„ç†æ“ä½œã€‚ è½½å…¥æ•°æ®é›†">
<meta name="twitter:image" content="https://cdn.kesci.com/upload/image/q5jcat3c8m.png?imageView2/0/w/640/h/640">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://leliyliu.github.io/2020/02/16/pytorch2/">





  <title>pytorch2 | ç¦¾å£°</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ç¦¾å£°</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">in the arm of the angel, fly away</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://leliyliu.github.io/2020/02/16/pytorch2/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leliyliu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç¦¾å£°">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">pytorch2</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-16T19:59:51+08:00">
                2020-02-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>[TOC]</p>
<h1 id="åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -task2"><a href="#åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -task2" class="headerlink" title="åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  task2"></a>åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  task2</h1><hr>
<h2 id="æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸"><a href="#æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸" class="headerlink" title="æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸"></a>æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸</h2><h2 id="æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯"><a href="#æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯" class="headerlink" title="æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯"></a>æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯</h2><p>æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ï¼šå°†ä¸€æ®µæ–‡æœ¬ä»ä¸€ç§è¯­è¨€è‡ªåŠ¨ç¿»è¯‘ä¸ºå¦ä¸€ç§è¯­è¨€ï¼Œç”¨ç¥ç»ç½‘ç»œè§£å†³è¿™ä¸ªé—®é¢˜é€šå¸¸ç§°ä¸ºç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰ã€‚ ä¸»è¦ç‰¹å¾ï¼šè¾“å‡ºæ˜¯å•è¯åºåˆ—è€Œä¸æ˜¯å•ä¸ªå•è¯ã€‚ è¾“å‡ºåºåˆ—çš„é•¿åº¦å¯èƒ½ä¸æºåºåˆ—çš„é•¿åº¦ä¸åŒã€‚</p>
<h3 id="æ•°æ®é¢„å¤„ç†è¿‡ç¨‹"><a href="#æ•°æ®é¢„å¤„ç†è¿‡ç¨‹" class="headerlink" title="æ•°æ®é¢„å¤„ç†è¿‡ç¨‹"></a>æ•°æ®é¢„å¤„ç†è¿‡ç¨‹</h3><p>å¯¹äºä¸€èˆ¬çš„æ•°æ®é¢„å¤„ç†è¿‡ç¨‹ï¼Œé¦–å…ˆè¦ä¿è¯ç¼–ç æ–¹å¼çš„æ­£ç¡®ã€‚ç„¶åéœ€è¦è½¬æ¢å¤§å°å†™ï¼Œè¿™é‡Œæ²¡æœ‰è®¸å¤šå¤šä½™çš„å¤„ç†æ“ä½œã€‚</p>
<h4 id="è½½å…¥æ•°æ®é›†"><a href="#è½½å…¥æ•°æ®é›†" class="headerlink" title="è½½å…¥æ•°æ®é›†"></a>è½½å…¥æ•°æ®é›†</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pad</span><span class="params">(line, max_len, padding_token)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(line) &gt; max_len:</span><br><span class="line">        <span class="keyword">return</span> line[:max_len]</span><br><span class="line">    <span class="keyword">return</span> line + [padding_token] * (max_len - len(line))</span><br><span class="line">pad(src_vocab[source[<span class="number">0</span>]], <span class="number">10</span>, src_vocab.pad)</span><br></pre></td></tr></table></figure>
<p>è¿™ä¸ªpad å‡½æ•°çš„ä½œç”¨åœ¨äºä¿æŒæ¯ä¸ªå¥å­çš„é•¿åº¦æ˜¯ä¸€æ ·çš„ï¼Œå¦‚æœæ˜¯å¤§äºçš„è¯ï¼Œé‚£ä¹ˆå°±è¿›è¡Œé˜¶æ®µï¼Œå¦åˆ™è¿›è¡Œç›¸åº”çš„è¡¥è¶³ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_array</span><span class="params">(lines, vocab, max_len, is_source)</span>:</span></span><br><span class="line">    lines = [vocab[line] <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> is_source:</span><br><span class="line">        lines = [[vocab.bos] + line + [vocab.eos] <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    array = torch.tensor([pad(line, max_len, vocab.pad) <span class="keyword">for</span> line <span class="keyword">in</span> lines])</span><br><span class="line">    valid_len = (array != vocab.pad).sum(<span class="number">1</span>) <span class="comment">#ç¬¬ä¸€ä¸ªç»´åº¦</span></span><br><span class="line">    <span class="keyword">return</span> array, valid_len</span><br></pre></td></tr></table></figure>
<p>æ³¨æ„è¿™é‡Œå…³äºæœ‰æ•ˆé•¿åº¦çš„è®¡ç®—ï¼Œä¹Ÿå°±æ˜¯è®¡ç®—éè¡¥è¶³çš„é•¿åº¦ã€‚</p>
<h3 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h3><p>å…¶ç»“æ„æ˜¯å¦‚æ­¤è¡¨ç¤ºçš„ï¼Œå³æ‰€æœ‰çš„å¯èƒ½æ˜¯ä»¥è¿™æ ·ä¸€ç§æ–¹å¼æ˜¾ç°å‡ºæ¥</p>
<p><img src="https://cdn.kesci.com/upload/image/q5jcat3c8m.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<p>å› ä¸ºæœ¬èº«çš„RNNçš„ç½‘ç»œç»“æ„ä¸èƒ½ä¿æŒå…·ä½“çš„ç¿»è¯‘è¿‡ç¨‹ä¸­é•¿åº¦çš„å˜åŒ–ï¼Œé‚£ä¹ˆè¦è¾¾åˆ°è¿™æ ·çš„ç›®æ ‡ï¼Œä½¿ç”¨äº†è¿™æ ·ä¸€ç§æ–¹å¼ï¼Œå³é¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œäº†ç¼–ç ï¼Œç„¶åè¿›è¡Œè§£ç åè¾“å‡ºã€‚</p>
<h4 id="Sequence-to-Sequence-æ¨¡å‹"><a href="#Sequence-to-Sequence-æ¨¡å‹" class="headerlink" title="Sequence to Sequence æ¨¡å‹"></a>Sequence to Sequence æ¨¡å‹</h4><p><img src="https://cdn.kesci.com/upload/image/q5jc7a53pt.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<p><img src="https://cdn.kesci.com/upload/image/q5jccjhkii.png?imageView2/0/w/500/h/500" alt="Image Name"></p>
<p>è¿™é‡Œè¿›è¡Œäº†ç›¸åº”çš„embeddingï¼Œæ˜¯å°†ç›¸åº”çš„è¾“å…¥è½¬æ¢ä¸ºè¯å‘é‡æ¥ä½œä¸ºç›¸åº”çš„è¾“å…¥ã€‚è¯å‘é‡çš„é•¿åº¦æ˜¯ç›¸åŒçš„ç»´åº¦ã€‚</p>
<h4 id="è®­ç»ƒæ¨¡å‹å’Œæµ‹è¯•æ¨¡å‹"><a href="#è®­ç»ƒæ¨¡å‹å’Œæµ‹è¯•æ¨¡å‹" class="headerlink" title="è®­ç»ƒæ¨¡å‹å’Œæµ‹è¯•æ¨¡å‹"></a>è®­ç»ƒæ¨¡å‹å’Œæµ‹è¯•æ¨¡å‹</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch7</span><span class="params">(model, data_iter, lr, num_epochs, device)</span>:</span>  <span class="comment"># Saved in d2l</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=lr)</span><br><span class="line">    loss = MaskedSoftmaxCELoss()</span><br><span class="line">    tic = time.time()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, num_epochs+<span class="number">1</span>):</span><br><span class="line">        l_sum, num_tokens_sum = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> data_iter:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            X, X_vlen, Y, Y_vlen = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> batch]</span><br><span class="line">            Y_input, Y_label, Y_vlen = Y[:,:<span class="number">-1</span>], Y[:,<span class="number">1</span>:], Y_vlen<span class="number">-1</span></span><br><span class="line">            </span><br><span class="line">            Y_hat, _ = model(X, Y_input, X_vlen, Y_vlen)</span><br><span class="line">            l = loss(Y_hat, Y_label, Y_vlen).sum()</span><br><span class="line">            l.backward()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                d2l.grad_clipping_nn(model, <span class="number">5</span>, device)</span><br><span class="line">            num_tokens = Y_vlen.sum().item()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            l_sum += l.sum().item()</span><br><span class="line">            num_tokens_sum += num_tokens</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"epoch &#123;0:4d&#125;,loss &#123;1:.3f&#125;, time &#123;2:.1f&#125; sec"</span>.format( </span><br><span class="line">                  epoch, (l_sum/num_tokens_sum), time.time()-tic))</span><br><span class="line">            tic = time.time()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">translate_ch7</span><span class="params">(model, src_sentence, src_vocab, tgt_vocab, max_len, device)</span>:</span></span><br><span class="line">    src_tokens = src_vocab[src_sentence.lower().split(<span class="string">' '</span>)]</span><br><span class="line">    src_len = len(src_tokens)</span><br><span class="line">    <span class="keyword">if</span> src_len &lt; max_len:</span><br><span class="line">        src_tokens += [src_vocab.pad] * (max_len - src_len)</span><br><span class="line">    enc_X = torch.tensor(src_tokens, device=device)</span><br><span class="line">    enc_valid_length = torch.tensor([src_len], device=device)</span><br><span class="line">    <span class="comment"># use expand_dim to add the batch_size dimension.</span></span><br><span class="line">    enc_outputs = model.encoder(enc_X.unsqueeze(dim=<span class="number">0</span>), enc_valid_length)</span><br><span class="line">    dec_state = model.decoder.init_state(enc_outputs, enc_valid_length)</span><br><span class="line">    dec_X = torch.tensor([tgt_vocab.bos], device=device).unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">    predict_tokens = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(max_len):</span><br><span class="line">        Y, dec_state = model.decoder(dec_X, dec_state)</span><br><span class="line">        <span class="comment"># The token with highest score is used as the next time step input.</span></span><br><span class="line">        dec_X = Y.argmax(dim=<span class="number">2</span>)</span><br><span class="line">        py = dec_X.squeeze(dim=<span class="number">0</span>).int().item()</span><br><span class="line">        <span class="keyword">if</span> py == tgt_vocab.eos:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        predict_tokens.append(py)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">' '</span>.join(tgt_vocab.to_tokens(predict_tokens))</span><br></pre></td></tr></table></figure>
<h2 id="æ³¨æ„åŠ›æœºåˆ¶"><a href="#æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="æ³¨æ„åŠ›æœºåˆ¶"></a>æ³¨æ„åŠ›æœºåˆ¶</h2><p><img src="https://cdn.kesci.com/upload/image/q5km4dwgf9.PNG?imageView2/0/w/960/h/960" alt="Image Name"></p>
<p>Attention æ˜¯ä¸€ç§é€šç”¨çš„å¸¦æƒæ± åŒ–æ–¹æ³•ï¼Œè¾“å…¥ç”±ä¸¤éƒ¨åˆ†æ„æˆï¼šè¯¢é—®ï¼ˆqueryï¼‰å’Œé”®å€¼å¯¹ï¼ˆkey-value pairsï¼‰ã€‚$ğ¤_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘˜}, ğ¯_ğ‘–âˆˆâ„^{ğ‘‘_ğ‘£}$. Query  $ğªâˆˆâ„^{ğ‘‘_ğ‘}$ , attention layerå¾—åˆ°è¾“å‡ºä¸valueçš„ç»´åº¦ä¸€è‡´ $ğ¨âˆˆâ„^{ğ‘‘_ğ‘£}$. å¯¹äºä¸€ä¸ªqueryæ¥è¯´ï¼Œattention layer ä¼šä¸æ¯ä¸€ä¸ªkeyè®¡ç®—æ³¨æ„åŠ›åˆ†æ•°å¹¶è¿›è¡Œæƒé‡çš„å½’ä¸€åŒ–ï¼Œè¾“å‡ºçš„å‘é‡$o$åˆ™æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼Œè€Œæ¯ä¸ªkeyè®¡ç®—çš„æƒé‡ä¸valueä¸€ä¸€å¯¹åº”ã€‚</p>
<p>ä¸ºäº†è®¡ç®—è¾“å‡ºï¼Œæˆ‘ä»¬é¦–å…ˆå‡è®¾æœ‰ä¸€ä¸ªå‡½æ•°$\alpha$ ç”¨äºè®¡ç®—queryå’Œkeyçš„ç›¸ä¼¼æ€§ï¼Œç„¶åå¯ä»¥è®¡ç®—æ‰€æœ‰çš„ attention scores $a_1, \ldots, a_n$ by</p>
<script type="math/tex; mode=display">
a_i = \alpha(\mathbf q, \mathbf k_i).</script><p>æˆ‘ä»¬ä½¿ç”¨<code>softmax</code>å‡½æ•° è·å¾—æ³¨æ„åŠ›æƒé‡ï¼š</p>
<script type="math/tex; mode=display">
b_1, \ldots, b_n = \textrm{softmax}(a_1, \ldots, a_n).</script><p>æœ€ç»ˆçš„è¾“å‡ºå°±æ˜¯valueçš„åŠ æƒæ±‚å’Œï¼š</p>
<script type="math/tex; mode=display">
\mathbf o = \sum_{i=1}^n b_i \mathbf v_i.</script><h3 id="softmax-å±è”½"><a href="#softmax-å±è”½" class="headerlink" title="softmax å±è”½"></a>softmax å±è”½</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">masked_softmax</span><span class="params">(X, valid_length)</span>:</span></span><br><span class="line">    <span class="comment"># X: 3-D tensor, valid_length: 1-D or 2-D tensor</span></span><br><span class="line">    softmax = nn.Softmax(dim=<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> valid_length <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> softmax(X)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        shape = X.shape</span><br><span class="line">        <span class="keyword">if</span> valid_length.dim() == <span class="number">1</span>: </span><br><span class="line"><span class="comment">#å¦‚æœæ˜¯ä¸€ç»´çš„è¯ï¼Œè¡¨ç¤ºæ²¡æœ‰è€ƒè™‘åˆ°æœ‰å¤šä¸ªbatch_sizeï¼Œé‚£ä¹ˆéœ€è¦è¿›è¡Œè€ƒè™‘</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(valid_length.numpy().repeat(shape[<span class="number">1</span>], axis=<span class="number">0</span>))<span class="comment">#[2,2,3,3] è¿›è¡Œrepeat æ˜¯æŒ‡éœ€è¦repeatäº†ç›¸åº”çš„æ­¥é•¿ç»´åº¦ç»™æ¯ä¸ªbatch</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(valid_length.cpu().numpy().repeat(shape[<span class="number">1</span>], axis=<span class="number">0</span>))<span class="comment">#[2,2,3,3] è¿™é‡Œè€ƒè™‘äº†æ˜¯åœ¨å…·ä½“å“ªä¸ªdevice ä¸Šè¿›è¡Œè®­ç»ƒ</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_length = valid_length.reshape((<span class="number">-1</span>,))</span><br><span class="line">        <span class="comment"># fill masked elements with a large negative, whose exp is 0</span></span><br><span class="line">        X = SequenceMask(X.reshape((<span class="number">-1</span>, shape[<span class="number">-1</span>])), valid_length)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> softmax(X).reshape(shape)</span><br></pre></td></tr></table></figure>
<p>è¿™é‡Œçš„mask çš„ä½œç”¨å’Œä¸Šä¸€èŠ‚ä¸­å®é™…ä¸Šæ˜¯ä¸€æ ·çš„ï¼Œç”±äºæ¯ä¸€å¥çš„é•¿åº¦æ˜¯ä¸åŒçš„ï¼Œä½†æ˜¯åœ¨è¿›è¡Œè®­ç»ƒçš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦ä¿æŒæ¯ä¸€å¥æ‰€å±•ç°å‡ºæ¥çš„ç»´åº¦æ˜¯ç›¸åŒçš„ï¼Œæ•…è€Œå¯¹äºç¼ºå°‘çš„ï¼Œä¼šè¿›è¡Œç›¸åº”çš„padding ,ä½†æ˜¯è¡¥è¶³çš„éƒ¨åˆ†ä¸åº”è¯¥çº³å…¥<code>softmax</code>çš„è®¡ç®—å½“ä¸­ã€‚</p>
<h4 id="ç»´åº¦"><a href="#ç»´åº¦" class="headerlink" title="ç»´åº¦"></a>ç»´åº¦</h4><p>æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢è¿›è¡Œåº”ç”¨çš„æ—¶å€™ï¼Œç»´åº¦æ˜¯æ¯”è¾ƒå¤æ‚çš„ä¸€ä¸ªç‚¹ï¼Œè¿™é‡Œä¸»è¦è¿›è¡Œä¸€ä¸‹è¯´æ˜ã€‚</p>
<p>ä¸€èˆ¬æ¥è¯´ï¼Œè¾“å…¥çš„ç»´åº¦ä¸€èˆ¬éƒ½åŒ…æ‹¬äº†è¿™æ ·å‡ ä¸ªæ–¹é¢ï¼Œbatch_size ï¼Œæ­¥é•¿ï¼Œè¾“å…¥ç»´åº¦ã€‚å¯¹äºè¯­è¨€è€Œè¨€ï¼Œå…¶æœ¬èº«çš„ç½‘ç»œï¼Œä¸ä»…åŒ…æ‹¬äº†åŸæ¥çš„å°æ‰¹é‡è®­ç»ƒæ—¶å€™çš„batch_size å’Œ æœ¬æ¥ä¸€ä¸ªè¯­å¥çš„ç»´åº¦ï¼ŒåŒæ—¶è¿˜æœ‰ä¸€ä¸ªæ—¶é—´ç»´åº¦ã€‚</p>
<p>ä¾‹å¦‚åœ¨è¿›è¡Œç›¸åº”çš„maskçš„æ—¶å€™ï¼Œå¯ä»¥å‚è§ä¸Šé¢çš„ä»£ç ä¸­æ‰€ç»™å‡ºçš„æ³¨é‡Šçš„å«ä¹‰ã€‚</p>
<h4 id="é«˜ç»´çŸ©é˜µç›¸ä¹˜"><a href="#é«˜ç»´çŸ©é˜µç›¸ä¹˜" class="headerlink" title="é«˜ç»´çŸ©é˜µç›¸ä¹˜"></a>é«˜ç»´çŸ©é˜µç›¸ä¹˜</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.bmm(torch.ones((<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>), dtype = torch.float), torch.ones((<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>), dtype = torch.float)) <span class="comment">#ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•</span></span><br></pre></td></tr></table></figure>
<p><code>torch.bmm</code>æ˜¯çŸ©é˜µçš„ä¹˜æ³•ï¼Œå¯¹äºé«˜ç»´çŸ©é˜µï¼Œæ¯”å¦‚ä¸Šé¢çš„ä»£ç æ‰€å±•ç¤ºçš„é‚£æ ·ï¼Œå¾—åˆ°çš„shape = (2,1,2)</p>
<p>ä¸¤ä¸ªæ•°ç»„å°ºå¯¸è¦æ±‚ï¼š</p>
<ul>
<li>â€œ<strong>2ç»´ä»¥ä¸Š</strong>â€œçš„å°ºå¯¸å¿…é¡»å®Œå…¨å¯¹åº”ç›¸ç­‰ï¼›</li>
<li>â€œ<strong>2ç»´</strong>â€œå…·æœ‰å®é™…æ„ä¹‰çš„å•ä½ï¼Œåªè¦æ»¡è¶³çŸ©é˜µç›¸ä¹˜çš„å°ºå¯¸è§„å¾‹å³å¯ã€‚</li>
</ul>
<h3 id="ç‚¹ç§¯æ³¨æ„åŠ›"><a href="#ç‚¹ç§¯æ³¨æ„åŠ›" class="headerlink" title="ç‚¹ç§¯æ³¨æ„åŠ›"></a>ç‚¹ç§¯æ³¨æ„åŠ›</h3><p>The dot product å‡è®¾queryå’Œkeysæœ‰ç›¸åŒçš„ç»´åº¦, å³ $\forall i, ğª,ğ¤_ğ‘– âˆˆ â„_ğ‘‘ $. é€šè¿‡è®¡ç®—queryå’Œkeyè½¬ç½®çš„ä¹˜ç§¯æ¥è®¡ç®—attention score,é€šå¸¸è¿˜ä¼šé™¤å» $\sqrt{d}$ å‡å°‘è®¡ç®—å‡ºæ¥çš„scoreå¯¹ç»´åº¦ğ‘‘çš„ä¾èµ–æ€§ï¼Œå¦‚ä¸‹</p>
<script type="math/tex; mode=display">
ğ›¼(ğª,ğ¤)=âŸ¨ğª,ğ¤âŸ©/ \sqrt{d}</script><p>å‡è®¾ $ ğâˆˆâ„^{ğ‘šÃ—ğ‘‘}$ æœ‰ $m$ ä¸ªqueryï¼Œ$ğŠâˆˆâ„^{ğ‘›Ã—ğ‘‘}$ æœ‰ $n$ ä¸ªkeys. æˆ‘ä»¬å¯ä»¥é€šè¿‡çŸ©é˜µè¿ç®—çš„æ–¹å¼è®¡ç®—æ‰€æœ‰ $mn$ ä¸ªscoreï¼š</p>
<script type="math/tex; mode=display">
ğ›¼(ğ,ğŠ)=ğğŠ^ğ‘‡/\sqrt{d}</script><p>ç°åœ¨è®©æˆ‘ä»¬å®ç°è¿™ä¸ªå±‚ï¼Œå®ƒæ”¯æŒä¸€æ‰¹æŸ¥è¯¢å’Œé”®å€¼å¯¹ã€‚æ­¤å¤–ï¼Œå®ƒæ”¯æŒä½œä¸ºæ­£åˆ™åŒ–éšæœºåˆ é™¤ä¸€äº›æ³¨æ„åŠ›æƒé‡.</p>
<h3 id="å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›"><a href="#å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›" class="headerlink" title="å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›"></a>å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›</h3><p>åœ¨å¤šå±‚æ„ŸçŸ¥å™¨ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå°† query and keys æŠ•å½±åˆ°  $â„^â„$ .ä¸ºäº†æ›´å…·ä½“ï¼Œæˆ‘ä»¬å°†å¯ä»¥å­¦ä¹ çš„å‚æ•°åšå¦‚ä¸‹æ˜ å°„<br>$ğ–_ğ‘˜âˆˆâ„^{â„Ã—ğ‘‘_ğ‘˜}$ ,  $ğ–_ğ‘âˆˆâ„^{â„Ã—ğ‘‘_ğ‘}$ , and  $ğ¯âˆˆâ„^h$ . å°†scoreå‡½æ•°å®šä¹‰</p>
<script type="math/tex; mode=display">
ğ›¼(ğ¤,ğª)=ğ¯^ğ‘‡tanh(ğ–_ğ‘˜ğ¤+ğ–_ğ‘ğª)</script><p>.<br>ç„¶åå°†key å’Œ value åœ¨ç‰¹å¾çš„ç»´åº¦ä¸Šåˆå¹¶ï¼ˆconcatenateï¼‰ï¼Œç„¶åé€è‡³ a single hidden layer perceptron è¿™å±‚ä¸­ hidden layer ä¸º  â„  and è¾“å‡ºçš„sizeä¸º 1 .éšå±‚æ¿€æ´»å‡½æ•°ä¸ºtanhï¼Œæ— åç½®.</p>
<h3 id="å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹"><a href="#å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹" class="headerlink" title="å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹"></a>å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹</h3><p>å°†æ³¨æ„æœºåˆ¶æ·»åŠ åˆ°sequence to sequence æ¨¡å‹ä¸­ï¼Œä»¥æ˜¾å¼åœ°ä½¿ç”¨æƒé‡èšåˆstatesã€‚ä¸‹å›¾å±•ç¤ºencoding å’Œdecodingçš„æ¨¡å‹ç»“æ„ï¼Œåœ¨æ—¶é—´æ­¥ä¸ºtçš„æ—¶å€™ã€‚æ­¤åˆ»attention layerä¿å­˜ç€encoderingçœ‹åˆ°çš„æ‰€æœ‰ä¿¡æ¯â€”â€”å³encodingçš„æ¯ä¸€æ­¥è¾“å‡ºã€‚åœ¨decodingé˜¶æ®µï¼Œè§£ç å™¨çš„$t$æ—¶åˆ»çš„éšè—çŠ¶æ€è¢«å½“ä½œqueryï¼Œencoderçš„æ¯ä¸ªæ—¶é—´æ­¥çš„hidden statesä½œä¸ºkeyå’Œvalueè¿›è¡Œattentionèšåˆ. Attetion modelçš„è¾“å‡ºå½“ä½œæˆä¸Šä¸‹æ–‡ä¿¡æ¯context vectorï¼Œå¹¶ä¸è§£ç å™¨è¾“å…¥$D_t$æ‹¼æ¥èµ·æ¥ä¸€èµ·é€åˆ°è§£ç å™¨ï¼š</p>
<p><img src="https://cdn.kesci.com/upload/image/q5km7o8z93.PNG?imageView2/0/w/800/h/800" alt="Image Name"></p>
<script type="math/tex; mode=display">
Fig1å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹è§£ç çš„ç¬¬äºŒæ­¥</script><p>ä¸‹å›¾å±•ç¤ºäº†seq2seqæœºåˆ¶çš„æ‰€æœ‰å±‚çš„å…³ç³»ï¼Œä¸‹é¢å±•ç¤ºäº†encoderå’Œdecoderçš„layerç»“æ„</p>
<p><img src="https://cdn.kesci.com/upload/image/q5km8dihlr.PNG?imageView2/0/w/800/h/800" alt="Image Name"></p>
<script type="math/tex; mode=display">
Fig2å…·æœ‰æ³¨æ„æœºåˆ¶çš„seq-to-seqæ¨¡å‹ä¸­å±‚ç»“æ„</script><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>åœ¨ä¹‹å‰çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»äº†ä¸»æµçš„ç¥ç»ç½‘ç»œæ¶æ„å¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰å’Œå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNsï¼‰ã€‚è®©æˆ‘ä»¬è¿›è¡Œä¸€äº›å›é¡¾ï¼š</p>
<ul>
<li>CNNs æ˜“äºå¹¶è¡ŒåŒ–ï¼Œå´ä¸é€‚åˆæ•æ‰å˜é•¿åºåˆ—å†…çš„ä¾èµ–å…³ç³»ã€‚</li>
<li>RNNs é€‚åˆæ•æ‰é•¿è·ç¦»å˜é•¿åºåˆ—çš„ä¾èµ–ï¼Œä½†æ˜¯å´éš¾ä»¥å®ç°å¹¶è¡ŒåŒ–å¤„ç†åºåˆ—ã€‚</li>
</ul>
<p>ä¸ºäº†æ•´åˆCNNå’ŒRNNçš„ä¼˜åŠ¿ï¼Œ<a href="https://d2l.ai/chapter_references/zreferences.html#vaswani-shazeer-parmar-ea-2017" target="_blank" rel="noopener">[Vaswani et al., 2017]</a> åˆ›æ–°æ€§åœ°ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶è®¾è®¡äº†Transformeræ¨¡å‹ã€‚è¯¥æ¨¡å‹åˆ©ç”¨attentionæœºåˆ¶å®ç°äº†å¹¶è¡ŒåŒ–æ•æ‰åºåˆ—ä¾èµ–ï¼Œå¹¶ä¸”åŒæ—¶å¤„ç†åºåˆ—çš„æ¯ä¸ªä½ç½®çš„tokensï¼Œä¸Šè¿°ä¼˜åŠ¿ä½¿å¾—Transformeræ¨¡å‹åœ¨æ€§èƒ½ä¼˜å¼‚çš„åŒæ—¶å¤§å¤§å‡å°‘äº†è®­ç»ƒæ—¶é—´ã€‚</p>
<p>å›¾10.3.1å±•ç¤ºäº†Transformeræ¨¡å‹çš„æ¶æ„ï¼Œä¸seq2seqæ¨¡å‹ç›¸ä¼¼ï¼ŒTransformeråŒæ ·åŸºäºç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå…¶åŒºåˆ«ä¸»è¦åœ¨äºä»¥ä¸‹ä¸‰ç‚¹ï¼š</p>
<ol>
<li>Transformer blocksï¼šå°†seq2seqæ¨¡å‹é‡çš„å¾ªç¯ç½‘ç»œæ›¿æ¢ä¸ºäº†Transformer Blocksï¼Œè¯¥æ¨¡å—åŒ…å«ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚ï¼ˆMulti-head Attention Layersï¼‰ä»¥åŠä¸¤ä¸ªposition-wise feed-forward networksï¼ˆFFNï¼‰ã€‚å¯¹äºè§£ç å™¨æ¥è¯´ï¼Œå¦ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚è¢«ç”¨äºæ¥å—ç¼–ç å™¨çš„éšè—çŠ¶æ€ã€‚</li>
<li>Add and normï¼šå¤šå¤´æ³¨æ„åŠ›å±‚å’Œå‰é¦ˆç½‘ç»œçš„è¾“å‡ºè¢«é€åˆ°ä¸¤ä¸ªâ€œadd and normâ€å±‚è¿›è¡Œå¤„ç†ï¼Œè¯¥å±‚åŒ…å«æ®‹å·®ç»“æ„ä»¥åŠå±‚å½’ä¸€åŒ–ã€‚</li>
<li>Position encodingï¼šç”±äºè‡ªæ³¨æ„åŠ›å±‚å¹¶æ²¡æœ‰åŒºåˆ†å…ƒç´ çš„é¡ºåºï¼Œæ‰€ä»¥ä¸€ä¸ªä½ç½®ç¼–ç å±‚è¢«ç”¨äºå‘åºåˆ—å…ƒç´ é‡Œæ·»åŠ ä½ç½®ä¿¡æ¯ã€‚</li>
</ol>
<p><img src="https://cdn.kesci.com/upload/image/q5kpbj2cj5.png?imageView2/0/w/960/h/960" alt="Fig. 10.3.1 The Transformer architecture."></p>
<script type="math/tex; mode=display">
Fig.10.3.1\ Transformer æ¶æ„.</script><h3 id="å¤šå¤´æ³¨æ„åŠ›å±‚"><a href="#å¤šå¤´æ³¨æ„åŠ›å±‚" class="headerlink" title="å¤šå¤´æ³¨æ„åŠ›å±‚"></a>å¤šå¤´æ³¨æ„åŠ›å±‚</h3><p>åœ¨æˆ‘ä»¬è®¨è®ºå¤šå¤´æ³¨æ„åŠ›å±‚ä¹‹å‰ï¼Œå…ˆæ¥è¿…é€Ÿç†è§£ä»¥ä¸‹è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰çš„ç»“æ„ã€‚è‡ªæ³¨æ„åŠ›æ¨¡å‹æ˜¯ä¸€ä¸ªæ­£è§„çš„æ³¨æ„åŠ›æ¨¡å‹ï¼Œåºåˆ—çš„æ¯ä¸€ä¸ªå…ƒç´ å¯¹åº”çš„keyï¼Œvalueï¼Œqueryæ˜¯å®Œå…¨ä¸€è‡´çš„ã€‚å¦‚å›¾10.3.2 è‡ªæ³¨æ„åŠ›è¾“å‡ºäº†ä¸€ä¸ªä¸è¾“å…¥é•¿åº¦ç›¸åŒçš„è¡¨å¾åºåˆ—ï¼Œä¸å¾ªç¯ç¥ç»ç½‘ç»œç›¸æ¯”ï¼Œè‡ªæ³¨æ„åŠ›å¯¹æ¯ä¸ªå…ƒç´ è¾“å‡ºçš„è®¡ç®—æ˜¯å¹¶è¡Œçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥é«˜æ•ˆçš„å®ç°è¿™ä¸ªæ¨¡å—ã€‚</p>
<p><img src="https://cdn.kesci.com/upload/image/q5kpckv38q.png?imageView2/0/w/320/h/320" alt="Fig. 10.3.2 è‡ªæ³¨æ„åŠ›ç»“æ„"></p>
<script type="math/tex; mode=display">
Fig.10.3.2\ è‡ªæ³¨æ„åŠ›ç»“æ„</script><p>å¤šå¤´æ³¨æ„åŠ›å±‚åŒ…å«$h$ä¸ªå¹¶è¡Œçš„è‡ªæ³¨æ„åŠ›å±‚ï¼Œæ¯ä¸€ä¸ªè¿™ç§å±‚è¢«æˆä¸ºä¸€ä¸ªheadã€‚å¯¹æ¯ä¸ªå¤´æ¥è¯´ï¼Œåœ¨è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ä¹‹å‰ï¼Œæˆ‘ä»¬ä¼šå°†queryã€keyå’Œvalueç”¨ä¸‰ä¸ªç°è¡Œå±‚è¿›è¡Œæ˜ å°„ï¼Œè¿™$h$ä¸ªæ³¨æ„åŠ›å¤´çš„è¾“å‡ºå°†ä¼šè¢«æ‹¼æ¥ä¹‹åè¾“å…¥æœ€åä¸€ä¸ªçº¿æ€§å±‚è¿›è¡Œæ•´åˆã€‚</p>
<p><img src="https://cdn.kesci.com/upload/image/q5kpcsozid.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<script type="math/tex; mode=display">
Fig.10.3.3\ å¤šå¤´æ³¨æ„åŠ›</script><p>å‡è®¾queryï¼Œkeyå’Œvalueçš„ç»´åº¦åˆ†åˆ«æ˜¯$d_q$ã€$d_k$å’Œ$d_v$ã€‚é‚£ä¹ˆå¯¹äºæ¯ä¸€ä¸ªå¤´$i=1,\ldots,h$ï¼Œæˆ‘ä»¬å¯ä»¥è®­ç»ƒç›¸åº”çš„æ¨¡å‹æƒé‡$W_q^{(i)} \in \mathbb{R}^{p_q\times d_q}$ã€$W_k^{(i)} \in \mathbb{R}^{p_k\times d_k}$å’Œ$W_v^{(i)} \in \mathbb{R}^{p_v\times d_v}$ï¼Œä»¥å¾—åˆ°æ¯ä¸ªå¤´çš„è¾“å‡ºï¼š</p>
<script type="math/tex; mode=display">
o^{(i)} = attention(W_q^{(i)}q, W_k^{(i)}k, W_v^{(i)}v)</script><p>è¿™é‡Œçš„attentionå¯ä»¥æ˜¯ä»»æ„çš„attention functionï¼Œæ¯”å¦‚å‰ä¸€èŠ‚ä»‹ç»çš„dot-product attentionä»¥åŠMLP attentionã€‚ä¹‹åæˆ‘ä»¬å°†æ‰€æœ‰headå¯¹åº”çš„è¾“å‡ºæ‹¼æ¥èµ·æ¥ï¼Œé€å…¥æœ€åä¸€ä¸ªçº¿æ€§å±‚è¿›è¡Œæ•´åˆï¼Œè¿™ä¸ªå±‚çš„æƒé‡å¯ä»¥è¡¨ç¤ºä¸º$W_o\in \mathbb{R}^{d_0 \times hp_v}$</p>
<script type="math/tex; mode=display">
o = W_o[o^{(1)}, \ldots, o^{(h)}]</script><p>æ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥æ¥å®ç°å¤šå¤´æ³¨æ„åŠ›äº†ï¼Œå‡è®¾æˆ‘ä»¬æœ‰hä¸ªå¤´ï¼Œéšè—å±‚æƒé‡ $hidden_size = p_q = p_k = p_v$ ä¸queryï¼Œkeyï¼Œvalueçš„ç»´åº¦ä¸€è‡´ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå› ä¸ºå¤šå¤´æ³¨æ„åŠ›å±‚ä¿æŒè¾“å…¥ä¸è¾“å‡ºå¼ é‡çš„ç»´åº¦ä¸å˜ï¼Œæ‰€ä»¥è¾“å‡ºfeatureçš„ç»´åº¦ä¹Ÿè®¾ç½®ä¸º $d_0 = hidden_size$ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, num_heads, dropout, **kwargs)</span>:</span></span><br><span class="line">        super(MultiHeadAttention, self).__init__(**kwargs)</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.attention = DotProductAttention(dropout)</span><br><span class="line">        self.W_q = nn.Linear(input_size, hidden_size, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.W_k = nn.Linear(input_size, hidden_size, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.W_v = nn.Linear(input_size, hidden_size, bias=<span class="keyword">False</span>)</span><br><span class="line">        self.W_o = nn.Linear(hidden_size, hidden_size, bias=<span class="keyword">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, valid_length)</span>:</span></span><br><span class="line">        <span class="comment"># query, key, and value shape: (batch_size, seq_len, dim),</span></span><br><span class="line">        <span class="comment"># where seq_len is the length of input sequence</span></span><br><span class="line">        <span class="comment"># valid_length shape is either (batch_size, )</span></span><br><span class="line">        <span class="comment"># or (batch_size, seq_len).</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Project and transpose query, key, and value from</span></span><br><span class="line">        <span class="comment"># (batch_size, seq_len, hidden_size * num_heads) to</span></span><br><span class="line">        <span class="comment"># (batch_size * num_heads, seq_len, hidden_size).</span></span><br><span class="line">        </span><br><span class="line">        query = transpose_qkv(self.W_q(query), self.num_heads)</span><br><span class="line">        key = transpose_qkv(self.W_k(key), self.num_heads)</span><br><span class="line">        value = transpose_qkv(self.W_v(value), self.num_heads)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> valid_length <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="comment"># Copy valid_length by num_heads times</span></span><br><span class="line">            device = valid_length.device</span><br><span class="line">            valid_length = valid_length.cpu().numpy() <span class="keyword">if</span> valid_length.is_cuda <span class="keyword">else</span> valid_length.numpy()</span><br><span class="line">            <span class="keyword">if</span> valid_length.ndim == <span class="number">1</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(np.tile(valid_length, self.num_heads))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                valid_length = torch.FloatTensor(np.tile(valid_length, (self.num_heads,<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">            valid_length = valid_length.to(device)</span><br><span class="line">            </span><br><span class="line">        output = self.attention(query, key, value, valid_length)</span><br><span class="line">        output_concat = transpose_output(output, self.num_heads)</span><br><span class="line">        <span class="keyword">return</span> self.W_o(output_concat)</span><br></pre></td></tr></table></figure>
<p>å…³äºå…¶ä¸­å®ç°çš„ä»£ç ï¼Œé¦–å…ˆè¦æ³¨æ„å…¶ç»´åº¦ä¸Šçš„å˜åŒ–ï¼Œå¯¹äºquery , key å’Œ value ï¼Œå…¶æœ¬èº«åœ¨ç»´åº¦ä¸Šéƒ½æ˜¯(batch_size , seq_len , dim )ï¼Œè¿™å’Œä¹‹å‰çš„æ˜¯ç›¸åŒçš„ï¼Œç„¶ååˆ©ç”¨transpose ä¼šå°†æœ€åä¸€ç»´å˜æˆä¸¤ç»´ï¼Œå€’æ•°ç¬¬äºŒç»´æ˜¯head_numsï¼Œç„¶åå†è¿›è¡Œå˜æ¢ï¼Œå…·ä½“å¯å‚è§å¦‚ä¸‹ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transpose_qkv</span><span class="params">(X, num_heads)</span>:</span></span><br><span class="line">    <span class="comment"># Original X shape: (batch_size, seq_len, hidden_size * num_heads),</span></span><br><span class="line">    <span class="comment"># -1 means inferring its value, after first reshape, X shape:</span></span><br><span class="line">    <span class="comment"># (batch_size, seq_len, num_heads, hidden_size)</span></span><br><span class="line">    X = X.view(X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>], num_heads, <span class="number">-1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># After transpose, X shape: (batch_size, num_heads, seq_len, hidden_size)</span></span><br><span class="line">    X = X.transpose(<span class="number">2</span>, <span class="number">1</span>).contiguous()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Merge the first two dimensions. Use reverse=True to infer shape from</span></span><br><span class="line">    <span class="comment"># right to left.</span></span><br><span class="line">    <span class="comment"># output shape: (batch_size * num_heads, seq_len, hidden_size)</span></span><br><span class="line">    output = X.view(<span class="number">-1</span>, X.shape[<span class="number">2</span>], X.shape[<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>å…³äº<code>np.tile</code>å‡½æ•°ï¼šå®˜æ–¹æ–‡æ¡£ä¸º</p>
<p><code>Construct an array by repeating A the number of times given by reps.</code></p>
<p>If <em>reps</em> has length <code>d</code>, the result will have dimension of <code>max(d, A.ndim)</code>.</p>
<p>If <code>A.ndim &lt; d</code>, <em>A</em> is promoted to be d-dimensional by prepending new axes. So a shape (3,) array is promoted to (1, 3) for 2-D replication, or shape (1, 1, 3) for 3-D replication. If this is not the desired behavior, promote <em>A</em> to d-dimensions manually before calling this function.</p>
<p>If <code>A.ndim &gt; d</code>, <em>reps</em> is promoted to <em>A</em>.ndim by pre-pending 1â€™s to it. Thus for an <em>A</em> of shape (2, 3, 4, 5), a <em>reps</em> of (2, 2) is treated as (1, 1, 2, 2).</p>
<p>æ³¨æ„ç»´åº¦çš„è°ƒæ¢</p>
<p>æœ€åçš„output çš„ shape  : (batch_size,seq_len,hide_size * head_nums)</p>
<h3 id="åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ"><a href="#åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ" class="headerlink" title="åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ"></a>åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ</h3><p>å…¶æ•ˆæœä¸»è¦ç”¨äºå˜æ¢ç»´åº¦ï¼Œå®é™…ä¸Šå°±ç­‰åŒäºä¸€ä¸ª$1 \times 1$çš„å·ç§¯å±‚</p>
<h3 id="Add-and-Norm"><a href="#Add-and-Norm" class="headerlink" title="Add and Norm"></a>Add and Norm</h3><p>é™¤äº†ä¸Šé¢ä¸¤ä¸ªæ¨¡å—ä¹‹å¤–ï¼ŒTransformerè¿˜æœ‰ä¸€ä¸ªé‡è¦çš„ç›¸åŠ å½’ä¸€åŒ–å±‚ï¼Œå®ƒå¯ä»¥å¹³æ»‘åœ°æ•´åˆè¾“å…¥å’Œå…¶ä»–å±‚çš„è¾“å‡ºï¼Œå› æ­¤æˆ‘ä»¬åœ¨æ¯ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚å’ŒFFNå±‚åé¢éƒ½æ·»åŠ ä¸€ä¸ªå«æ®‹å·®è¿æ¥çš„Layer Normå±‚ã€‚è¿™é‡Œ Layer Norm ä¸7.5å°èŠ‚çš„Batch Normå¾ˆç›¸ä¼¼ï¼Œå”¯ä¸€çš„åŒºåˆ«åœ¨äºBatch Normæ˜¯å¯¹äºbatch sizeè¿™ä¸ªç»´åº¦è¿›è¡Œè®¡ç®—å‡å€¼å’Œæ–¹å·®çš„ï¼Œè€ŒLayer Normåˆ™æ˜¯å¯¹æœ€åä¸€ç»´è¿›è¡Œè®¡ç®—ã€‚å±‚å½’ä¸€åŒ–å¯ä»¥é˜²æ­¢å±‚å†…çš„æ•°å€¼å˜åŒ–è¿‡å¤§ï¼Œä»è€Œæœ‰åˆ©äºåŠ å¿«è®­ç»ƒé€Ÿåº¦å¹¶ä¸”æé«˜æ³›åŒ–æ€§èƒ½ã€‚ <a href="https://zhuanlan.zhihu.com/p/54530247" target="_blank" rel="noopener">(ref)</a> </p>
<p>ä¸å¾ªç¯ç¥ç»ç½‘ç»œä¸åŒï¼Œæ— è®ºæ˜¯å¤šå¤´æ³¨æ„åŠ›ç½‘ç»œè¿˜æ˜¯å‰é¦ˆç¥ç»ç½‘ç»œéƒ½æ˜¯ç‹¬ç«‹åœ°å¯¹æ¯ä¸ªä½ç½®çš„å…ƒç´ è¿›è¡Œæ›´æ–°ï¼Œè¿™ç§ç‰¹æ€§å¸®åŠ©æˆ‘ä»¬å®ç°äº†é«˜æ•ˆçš„å¹¶è¡Œï¼Œå´ä¸¢å¤±äº†é‡è¦çš„åºåˆ—é¡ºåºçš„ä¿¡æ¯ã€‚ä¸ºäº†æ›´å¥½çš„æ•æ‰åºåˆ—ä¿¡æ¯ï¼ŒTransformeræ¨¡å‹å¼•å…¥äº†ä½ç½®ç¼–ç å»ä¿æŒè¾“å…¥åºåˆ—å…ƒç´ çš„ä½ç½®ã€‚</p>
<p>å‡è®¾è¾“å…¥åºåˆ—çš„åµŒå…¥è¡¨ç¤º $X\in \mathbb{R}^{l\times d}$, åºåˆ—é•¿åº¦ä¸º$l$åµŒå…¥å‘é‡ç»´åº¦ä¸º$d$ï¼Œåˆ™å…¶ä½ç½®ç¼–ç ä¸º$P \in \mathbb{R}^{l\times d}$ ï¼Œè¾“å‡ºçš„å‘é‡å°±æ˜¯äºŒè€…ç›¸åŠ  $X + P$ã€‚</p>
<h3 id="ä½ç½®ç¼–ç "><a href="#ä½ç½®ç¼–ç " class="headerlink" title="ä½ç½®ç¼–ç "></a>ä½ç½®ç¼–ç </h3><p>ä½ç½®ç¼–ç æ˜¯ä¸€ä¸ªäºŒç»´çš„çŸ©é˜µï¼Œiå¯¹åº”ç€åºåˆ—ä¸­çš„é¡ºåºï¼Œjå¯¹åº”å…¶embedding vectorå†…éƒ¨çš„ç»´åº¦ç´¢å¼•ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ç­‰å¼è®¡ç®—ä½ç½®ç¼–ç ï¼š</p>
<script type="math/tex; mode=display">
P_{i,2j} = sin(i/10000^{2j/d})</script><script type="math/tex; mode=display">
P_{i,2j+1} = cos(i/10000^{2j/d})</script><script type="math/tex; mode=display">
for\ i=0,\ldots, l-1\ and\ j=0,\ldots,\lfloor (d-1)/2 \rfloor</script><p><img src="https://cdn.kesci.com/upload/image/q5kpe0lu38.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<script type="math/tex; mode=display">
Fig. 10.3.4\ ä½ç½®ç¼–ç </script><p>å¯¹äºtransformerè€Œè¨€ï¼Œæœ¬èº«æ²¡æœ‰åŒ…å«ä½ç½®çš„æ€§è´¨ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.training:</span><br><span class="line">            batch_size, seq_len, _ = X.shape</span><br><span class="line">            <span class="comment"># Shape: (batch_size, seq_len), the values in the j-th column are j+1</span></span><br><span class="line">            valid_length = torch.FloatTensor(np.tile(np.arange(<span class="number">1</span>, seq_len+<span class="number">1</span>), (batch_size, <span class="number">1</span>))) </span><br><span class="line">            valid_length = valid_length.to(X.device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            valid_length = <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<p>åœ¨è¿™é‡Œï¼Œè¦ç†è§£ä¸€ä¸‹ï¼Œå¯¹äºè®­ç»ƒå’Œé¢„æµ‹ï¼Œå…¶è¾“å…¥æ˜¯ä¸åŒçš„ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šç›´æ¥è¾“å…¥æ•´ä¸ªtargetsçš„æ‰€æœ‰tokensï¼Œé‚£ä¹ˆè¿™ä¸ªæ—¶å€™ä¸ºäº†ä¿è¯å…¶ä¸çœ‹åˆ°åé¢çš„ç»“æœæ¥è¿›è¡Œlossçš„è®­ç»ƒï¼Œéœ€è¦è®¾å®šå½“å‰çš„<code>valid_length</code>ï¼Œç›¸å½“äºåªçœ‹åˆ°äº†seq_len+1 è¿™ä¸€ä¸ªtokensä¸ºæ­¢ã€‚</p>
<h2 id="å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€"><a href="#å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€" class="headerlink" title="å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€"></a>å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€</h2><p>è¾“å…¥ç»´åº¦ï¼š</p>
<p>å¯¹äºå·ç§¯ç¥ç»ç½‘ç»œæ¥è¯´ï¼Œä¸€èˆ¬çš„è¾“å…¥Xå’Œä¸­é—´çš„éšè—å±‚ï¼Œéƒ½å…·æœ‰4ä¸ªç»´åº¦ï¼Œå…¶åˆ†åˆ«æ˜¯ï¼š</p>
<p>(batch_size, channels,length,width)</p>
<p>å¯¹äºå…¶ä»–éƒ¨åˆ†ï¼Œåº”è¯¥å°±æ¯”è¾ƒå¥½ç†è§£ã€‚</p>
<h2 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h2><p>LeNetæ˜¯ä¸€ä¸ªæœ€ç»å…¸çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚</p>
<p>ä½¿ç”¨å…¨è¿æ¥å±‚çš„å±€é™æ€§ï¼š</p>
<ul>
<li>å›¾åƒåœ¨åŒä¸€åˆ—é‚»è¿‘çš„åƒç´ åœ¨è¿™ä¸ªå‘é‡ä¸­å¯èƒ½ç›¸è·è¾ƒè¿œã€‚å®ƒä»¬æ„æˆçš„æ¨¡å¼å¯èƒ½éš¾ä»¥è¢«æ¨¡å‹è¯†åˆ«ã€‚</li>
<li>å¯¹äºå¤§å°ºå¯¸çš„è¾“å…¥å›¾åƒï¼Œä½¿ç”¨å…¨è¿æ¥å±‚å®¹æ˜“å¯¼è‡´æ¨¡å‹è¿‡å¤§ã€‚</li>
</ul>
<p>ä½¿ç”¨å·ç§¯å±‚çš„ä¼˜åŠ¿ï¼š</p>
<ul>
<li>å·ç§¯å±‚ä¿ç•™è¾“å…¥å½¢çŠ¶ã€‚</li>
<li>å·ç§¯å±‚é€šè¿‡æ»‘åŠ¨çª—å£å°†åŒä¸€å·ç§¯æ ¸ä¸ä¸åŒä½ç½®çš„è¾“å…¥é‡å¤è®¡ç®—ï¼Œä»è€Œé¿å…å‚æ•°å°ºå¯¸è¿‡å¤§ã€‚</li>
</ul>
<h2 id="å·ç§¯ç¥ç»ç½‘ç»œè¿›é˜¶"><a href="#å·ç§¯ç¥ç»ç½‘ç»œè¿›é˜¶" class="headerlink" title="å·ç§¯ç¥ç»ç½‘ç»œè¿›é˜¶"></a>å·ç§¯ç¥ç»ç½‘ç»œè¿›é˜¶</h2><p>ä¸»è¦ä»‹ç»äº†å‡ ä¸ªç»å…¸çš„å·ç§¯ç¥ç»ç½‘ç»œ</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>é¦–æ¬¡è¯æ˜äº†å­¦ä¹ åˆ°çš„ç‰¹å¾å¯ä»¥è¶…è¶Šâ¼¿â¼¯è®¾è®¡çš„ç‰¹å¾ï¼Œä»è€Œâ¼€ä¸¾æ‰“ç ´è®¡ç®—æœºè§†è§‰ç ”ç©¶çš„å‰çŠ¶ã€‚<br> <strong>ç‰¹å¾ï¼š</strong></p>
<ol>
<li>8å±‚å˜æ¢ï¼Œå…¶ä¸­æœ‰5å±‚å·ç§¯å’Œ2å±‚å…¨è¿æ¥éšè—å±‚ï¼Œä»¥åŠ1ä¸ªå…¨è¿æ¥è¾“å‡ºå±‚ã€‚</li>
<li>å°†sigmoidæ¿€æ´»å‡½æ•°æ”¹æˆäº†æ›´åŠ ç®€å•çš„ReLUæ¿€æ´»å‡½æ•°ã€‚</li>
<li>ç”¨Dropoutæ¥æ§åˆ¶å…¨è¿æ¥å±‚çš„æ¨¡å‹å¤æ‚åº¦ã€‚</li>
<li>å¼•å…¥æ•°æ®å¢å¼ºï¼Œå¦‚ç¿»è½¬ã€è£å‰ªå’Œé¢œè‰²å˜åŒ–ï¼Œä»è€Œè¿›ä¸€æ­¥æ‰©å¤§æ•°æ®é›†æ¥ç¼“è§£è¿‡æ‹Ÿåˆã€‚</li>
</ol>
<h3 id="ä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œï¼ˆVGGï¼‰"><a href="#ä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œï¼ˆVGGï¼‰" class="headerlink" title="ä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œï¼ˆVGGï¼‰"></a>ä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œï¼ˆVGGï¼‰</h3><p>VGGï¼šé€šè¿‡é‡å¤ä½¿â½¤ç®€å•çš„åŸºç¡€å—æ¥æ„å»ºæ·±åº¦æ¨¡å‹ã€‚<br> Block:æ•°ä¸ªç›¸åŒçš„å¡«å……ä¸º1ã€çª—å£å½¢çŠ¶ä¸º</p>
<p>çš„å·ç§¯å±‚,æ¥ä¸Šä¸€ä¸ªæ­¥å¹…ä¸º2ã€çª—å£å½¢çŠ¶ä¸ºçš„æœ€å¤§æ± åŒ–å±‚ã€‚<br> å·ç§¯å±‚ä¿æŒè¾“å…¥çš„é«˜å’Œå®½ä¸å˜ï¼Œè€Œæ± åŒ–å±‚åˆ™å¯¹å…¶å‡åŠã€‚</p>
<p><img src="https://cdn.kesci.com/upload/image/q5l6vut7h1.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
<h3 id="ç½‘ç»œä¸­çš„ç½‘ç»œ-NiN"><a href="#ç½‘ç»œä¸­çš„ç½‘ç»œ-NiN" class="headerlink" title="ç½‘ç»œä¸­çš„ç½‘ç»œ(NiN)"></a>ç½‘ç»œä¸­çš„ç½‘ç»œ(NiN)</h3><p>LeNetã€AlexNetå’ŒVGGï¼šå…ˆä»¥ç”±å·ç§¯å±‚æ„æˆçš„æ¨¡å—å……åˆ†æŠ½å– ç©ºé—´ç‰¹å¾ï¼Œå†ä»¥ç”±å…¨è¿æ¥å±‚æ„æˆçš„æ¨¡å—æ¥è¾“å‡ºåˆ†ç±»ç»“æœã€‚<br> NiNï¼šä¸²è”å¤šä¸ªç”±å·ç§¯å±‚å’Œâ€œå…¨è¿æ¥â€å±‚æ„æˆçš„å°â½¹ç»œæ¥æ„å»ºâ¼€ä¸ªæ·±å±‚â½¹ç»œã€‚<br> â½¤äº†è¾“å‡ºé€šé“æ•°ç­‰äºæ ‡ç­¾ç±»åˆ«æ•°çš„NiNå—ï¼Œç„¶åä½¿â½¤å…¨å±€å¹³å‡æ± åŒ–å±‚å¯¹æ¯ä¸ªé€šé“ä¸­æ‰€æœ‰å…ƒç´ æ±‚å¹³å‡å¹¶ç›´æ¥â½¤äºåˆ†ç±»ã€‚</p>
<p><img src="https://cdn.kesci.com/upload/image/q5l6u1p5vy.png?imageView2/0/w/960/h/960" alt="Image Name"></p>
<h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><ol>
<li>ç”±InceptionåŸºç¡€å—ç»„æˆã€‚  </li>
<li>Inceptionå—ç›¸å½“äºâ¼€ä¸ªæœ‰4æ¡çº¿è·¯çš„â¼¦â½¹ç»œã€‚å®ƒé€šè¿‡ä¸åŒçª—å£å½¢çŠ¶çš„å·ç§¯å±‚å’Œæœ€â¼¤æ± åŒ–å±‚æ¥å¹¶â¾æŠ½å–ä¿¡æ¯ï¼Œå¹¶ä½¿â½¤1Ã—1å·ç§¯å±‚å‡å°‘é€šé“æ•°ä»è€Œé™ä½æ¨¡å‹å¤æ‚åº¦ã€‚   </li>
<li>å¯ä»¥â¾ƒå®šä¹‰çš„è¶…å‚æ•°æ˜¯æ¯ä¸ªå±‚çš„è¾“å‡ºé€šé“æ•°ï¼Œæˆ‘ä»¬ä»¥æ­¤æ¥æ§åˆ¶æ¨¡å‹å¤æ‚åº¦ã€‚ </li>
</ol>
<p><img src="https://cdn.kesci.com/upload/image/q5l6uortw.png?imageView2/0/w/640/h/640" alt="Image Name"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -pytorch/" rel="tag"># åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  pytorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/02/14/pytorch1/" rel="next" title="pytorch1">
                <i class="fa fa-chevron-left"></i> pytorch1
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/02/24/pytorch3/" rel="prev" title="pytorch3">
                pytorch3 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Leliyliu</p>
              <p class="site-description motion-element" itemprop="description">record</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -task2"><span class="nav-number">1.</span> <span class="nav-text">åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  task2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸"><span class="nav-number">1.1.</span> <span class="nav-text">æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯"><span class="nav-number">1.2.</span> <span class="nav-text">æœºå™¨ç¿»è¯‘åŠç›¸å…³æŠ€æœ¯</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#æ•°æ®é¢„å¤„ç†è¿‡ç¨‹"><span class="nav-number">1.2.1.</span> <span class="nav-text">æ•°æ®é¢„å¤„ç†è¿‡ç¨‹</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#è½½å…¥æ•°æ®é›†"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">è½½å…¥æ•°æ®é›†</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Encoder-Decoder"><span class="nav-number">1.2.2.</span> <span class="nav-text">Encoder-Decoder</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sequence-to-Sequence-æ¨¡å‹"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">Sequence to Sequence æ¨¡å‹</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#è®­ç»ƒæ¨¡å‹å’Œæµ‹è¯•æ¨¡å‹"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">è®­ç»ƒæ¨¡å‹å’Œæµ‹è¯•æ¨¡å‹</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#æ³¨æ„åŠ›æœºåˆ¶"><span class="nav-number">1.3.</span> <span class="nav-text">æ³¨æ„åŠ›æœºåˆ¶</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#softmax-å±è”½"><span class="nav-number">1.3.1.</span> <span class="nav-text">softmax å±è”½</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ç»´åº¦"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">ç»´åº¦</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#é«˜ç»´çŸ©é˜µç›¸ä¹˜"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">é«˜ç»´çŸ©é˜µç›¸ä¹˜</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ç‚¹ç§¯æ³¨æ„åŠ›"><span class="nav-number">1.3.2.</span> <span class="nav-text">ç‚¹ç§¯æ³¨æ„åŠ›</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›"><span class="nav-number">1.3.3.</span> <span class="nav-text">å¤šå±‚æ„ŸçŸ¥æœºæ³¨æ„åŠ›</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹"><span class="nav-number">1.3.4.</span> <span class="nav-text">å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶çš„Seq2seqæ¨¡å‹</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Transformer"><span class="nav-number">1.4.</span> <span class="nav-text">Transformer</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#å¤šå¤´æ³¨æ„åŠ›å±‚"><span class="nav-number">1.4.1.</span> <span class="nav-text">å¤šå¤´æ³¨æ„åŠ›å±‚</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ"><span class="nav-number">1.4.2.</span> <span class="nav-text">åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Add-and-Norm"><span class="nav-number">1.4.3.</span> <span class="nav-text">Add and Norm</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ä½ç½®ç¼–ç "><span class="nav-number">1.4.4.</span> <span class="nav-text">ä½ç½®ç¼–ç </span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€"><span class="nav-number">1.5.</span> <span class="nav-text">å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LeNet"><span class="nav-number">1.6.</span> <span class="nav-text">LeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#å·ç§¯ç¥ç»ç½‘ç»œè¿›é˜¶"><span class="nav-number">1.7.</span> <span class="nav-text">å·ç§¯ç¥ç»ç½‘ç»œè¿›é˜¶</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AlexNet"><span class="nav-number">1.7.1.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œï¼ˆVGGï¼‰"><span class="nav-number">1.7.2.</span> <span class="nav-text">ä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œï¼ˆVGGï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ç½‘ç»œä¸­çš„ç½‘ç»œ-NiN"><span class="nav-number">1.7.3.</span> <span class="nav-text">ç½‘ç»œä¸­çš„ç½‘ç»œ(NiN)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GoogLeNet"><span class="nav-number">1.7.4.</span> <span class="nav-text">GoogLeNet</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leliyliu</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
